<!DOCTYPE html>
<!-- saved from url=(0093)https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/ -->
<html lang="en" class="wf-sortsmillgoudy1-n5-active wf-active"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script async="" src="https://graph.facebook.com/?callback=WPCOMSharing.update_facebook_count&amp;ids=https%3A%2F%2Fjeremykun.com%2F2016%2F05%2F16%2Fsingular-value-decomposition-part-2-theorem-proof-algorithm%2F&amp;_=1572929743784"></script><script async="" src="https://api.pinterest.com/v1/urls/count.json?callback=WPCOMSharing.update_pinterest_count&amp;url=https%3A%2F%2Fjeremykun.com%2F2016%2F05%2F16%2Fsingular-value-decomposition-part-2-theorem-proof-algorithm%2F&amp;_=1572929743783"></script>

<meta name="viewport" content="width=device-width">
<link rel="profile" href="http://gmpg.org/xfn/11">
<link rel="pingback" href="https://jeremykun.com/xmlrpc.php">
<!--[if lt IE 9]>
<script src="https://s2.wp.com/wp-content/themes/pub/confit/js/html5.js" type="text/javascript"></script>
<![endif]-->

<title>Singular Value Decomposition Part 2: Theorem, Proof, Algorithm – Math ∩ Programming</title>
<script type="text/javascript" async="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/ga.js.下载"></script><script src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/webfont.js.下载" type="text/javascript" async=""></script><script type="text/javascript">
  WebFontConfig = {"typekit":{"id":"das4ere"}};
  (function() {
    var wf = document.createElement('script');
    wf.src = 'https://s0.wp.com/wp-content/plugins/custom-fonts/js/webfont.js';
    wf.type = 'text/javascript';
    wf.async = 'true';
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(wf, s);
	})();
</script><style id="jetpack-custom-fonts-css">.wf-active .site-title{font-family:"sorts-mill-goudy-1","sorts-mill-goudy-2",serif;font-size:32.6px;font-weight:500;font-style:normal}.wf-active .main-navigation{font-style:normal;font-weight:500}.wf-active .main-navigation a{font-family:"sorts-mill-goudy-1","sorts-mill-goudy-2",serif;font-weight:500;font-style:normal}.wf-active .main-small-navigation a{font-family:"sorts-mill-goudy-1","sorts-mill-goudy-2",serif;font-weight:500;font-style:normal}.wf-active .entry-title{font-family:"sorts-mill-goudy-1","sorts-mill-goudy-2",serif;font-weight:500;font-style:normal}.wf-active .comment-content h1, .wf-active .comment-content h2, .wf-active .comment-content h3, .wf-active .comment-content h4, .wf-active .comment-content h5, .wf-active .comment-content h6, .wf-active .entry-content h1, .wf-active .entry-content h2, .wf-active .entry-content h3, .wf-active .entry-content h4, .wf-active .entry-content h5, .wf-active .entry-content h6{font-family:"sorts-mill-goudy-1","sorts-mill-goudy-2",serif;font-weight:500;font-style:normal}.wf-active .comment-content h1, .wf-active .entry-content h1{font-style:normal;font-weight:500}.wf-active .comment-content h2, .wf-active .entry-content h2{font-style:normal;font-weight:500}.wf-active .comment-content h3, .wf-active .entry-content h3{font-style:normal;font-weight:500}.wf-active .comment-content h4, .wf-active .entry-content h4{font-style:normal;font-weight:500}.wf-active .comment-content h5, .wf-active .entry-content h5{font-style:normal;font-weight:500}.wf-active .comment-content h6, .wf-active .entry-content h6{font-style:normal;font-weight:500}.wf-active .page-template-page-menu-php .menu-group-title{font-family:"sorts-mill-goudy-1","sorts-mill-goudy-2",serif;font-weight:500;font-style:normal}.wf-active .widget-title{font-family:"sorts-mill-goudy-1","sorts-mill-goudy-2",serif;font-weight:500;font-style:normal}</style>
<meta name="google-site-verification" content="8HY57qHGWbOLf0Mw2cmAeX9whInRfftYXbFRcYJ7JDA">

<!-- Async WordPress.com Remote Login -->

<link rel="dns-prefetch" href="https://s2.wp.com/">
<link rel="dns-prefetch" href="https://s1.wp.com/">
<link rel="dns-prefetch" href="https://jeremykun.wordpress.com/">
<link rel="dns-prefetch" href="https://s0.wp.com/">
<link rel="dns-prefetch" href="https://widgets.wp.com/">
<link rel="dns-prefetch" href="https://wordpress.com/">
<link rel="dns-prefetch" href="https://fonts.googleapis.com/">
<link rel="alternate" type="application/rss+xml" title="Math ∩ Programming » Feed" href="https://jeremykun.com/feed/">
<link rel="alternate" type="application/rss+xml" title="Math ∩ Programming » Comments Feed" href="https://jeremykun.com/comments/feed/">
<link rel="alternate" type="application/rss+xml" title="Math ∩ Programming » Singular Value Decomposition Part 2: Theorem, Proof, Algorithm Comments Feed" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/feed/">
	<script type="text/javascript">
		/* <![CDATA[ */
		function addLoadEvent(func) {
			var oldonload = window.onload;
			if (typeof window.onload != 'function') {
				window.onload = func;
			} else {
				window.onload = function () {
					oldonload();
					func();
				}
			}
		}
		/* ]]> */
	</script>
			<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s0.wp.com\/wp-content\/mu-plugins\/wpcom-smileys\/twemoji\/2\/72x72\/","ext":".png","svgUrl":"https:\/\/s0.wp.com\/wp-content\/mu-plugins\/wpcom-smileys\/twemoji\/2\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/s2.wp.com\/wp-includes\/js\/wp-emoji-release.min.js?m=1572020829h&ver=5.3-beta2-46382"}};
			!function(e,a,t){var r,n,o,i,p=a.createElement("canvas"),s=p.getContext&&p.getContext("2d");function c(e,t){var a=String.fromCharCode;s.clearRect(0,0,p.width,p.height),s.fillText(a.apply(this,e),0,0);var r=p.toDataURL();return s.clearRect(0,0,p.width,p.height),s.fillText(a.apply(this,t),0,0),r===p.toDataURL()}function l(e){if(!s||!s.fillText)return!1;switch(s.textBaseline="top",s.font="600 32px Arial",e){case"flag":return!c([127987,65039,8205,9895,65039],[127987,65039,8203,9895,65039])&&(!c([55356,56826,55356,56819],[55356,56826,8203,55356,56819])&&!c([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]));case"emoji":return!c([55357,56424,55356,57342,8205,55358,56605,8205,55357,56424,55356,57340],[55357,56424,55356,57342,8203,55358,56605,8203,55357,56424,55356,57340])}return!1}function d(e){var t=a.createElement("script");t.src=e,t.defer=t.type="text/javascript",a.getElementsByTagName("head")[0].appendChild(t)}for(i=Array("flag","emoji"),t.supports={everything:!0,everythingExceptFlag:!0},o=0;o<i.length;o++)t.supports[i[o]]=l(i[o]),t.supports.everything=t.supports.everything&&t.supports[i[o]],"flag"!==i[o]&&(t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&t.supports[i[o]]);t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&!t.supports.flag,t.DOMReady=!1,t.readyCallback=function(){t.DOMReady=!0},t.supports.everything||(n=function(){t.readyCallback()},a.addEventListener?(a.addEventListener("DOMContentLoaded",n,!1),e.addEventListener("load",n,!1)):(e.attachEvent("onload",n),a.attachEvent("onreadystatechange",function(){"complete"===a.readyState&&t.readyCallback()})),(r=t.source||{}).concatemoji?d(r.concatemoji):r.wpemoji&&r.twemoji&&(d(r.twemoji),d(r.wpemoji)))}(window,document,window._wpemojiSettings);
		</script><script src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/wp-emoji-release.min.js.下载" type="text/javascript" defer=""></script>
		<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
	<link rel="stylesheet" id="all-css-0-1" href="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/saved_resource(1)" type="text/css" media="all">
<link rel="stylesheet" id="wpcom-block-editor-styles-css" href="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/common.min.css" media="all">
<link rel="stylesheet" id="all-css-2-1" href="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/saved_resource(2)" type="text/css" media="all">
<link rel="stylesheet" id="confit-font-muli-css" href="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/css" media="all">
<link rel="stylesheet" id="confit-font-enriqueta-css" href="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/css(1)" media="all">
<link rel="stylesheet" id="all-css-6-1" href="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/saved_resource(3)" type="text/css" media="all">
<link rel="stylesheet" id="print-css-7-1" href="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/global-print.css" type="text/css" media="print">
<link rel="stylesheet" id="all-css-8-1" href="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/saved_resource(4)" type="text/css" media="all">
<script>
var related_posts_js_options = {"post_heading":"h4"};
</script>
<script type="text/javascript" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/saved_resource(5)"></script>
<link rel="stylesheet" id="all-css-0-2" href="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/style(1).css" type="text/css" media="all">
<!--[if lt IE 8]>
<link rel='stylesheet' id='highlander-comments-ie7-css'  href='https://s2.wp.com/wp-content/mu-plugins/highlander-comments/style-ie7.css?m=1351637563h&#038;ver=20110606' media='all' />
<![endif]-->
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://jeremykun.wordpress.com/xmlrpc.php?rsd">
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="https://s1.wp.com/wp-includes/wlwmanifest.xml"> 
<link rel="prev" title="Book mailing list" href="https://jeremykun.com/2016/04/25/book-mailing-list/">
<link rel="next" title="Zero Knowledge Proofs — A Primer" href="https://jeremykun.com/2016/07/05/zero-knowledge-proofs-a-primer/">
<meta name="generator" content="WordPress.com">
<link rel="canonical" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/">
<link rel="shortlink" href="https://wp.me/p1Cqvi-2al">
<link rel="alternate" type="application/json+oembed" href="https://public-api.wordpress.com/oembed/?format=json&amp;url=https%3A%2F%2Fjeremykun.com%2F2016%2F05%2F16%2Fsingular-value-decomposition-part-2-theorem-proof-algorithm%2F&amp;for=wpcom-auto-discovery"><link rel="alternate" type="application/xml+oembed" href="https://public-api.wordpress.com/oembed/?format=xml&amp;url=https%3A%2F%2Fjeremykun.com%2F2016%2F05%2F16%2Fsingular-value-decomposition-part-2-theorem-proof-algorithm%2F&amp;for=wpcom-auto-discovery">
<!-- Jetpack Open Graph Tags -->
<meta property="og:type" content="article">
<meta property="og:title" content="Singular Value Decomposition Part 2: Theorem, Proof, Algorithm">
<meta property="og:url" content="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/">
<meta property="og:description" content="I’m just going to jump right into the definitions and rigor, so if you haven’t read the previous post motivating the singular value decomposition, go back and do that first. This post w…">
<meta property="article:published_time" content="2016-05-16T15:00:19+00:00">
<meta property="article:modified_time" content="2016-12-01T16:04:20+00:00">
<meta property="og:site_name" content="Math ∩ Programming">
<meta property="og:image" content="https://jeremykun.files.wordpress.com/2015/11/movieratings.png">
<meta property="og:image:width" content="812">
<meta property="og:image:height" content="521">
<meta property="og:image:alt" content="movieratings">
<meta property="og:locale" content="en_US">
<meta name="twitter:creator" content="@MathProgramming">
<meta name="twitter:site" content="@MathProgramming">
<meta name="twitter:text:title" content="Singular Value Decomposition Part 2: Theorem, Proof, Algorithm">
<meta name="twitter:card" content="summary">
<meta property="article:publisher" content="https://www.facebook.com/WordPresscom">

<!-- End Jetpack Open Graph Tags -->
<link rel="shortcut icon" type="image/x-icon" href="https://secure.gravatar.com/blavatar/ffc08531463d8605aef9e0b51a9ac71f?s=32" sizes="16x16">
<link rel="icon" type="image/x-icon" href="https://secure.gravatar.com/blavatar/ffc08531463d8605aef9e0b51a9ac71f?s=32" sizes="16x16">
<link rel="apple-touch-icon-precomposed" href="https://secure.gravatar.com/blavatar/ffc08531463d8605aef9e0b51a9ac71f?s=114">
<link rel="openid.server" href="https://jeremykun.com/?openidserver=1">
<link rel="openid.delegate" href="https://jeremykun.com/">
<link rel="search" type="application/opensearchdescription+xml" href="https://jeremykun.com/osd.xml" title="Math ∩ Programming">
<link rel="search" type="application/opensearchdescription+xml" href="https://s1.wp.com/opensearch.xml" title="WordPress.com">
<meta name="theme-color" content="#ffffff">
		<style type="text/css">
			.recentcomments a {
				display: inline !important;
				padding: 0 !important;
				margin: 0 !important;
			}

			table.recentcommentsavatartop img.avatar, table.recentcommentsavatarend img.avatar {
				border: 0px;
				margin: 0;
			}

			table.recentcommentsavatartop a, table.recentcommentsavatarend a {
				border: 0px !important;
				background-color: transparent !important;
			}

			td.recentcommentsavatarend, td.recentcommentsavatartop {
				padding: 0px 0px 1px 0px;
				margin: 0px;
			}

			td.recentcommentstextend {
				border: none !important;
				padding: 0px 0px 2px 10px;
			}

			.rtl td.recentcommentstextend {
				padding: 0px 10px 2px 0px;
			}

			td.recentcommentstexttop {
				border: none;
				padding: 0px 0px 0px 10px;
			}

			.rtl td.recentcommentstexttop {
				padding: 0px 10px 0px 0px;
			}
		</style>
		<meta name="application-name" content="Math ∩ Programming"><meta name="msapplication-window" content="width=device-width;height=device-height"><meta name="msapplication-task" content="name=Subscribe;action-uri=https://jeremykun.com/feed/;icon-uri=https://secure.gravatar.com/blavatar/ffc08531463d8605aef9e0b51a9ac71f?s=16"><meta name="msapplication-task" content="name=Sign up for a free blog;action-uri=http://wordpress.com/signup/;icon-uri=https://s1.wp.com/i/favicon.ico"><meta name="msapplication-task" content="name=WordPress.com Support;action-uri=http://support.wordpress.com/;icon-uri=https://s1.wp.com/i/favicon.ico"><meta name="msapplication-task" content="name=WordPress.com Forums;action-uri=http://forums.wordpress.com/;icon-uri=https://s1.wp.com/i/favicon.ico"><meta name="description" content="I&#39;m just going to jump right into the definitions and rigor, so if you haven&#39;t read the previous post motivating the singular value decomposition, go back and do that first. This post will be theorem, proof, algorithm, data. The data set we test on is a thousand-story CNN news data set. All of the data, code, and examples…">
<style type="text/css" id="custom-background-css">
	body.custom-background { background-color: #ffffff; }
	</style>
<style type="text/css" id="custom-colors-css">.site-description,.entry-header .entry-meta,.entry-content blockquote,.comment-content blockquote,.comment-meta a{opacity:.5}@media screen and (min-width:768px) and (min-device-width:769px){#masthead,#secondary{background-color:transparent !important}}body{background-color:#fff}#page:before{background-color:#fff}#page:before{background-color:rgba(255,255,255,.95)}.site-footer{background-color:#fff}.site-footer{background-color:rgba(255,255,255,.95)}.main-navigation ul ul{background-color:#fff}.main-navigation ul ul{background-color:rgba(255,255,255,.95)}.site-content article{background-color:#fff}.site-content article{background-color:rgba(255,255,255,.95)}.archive-header,.page-header,.single .menu-group-header{background-color:#fff}.archive-header,.page-header,.single .menu-group-header{background-color:rgba(255,255,255,.95)}.page-template-page-menu-php .menu-items{background-color:#fff}.page-template-page-menu-php .menu-items{background-color:rgba(255,255,255,.95)}.menu-labels span{color:#fff}.pdf-menu a{color:#fff}.site-content .site-navigation{background-color:#fff}.site-content .site-navigation{background-color:rgba(255,255,255,.95)}.comments-area{background-color:#fff}.comments-area{background-color:rgba(255,255,255,.95)}.comment-author span{background-color:#fff}#infinite-handle span{background-color:#fff}#infinite-handle span{background-color:rgba(255,255,255,.95)}#masthead{background-color:#fff}#masthead{background-color:rgba(255,255,255,.95)}#secondary{background-color:#fff}#secondary{background-color:rgba(255,255,255,.95)}button,html input[type=button],input[type=reset],input[type=submit]{color:#fff}button,html input[type=button],input[type=reset],input[type=submit]{color:rgba(255,255,255,.95)}input[type=text],input[type=email],input[type=password],textarea{background-color:#d8d8d8}input[type=text],input[type=email],input[type=password],textarea{border-color:#e5e5e5}hr{background-color:#e5e5e5}.main-navigation li{border-color:#e5e5e5}.entry-content pre,.comment-content pre{border-color:#e5e5e5}.entry-content abbr,.comment-content abbr,.entry-content dfn,.comment-content dfn,.entry-content acronym,.comment-content acronym{border-color:#e5e5e5}.entry-content table,.comment-content table,.entry-content td,.comment-content td{border-color:#e5e5e5}.page-template-page-menu-php .menu-items article{border-color:#e5e5e5}.wp-caption{border-color:#e5e5e5}.widget_calendar #wp-calendar,.widget_calendar #wp-calendar thead th,.widget_calendar #wp-calendar tbody td,.widget_calendar #wp-calendar tfoot td#next{border-color:#e5e5e5}.entry-content div.sharedaddy div.sd-block{border-color:#e5e5e5}.main-small-navigation{border-color:#e5e5e5}body,button,input,select,textarea{color:#36312d}.main-navigation a,.main-small-navigation a,.main-navigation a:visited,.main-small-navigation a:visited{color:#36312d}.page-template-page-menu-php .menu-items .entry-title{color:#36312d}.widget-title a{color:#36312d}input[type=text],input[type=email],input[type=password],textarea{color:#36312d}.site-description{color:#36312d}.entry-meta{color:#36312d}.entry-header .entry-meta a{color:#36312d}.entry-content blockquote,.comment-content blockquote{color:#36312d}.comment-meta a{color:#36312d}a{color:#2f7de4}a:visited{color:#2f7de4}button,html input[type=button],input[type=reset],input[type=submit]{background-color:#2f7de4}.main-navigation a:hover,.main-navigation .current_page_item>a,.main-navigation .current_page_ancestor>a,.main-navigation .current-menu-item>a,.main-navigation .current-menu-ancestor>a{color:#2f7de4}.main-navigation .current_page_item>a:visited,.main-navigation .current_page_ancestor>a:visited,.main-navigation .current-menu-item>a:visited,.main-navigation .current-menu-ancestor>a:visited{color:#2f7de4}.entry-title{color:#2f7de4}.entry-title{border-color:#2f7de4}.page-template-page-menu-php .menu-group-title{color:#2f7de4}.menu-labels span{background-color:#2f7de4}.pdf-menu a{background-color:#2f7de4}.bypostauthor>article .comment-author span{background-color:#2f7de4}.widget_flickr #flickr_badge_uber_wrapper a{color:#2f7de4}#infinite-handle span{color:#2f7de4}#infinite-handle span:before{color:#2f7de4}.entry-content blockquote p,.comment-content blockquote p{border-color:#2f7de4}a:hover,a:focus,a:active{color:#000}button:hover,html input[type=button]:hover,input[type=reset]:hover,input[type=submit]:hover,button:focus,html input[type=button]:focus,input[type=reset]:focus,input[type=submit]:focus,button:active,html input[type=button]:active,input[type=reset]:active,input[type=submit]:active{background-color:#000}.site-title a:hover{color:#000}.entry-header .entry-meta a:hover{color:#000}.entry-title a:hover{color:#000}.pdf-menu a:hover{background-color:#000}.widget_flickr #flickr_badge_uber_wrapper a:hover{color:#000}#infinite-handle span:hover,#infinite-handle span:hover:before{color:#000}</style>
		<link rel="stylesheet" id="custom-css-css" type="text/css" href="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/saved_resource(6)">
		<style type="text/css">.tk-sorts-mill-goudy{font-family:"sorts-mill-goudy-1","sorts-mill-goudy-2",serif;}</style><style type="text/css">@font-face{font-family:sorts-mill-goudy-1;src:url(https://use.typekit.net/af/fd93b1/00000000000000000000d755/27/l?subset_id=2&fvd=n5&v=3) format("woff2"),url(https://use.typekit.net/af/fd93b1/00000000000000000000d755/27/d?subset_id=2&fvd=n5&v=3) format("woff"),url(https://use.typekit.net/af/fd93b1/00000000000000000000d755/27/a?subset_id=2&fvd=n5&v=3) format("opentype");font-weight:500;font-style:normal;}</style><link rel="stylesheet" type="text/css" href="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/shCore.css"><link rel="stylesheet" type="text/css" href="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/shThemeDefault.css"><style type="text/css"></style><link rel="stylesheet" type="text/css" id="gravatar-card-css" href="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/hovercard.min.css"><link rel="stylesheet" type="text/css" id="gravatar-card-services-css" href="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/services.min.css"></head>

<body class="post-template-default single single-post postid-8329 single-format-standard custom-background customizer-styles-applied group-blog highlander-enabled highlander-light custom-colors">

<div id="wrapper">
	<div id="page" class="hfeed site">
				<header id="masthead" class="site-header" role="banner">

			
			
			<hgroup>
				<h1 class="site-title"><a href="https://jeremykun.com/" title="Math ∩ Programming" rel="home">Math ∩ Programming</a></h1>
				<h2 class="site-description"></h2>
			</hgroup>

			<nav role="navigation" class="site-navigation main-navigation">
				<h1 class="assistive-text">Navigation</h1>
				<div class="assistive-text skip-link"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#content" title="Skip to content">Skip to content</a></div>

				<div class="menu"><ul>
<li><a href="https://jeremykun.com/">Home</a></li><li class="page_item page-item-374"><a href="https://jeremykun.com/main-content/">Main Content</a></li>
<li class="page_item page-item-150"><a href="https://jeremykun.com/primers/">Primers</a></li>
<li class="page_item page-item-3990"><a href="https://jeremykun.com/research/">Research</a></li>
<li class="page_item page-item-487"><a href="https://jeremykun.com/program-gallery/">Program Gallery</a></li>
<li class="page_item page-item-360"><a href="https://jeremykun.com/proof-gallery/">Proof Gallery</a></li>
<li class="page_item page-item-2"><a href="https://jeremykun.com/about/">About the Author</a></li>
<li class="page_item page-item-3215"><a href="https://jeremykun.com/support/">Support</a></li>
</ul></div>
			</nav><!-- .site-navigation .main-navigation -->
		</header><!-- #masthead .site-header -->

		<div id="main" class="site-main">

		<div id="primary" class="content-area">
			<div id="content" class="site-content" role="main">

			
					<nav role="navigation" id="nav-above" class="site-navigation post-navigation">
		<h1 class="assistive-text">Post navigation</h1>

	
		<div class="nav-previous"><a href="https://jeremykun.com/2016/04/25/book-mailing-list/" rel="prev"><span class="meta-nav">←</span> Book mailing list</a></div>		<div class="nav-next"><a href="https://jeremykun.com/2016/07/05/zero-knowledge-proofs-a-primer/" rel="next">Zero Knowledge Proofs — A Primer <span class="meta-nav">→</span></a></div>
	
	</nav><!-- #nav-above -->
	
				
<article id="post-8329" class="post-8329 post type-post status-publish format-standard hentry category-algorithms category-data-mining-2 category-linear-algebra category-optimization-2 category-statistics tag-greedy-algorithm tag-mathematics tag-optimization tag-programming tag-python tag-singular-value-decomposition">
	<header class="entry-header">
		<h1 class="entry-title">Singular Value Decomposition Part 2: Theorem, Proof, Algorithm</h1>

		<div class="entry-meta">
		Posted on <a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/" title="8:00 am" rel="bookmark"><time class="entry-date" datetime="2016-05-16T08:00:19-07:00" pubdate="">May 16, 2016</time></a><span class="byline"> by <span class="author vcard"><a class="url fn n" href="https://jeremykun.com/author/jeremykun/" title="View all posts by j2kun" rel="author">j2kun</a></span></span>		</div><!-- .entry-meta -->
	</header><!-- .entry-header -->

	<div class="entry-content">
		<p>I’m just going to jump right into the definitions and rigor, so if you haven’t read&nbsp;the previous post&nbsp;<a href="https://jeremykun.com/2016/04/18/singular-value-decomposition-part-1-perspectives-on-linear-algebra/">motivating the singular value decomposition</a>, go back and do that first. This post will be theorem, proof, algorithm, data. The data set we test on is a thousand-story CNN news data set.&nbsp;All of the data, code, and examples used in&nbsp;this&nbsp;post is in a <a href="https://github.com/j2kun/svd">github repository</a>, as usual.</p>
<p>We start with the best-approximating <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex.php" alt="k" title="k" class="latex" width="9" height="11" srcset="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">-dimensional linear subspace.</p>
<p><strong>Definition:</strong>&nbsp;Let <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(1).php" alt="X = \{ x_1, \dots, x_m \}" title="X = \{ x_1, \dots, x_m \}" class="latex" width="125" height="17" srcset="https://s0.wp.com/latex.php?latex=X+%3D+%5C%7B+x_1%2C+%5Cdots%2C+x_m+%5C%7D&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> be a set of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(2).php" alt="m" title="m" class="latex" width="14" height="7" srcset="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> points in <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(3).php" alt="\mathbb{R}^n" title="\mathbb{R}^n" class="latex" width="19" height="11" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5En&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. The <em>best approximating <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex.php" alt="k" title="k" class="latex" width="9" height="11" srcset="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">-dimensional linear subspace</em> of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(4).php" alt="X" title="X" class="latex" width="14" height="11" srcset="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is the <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex.php" alt="k" title="k" class="latex" width="9" height="11" srcset="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">-dimensional&nbsp;linear subspace <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(5).php" alt="V \subset \mathbb{R}^n" title="V \subset \mathbb{R}^n" class="latex" width="54" height="12" srcset="https://s0.wp.com/latex.php?latex=V+%5Csubset+%5Cmathbb%7BR%7D%5En&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> which minimizes the sum of the squared distances from the points in <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(4).php" alt="X" title="X" class="latex" width="14" height="11" srcset="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> to <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(6).php" alt="V" title="V" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">.</p>
<p>Let me clarify what I mean by minimizing the sum of squared distances. First we’ll start with the simple case: we have&nbsp;a vector <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(7).php" alt="x \in X" title="x \in X" class="latex" width="43" height="12" srcset="https://s0.wp.com/latex.php?latex=x+%5Cin+X&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, and a candidate line <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(8).php" alt="L" title="L" class="latex" width="11" height="11" srcset="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> (a 1-dimensional subspace) that is the span of a unit vector&nbsp;<img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(9).php" alt="v" title="v" class="latex" width="8" height="7" srcset="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. The <em>squared&nbsp;distance</em> from <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(10).php" alt="x" title="x" class="latex" width="9" height="7" srcset="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> to the line spanned by <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(9).php" alt="v" title="v" class="latex" width="8" height="7" srcset="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is the squared length of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(10).php" alt="x" title="x" class="latex" width="9" height="7" srcset="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> minus the squared length of the projection of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(10).php" alt="x" title="x" class="latex" width="9" height="7" srcset="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> onto <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(9).php" alt="v" title="v" class="latex" width="8" height="7" srcset="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. Here’s a picture.</p>
<p><a href="https://jeremykun.com/2016/04/18/singular-value-decomposition-part-1-perspectives-on-linear-algebra/vectormax/#main" rel="attachment wp-att-8290" class="single-image-gallery"><img data-attachment-id="8290" data-permalink="https://jeremykun.com/2016/04/18/singular-value-decomposition-part-1-perspectives-on-linear-algebra/vectormax/#main" data-orig-file="https://jeremykun.files.wordpress.com/2016/02/vectormax.png" data-orig-size="415,230" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="vectormax" data-image-description="" data-medium-file="https://jeremykun.files.wordpress.com/2016/02/vectormax.png?w=300" data-large-file="https://jeremykun.files.wordpress.com/2016/02/vectormax.png?w=415" class="aligncenter size-full wp-image-8290" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/vectormax.png" alt="vectormax" srcset="https://jeremykun.files.wordpress.com/2016/02/vectormax.png 415w, https://jeremykun.files.wordpress.com/2016/02/vectormax.png?w=150 150w, https://jeremykun.files.wordpress.com/2016/02/vectormax.png?w=300 300w" sizes="(max-width: 415px) 100vw, 415px"></a></p>
<p>I’m saying that the pink vector <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(11).php" alt="z" title="z" class="latex" width="8" height="7" srcset="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> in the picture is the difference of the black and green vectors <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(12).php" alt="x-y" title="x-y" class="latex" width="37" height="10" srcset="https://s0.wp.com/latex.php?latex=x-y&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, and that the “distance” from <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(10).php" alt="x" title="x" class="latex" width="9" height="7" srcset="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> to <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(9).php" alt="v" title="v" class="latex" width="8" height="7" srcset="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is the length of the pink vector. The reason is just the Pythagorean theorem: the vector <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(10).php" alt="x" title="x" class="latex" width="9" height="7" srcset="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is the hypotenuse of a right triangle whose&nbsp;other two sides are the projected vector <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(13).php" alt="y" title="y" class="latex" width="8" height="10" srcset="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> and the difference vector <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(11).php" alt="z" title="z" class="latex" width="8" height="7" srcset="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">.</p>
<p>Let’s throw down some notation. I’ll call <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(14).php" alt="\textup{proj}_v: \mathbb{R}^n \to \mathbb{R}^n" title="\textup{proj}_v: \mathbb{R}^n \to \mathbb{R}^n" class="latex" width="115" height="16" srcset="https://s0.wp.com/latex.php?latex=%5Ctextup%7Bproj%7D_v%3A+%5Cmathbb%7BR%7D%5En+%5Cto+%5Cmathbb%7BR%7D%5En&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> the linear&nbsp;map that takes as input a vector <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(10).php" alt="x" title="x" class="latex" width="9" height="7" srcset="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> and produces as output the projection of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(10).php" alt="x" title="x" class="latex" width="9" height="7" srcset="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> onto <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(9).php" alt="v" title="v" class="latex" width="8" height="7" srcset="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. In fact we have a brief formula for this when <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(9).php" alt="v" title="v" class="latex" width="8" height="7" srcset="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is a unit vector. If we call <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(15).php" alt="x \cdot v" title="x \cdot v" class="latex" width="29" height="7" srcset="https://s0.wp.com/latex.php?latex=x+%5Ccdot+v&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> the usual dot product, then <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(16).php" alt="\textup{proj}_v(x) = (x \cdot v)v" title="\textup{proj}_v(x) = (x \cdot v)v" class="latex" width="130" height="18" srcset="https://s0.wp.com/latex.php?latex=%5Ctextup%7Bproj%7D_v%28x%29+%3D+%28x+%5Ccdot+v%29v&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. That’s <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(9).php" alt="v" title="v" class="latex" width="8" height="7" srcset="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> scaled by the inner product of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(10).php" alt="x" title="x" class="latex" width="9" height="7" srcset="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> and <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(9).php" alt="v" title="v" class="latex" width="8" height="7" srcset="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. In the picture above, since the line <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(8).php" alt="L" title="L" class="latex" width="11" height="11" srcset="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is the span of the vector <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(9).php" alt="v" title="v" class="latex" width="8" height="7" srcset="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, that means that <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(17).php" alt="y = \textup{proj}_v(x)" title="y = \textup{proj}_v(x)" class="latex" width="87" height="18" srcset="https://s0.wp.com/latex.php?latex=y+%3D+%5Ctextup%7Bproj%7D_v%28x%29&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> and <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(18).php" alt="z = x -\textup{proj}_v(x) = x-y" title="z = x -\textup{proj}_v(x) = x-y" class="latex" width="177" height="18" srcset="https://s0.wp.com/latex.php?latex=z+%3D+x+-%5Ctextup%7Bproj%7D_v%28x%29+%3D+x-y&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">.</p>
<p>The dot-product formula is useful&nbsp;for us&nbsp;because it allows us to&nbsp;compute the squared length&nbsp;of the projection by taking a dot product <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(19).php" alt="|x \cdot v|^2" title="|x \cdot v|^2" class="latex" width="44" height="18" srcset="https://s0.wp.com/latex.php?latex=%7Cx+%5Ccdot+v%7C%5E2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. So then a formula for the distance of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(10).php" alt="x" title="x" class="latex" width="9" height="7" srcset="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> from the line spanned by the unit vector <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(9).php" alt="v" title="v" class="latex" width="8" height="7" srcset="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is</p>
<p style="text-align:center;"><img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(20).php" alt="\displaystyle (\textup{dist}_v(x))^2 = \left ( \sum_{i=1}^n x_i^2 \right ) - |x \cdot v|^2" title="\displaystyle (\textup{dist}_v(x))^2 = \left ( \sum_{i=1}^n x_i^2 \right ) - |x \cdot v|^2" class="latex" width="229" height="51" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%28%5Ctextup%7Bdist%7D_v%28x%29%29%5E2+%3D+%5Cleft+%28+%5Csum_%7Bi%3D1%7D%5En+x_i%5E2+%5Cright+%29+-+%7Cx+%5Ccdot+v%7C%5E2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"></p>
<p>This formula is just a restatement of the Pythagorean theorem for perpendicular vectors.</p>
<p style="text-align:center;"><img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(21).php" alt="\displaystyle \sum_{i} x_i^2 = (\textup{proj}_v(x))^2 + (\textup{dist}_v(x))^2" title="\displaystyle \sum_{i} x_i^2 = (\textup{proj}_v(x))^2 + (\textup{dist}_v(x))^2" class="latex" width="234" height="35" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csum_%7Bi%7D+x_i%5E2+%3D+%28%5Ctextup%7Bproj%7D_v%28x%29%29%5E2+%2B+%28%5Ctextup%7Bdist%7D_v%28x%29%29%5E2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"></p>
<p>In particular, the difference vector we originally called <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(11).php" alt="z" title="z" class="latex" width="8" height="7" srcset="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> has squared length <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(22).php" alt="\textup{dist}_v(x)^2" title="\textup{dist}_v(x)^2" class="latex" width="60" height="18" srcset="https://s0.wp.com/latex.php?latex=%5Ctextup%7Bdist%7D_v%28x%29%5E2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. The vector <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(13).php" alt="y" title="y" class="latex" width="8" height="10" srcset="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, which is perpendicular to <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(11).php" alt="z" title="z" class="latex" width="8" height="7" srcset="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> and is also the projection of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(10).php" alt="x" title="x" class="latex" width="9" height="7" srcset="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> onto <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(8).php" alt="L" title="L" class="latex" width="11" height="11" srcset="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, it’s squared length is <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(23).php" alt="(\textup{proj}_v(x))^2" title="(\textup{proj}_v(x))^2" class="latex" width="75" height="18" srcset="https://s0.wp.com/latex.php?latex=%28%5Ctextup%7Bproj%7D_v%28x%29%29%5E2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. And the Pythagorean theorem tells us that summing those two squared lengths gives you the squared length of the hypotenuse <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(10).php" alt="x" title="x" class="latex" width="9" height="7" srcset="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">.</p>
<p style="text-align:left;">If we were trying to find the best approximating 1-dimensional subspace for a set of data points <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(4).php" alt="X" title="X" class="latex" width="14" height="11" srcset="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, then we’d want to minimize the sum of&nbsp;the squared distances for every point <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(7).php" alt="x \in X" title="x \in X" class="latex" width="43" height="12" srcset="https://s0.wp.com/latex.php?latex=x+%5Cin+X&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. Namely, we want the <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(9).php" alt="v" title="v" class="latex" width="8" height="7" srcset="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> that solves&nbsp;<img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(24).php" alt="\min_{|v|=1} \sum_{x \in X} (\textup{dist}_v(x))^2" title="\min_{|v|=1} \sum_{x \in X} (\textup{dist}_v(x))^2" class="latex" width="174" height="20" srcset="https://s0.wp.com/latex.php?latex=%5Cmin_%7B%7Cv%7C%3D1%7D+%5Csum_%7Bx+%5Cin+X%7D+%28%5Ctextup%7Bdist%7D_v%28x%29%29%5E2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">.</p>
<p style="text-align:left;">With some slight algebra we can make our life easier. The short version:&nbsp;minimizing&nbsp;the sum of squared&nbsp;distances is the same thing as&nbsp;<em>maximizing&nbsp;</em>the sum of squared lengths of the projections. The longer version: let’s go back to a single point <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(10).php" alt="x" title="x" class="latex" width="9" height="7" srcset="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> and the line spanned by <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(9).php" alt="v" title="v" class="latex" width="8" height="7" srcset="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">.&nbsp;The Pythagorean theorem told us that</p>
<p style="text-align:center;"><img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(21).php" alt="\displaystyle \sum_{i} x_i^2 = (\textup{proj}_v(x))^2 + (\textup{dist}_v(x))^2" title="\displaystyle \sum_{i} x_i^2 = (\textup{proj}_v(x))^2 + (\textup{dist}_v(x))^2" class="latex" width="234" height="35" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csum_%7Bi%7D+x_i%5E2+%3D+%28%5Ctextup%7Bproj%7D_v%28x%29%29%5E2+%2B+%28%5Ctextup%7Bdist%7D_v%28x%29%29%5E2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"></p>
<p style="text-align:left;">The&nbsp;squared length of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(10).php" alt="x" title="x" class="latex" width="9" height="7" srcset="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is constant. It’s an input&nbsp;to the algorithm and it doesn’t change through a run of the algorithm. So&nbsp;we get the squared distance by subtracting <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(23).php" alt="(\textup{proj}_v(x))^2" title="(\textup{proj}_v(x))^2" class="latex" width="75" height="18" srcset="https://s0.wp.com/latex.php?latex=%28%5Ctextup%7Bproj%7D_v%28x%29%29%5E2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> from a constant number,</p>
<p style="text-align:center;"><img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(25).php" alt="\displaystyle \sum_{i} x_i^2 - (\textup{proj}_v(x))^2 = (\textup{dist}_v(x))^2" title="\displaystyle \sum_{i} x_i^2 - (\textup{proj}_v(x))^2 = (\textup{dist}_v(x))^2" class="latex" width="235" height="35" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csum_%7Bi%7D+x_i%5E2+-+%28%5Ctextup%7Bproj%7D_v%28x%29%29%5E2+%3D%C2%A0%28%5Ctextup%7Bdist%7D_v%28x%29%29%5E2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"></p>
<p style="text-align:left;">which means if we want to <em>minimize</em> the squared distance, we can instead&nbsp;<em>maximize</em> the squared projection. Maximizing the subtracted thing minimizes the whole expression.</p>
<p style="text-align:left;">It works the same way if you’re&nbsp;summing over all the&nbsp;data points in <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(4).php" alt="X" title="X" class="latex" width="14" height="11" srcset="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. In fact, we can say it much more compactly this way. If the rows of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(26).php" alt="A" title="A" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> are your data points, then <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(27).php" alt="Av" title="Av" class="latex" width="20" height="11" srcset="https://s0.wp.com/latex.php?latex=Av&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> contains as each entry the (signed) dot products <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(28).php" alt="x_i \cdot v" title="x_i \cdot v" class="latex" width="34" height="10" srcset="https://s0.wp.com/latex.php?latex=x_i+%5Ccdot+v&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. And the squared norm of this vector, <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(29).php" alt="|Av|^2" title="|Av|^2" class="latex" width="35" height="18" srcset="https://s0.wp.com/latex.php?latex=%7CAv%7C%5E2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, is exactly the sum of the squared lengths of the projections of the data onto the line spanned by <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(9).php" alt="v" title="v" class="latex" width="8" height="7" srcset="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. The last thing is that maximizing a square is the same as maximizing&nbsp;its square root, so we can switch freely between saying our objective is to find the&nbsp;unit vector&nbsp;<img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(9).php" alt="v" title="v" class="latex" width="8" height="7" srcset="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> that maximizes <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(30).php" alt="|Av|" title="|Av|" class="latex" width="27" height="17" srcset="https://s0.wp.com/latex.php?latex=%7CAv%7C&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> and that which maximizes <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(29).php" alt="|Av|^2" title="|Av|^2" class="latex" width="35" height="18" srcset="https://s0.wp.com/latex.php?latex=%7CAv%7C%5E2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">.</p>
<p style="text-align:left;">At this point you should be thinking,</p>
<blockquote>
<p style="text-align:left;">Great, we have written down an optimization problem: <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(31).php" alt="\max_{v : |v|=1} |Av|" title="\max_{v : |v|=1} |Av|" class="latex" width="99" height="19" srcset="https://s0.wp.com/latex.php?latex=%5Cmax_%7Bv+%3A+%7Cv%7C%3D1%7D+%7CAv%7C&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. If we could solve this, we’d have the best 1-dimensional linear approximation to the data contained in the rows of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(26).php" alt="A" title="A" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. But (1) how do we solve that problem? And (2) you&nbsp;promised&nbsp;a <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex.php" alt="k" title="k" class="latex" width="9" height="11" srcset="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">-dimensional approximating subspace. I feel betrayed! Swindled! Bamboozled!</p>
</blockquote>
<p style="text-align:left;">Here’s the fantastic thing.&nbsp;We can solve the 1-dimensional optimization problem efficiently (we’ll do it later in this post), and&nbsp;(2) is&nbsp;answered by the following theorem.</p>
<p style="text-align:left;"><strong>The SVD Theorem:</strong> Computing the best <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex.php" alt="k" title="k" class="latex" width="9" height="11" srcset="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">-dimensional subspace reduces to <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex.php" alt="k" title="k" class="latex" width="9" height="11" srcset="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> applications of the&nbsp;one-dimensional problem.</p>
<p>We will prove this after we&nbsp;introduce the terms “singular value” and “singular vector.”</p>
<h2 style="text-align:center;">Singular values and vectors</h2>
<p>As I just said, we can get the best <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex.php" alt="k" title="k" class="latex" width="9" height="11" srcset="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">-dimensional approximating linear subspace by&nbsp;solving the one-dimensional maximization problem <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex.php" alt="k" title="k" class="latex" width="9" height="11" srcset="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> times. The&nbsp;<em>singular vectors&nbsp;</em>of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(26).php" alt="A" title="A" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> are defined recursively as the solutions to these&nbsp;sub-problems. That is, I’ll call <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(32).php" alt="v_1" title="v_1" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> the&nbsp;<em>first singular vector</em>&nbsp;of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(26).php" alt="A" title="A" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, and it is:</p>
<p style="text-align:center;"><img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(33).php" alt="\displaystyle v_1 = \arg \max_{v, |v|=1} |Av|" title="\displaystyle v_1 = \arg \max_{v, |v|=1} |Av|" class="latex" width="130" height="27" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+v_1+%3D+%5Carg+%5Cmax_%7Bv%2C+%7Cv%7C%3D1%7D+%7CAv%7C&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"></p>
<p style="text-align:left;">And the corresponding <em>first&nbsp;singular value, </em>denoted <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(34).php" alt="\sigma_1(A)" title="\sigma_1(A)" class="latex" width="39" height="18" srcset="https://s0.wp.com/latex.php?latex=%5Csigma_1%28A%29&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, is the maximal value of the optimization objective, i.e. <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(35).php" alt="|Av_1|" title="|Av_1|" class="latex" width="33" height="17" srcset="https://s0.wp.com/latex.php?latex=%7CAv_1%7C&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. (I will use this term frequently, that <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(30).php" alt="|Av|" title="|Av|" class="latex" width="27" height="17" srcset="https://s0.wp.com/latex.php?latex=%7CAv%7C&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is the “objective” of the optimization problem.) Informally speaking, <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(36).php" alt="(\sigma_1(A))^2" title="(\sigma_1(A))^2" class="latex" width="57" height="18" srcset="https://s0.wp.com/latex.php?latex=%28%5Csigma_1%28A%29%29%5E2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> represents how much of the data was captured by the first singular vector. Meaning, how close the vectors are to lying on the line spanned by&nbsp;<img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(32).php" alt="v_1" title="v_1" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. Larger values imply&nbsp;the approximation is better. In fact, if all the data points lie on a line, then&nbsp;<img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(36).php" alt="(\sigma_1(A))^2" title="(\sigma_1(A))^2" class="latex" width="57" height="18" srcset="https://s0.wp.com/latex.php?latex=%28%5Csigma_1%28A%29%29%5E2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is&nbsp;the sum of&nbsp;the squared norms of the rows of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(26).php" alt="A" title="A" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">.</p>
<p style="text-align:left;">Now here is where we see the reduction from the <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex.php" alt="k" title="k" class="latex" width="9" height="11" srcset="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">-dimensional case to the 1-dimensional case. To find the best 2-dimensional subspace, you first find the best one-dimensional subspace (spanned by <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(32).php" alt="v_1" title="v_1" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">), and then find the best 1-dimensional subspace, but&nbsp;<em>only</em> considering those subspaces that are the spans of unit vectors perpendicular to <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(32).php" alt="v_1" title="v_1" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. The notation for “vectors <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(9).php" alt="v" title="v" class="latex" width="8" height="7" srcset="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> perpendicular to <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(32).php" alt="v_1" title="v_1" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">” is <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(37).php" alt="v \perp v_1" title="v \perp v_1" class="latex" width="44" height="16" srcset="https://s0.wp.com/latex.php?latex=v+%5Cperp+v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. Restating,&nbsp;the second singular vector <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(38).php" alt="v _2" title="v _2" class="latex" width="14" height="10" srcset="https://s0.wp.com/latex.php?latex=v+_2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">&nbsp;is defined as</p>
<p style="text-align:center;"><img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(39).php" alt="\displaystyle v_2 = \arg \max_{v \perp v_1, |v| = 1} |Av|" title="\displaystyle v_2 = \arg \max_{v \perp v_1, |v| = 1} |Av|" class="latex" width="151" height="27" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+v_2+%3D+%5Carg+%5Cmax_%7Bv+%5Cperp+v_1%2C+%7Cv%7C+%3D+1%7D+%7CAv%7C&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"></p>
<p style="text-align:left;">And the SVD theorem implies&nbsp;the subspace spanned by <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(40).php" alt="\{ v_1, v_2 \}" title="\{ v_1, v_2 \}" class="latex" width="51" height="17" srcset="https://s0.wp.com/latex.php?latex=%5C%7B+v_1%2C+v_2+%5C%7D&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is the best 2-dimensional linear approximation to the data. Likewise <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(41).php" alt="\sigma_2(A) = |Av_2|" title="\sigma_2(A) = |Av_2|" class="latex" width="97" height="18" srcset="https://s0.wp.com/latex.php?latex=%5Csigma_2%28A%29+%3D+%7CAv_2%7C&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is the second singular value. Its squared magnitude tells us how much of the data that was not “captured” by <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(32).php" alt="v_1" title="v_1" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is captured by <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(42).php" alt="v_2" title="v_2" class="latex" width="14" height="10" srcset="https://s0.wp.com/latex.php?latex=v_2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. Again, if the data lies in a 2-dimensional subspace, then the span of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(40).php" alt="\{ v_1, v_2 \}" title="\{ v_1, v_2 \}" class="latex" width="51" height="17" srcset="https://s0.wp.com/latex.php?latex=%5C%7B+v_1%2C+v_2+%5C%7D&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> will be that subspace.</p>
<p style="text-align:left;">We can continue this process. Recursively define <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(43).php" alt="v_k" title="v_k" class="latex" width="14" height="10" srcset="https://s0.wp.com/latex.php?latex=v_k&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, the <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex.php" alt="k" title="k" class="latex" width="9" height="11" srcset="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">-th singular vector, to be the vector which maximizes <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(30).php" alt="|Av|" title="|Av|" class="latex" width="27" height="17" srcset="https://s0.wp.com/latex.php?latex=%7CAv%7C&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, when <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(9).php" alt="v" title="v" class="latex" width="8" height="7" srcset="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is considered&nbsp;only among&nbsp;the unit vectors which are perpendicular to <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(44).php" alt="\textup{span} \{ v_1, \dots, v_{k-1} \}" title="\textup{span} \{ v_1, \dots, v_{k-1} \}" class="latex" width="130" height="17" srcset="https://s0.wp.com/latex.php?latex=%5Ctextup%7Bspan%7D+%5C%7B+v_1%2C+%5Cdots%2C+v_%7Bk-1%7D+%5C%7D&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. The corresponding singular value <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(45).php" alt="\sigma_k(A)" title="\sigma_k(A)" class="latex" width="39" height="18" srcset="https://s0.wp.com/latex.php?latex=%5Csigma_k%28A%29&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is the value of the optimization problem.</p>
<p style="text-align:left;">As a side note, because&nbsp;of the way we defined&nbsp;the singular values as&nbsp;the objective values of “nested” optimization problems, the singular values&nbsp;are decreasing, <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(46).php" alt="\sigma_1(A) \geq \sigma_2(A) \geq \dots \geq \sigma_n(A) \geq 0" title="\sigma_1(A) \geq \sigma_2(A) \geq \dots \geq \sigma_n(A) \geq 0" class="latex" width="239" height="18" srcset="https://s0.wp.com/latex.php?latex=%5Csigma_1%28A%29+%5Cgeq+%5Csigma_2%28A%29+%5Cgeq+%5Cdots+%5Cgeq+%5Csigma_n%28A%29+%5Cgeq+0&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. This is obvious:&nbsp;you only pick <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(42).php" alt="v_2" title="v_2" class="latex" width="14" height="10" srcset="https://s0.wp.com/latex.php?latex=v_2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> in the second optimization problem because you already picked <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(32).php" alt="v_1" title="v_1" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> which&nbsp;gave a bigger singular value, so <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(42).php" alt="v_2" title="v_2" class="latex" width="14" height="10" srcset="https://s0.wp.com/latex.php?latex=v_2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">‘s&nbsp;objective&nbsp;can’t be bigger.</p>
<p style="text-align:left;">If you keep doing this,&nbsp;one of two things happen. Either you reach <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(47).php" alt="v_n" title="v_n" class="latex" width="15" height="10" srcset="https://s0.wp.com/latex.php?latex=v_n&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> and since the domain&nbsp;is <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(48).php" alt="n" title="n" class="latex" width="10" height="7" srcset="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">-dimensional there are&nbsp;no remaining vectors to choose from, the <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(49).php" alt="v_i" title="v_i" class="latex" width="12" height="10" srcset="https://s0.wp.com/latex.php?latex=v_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">&nbsp;are an orthonormal&nbsp;basis of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(3).php" alt="\mathbb{R}^n" title="\mathbb{R}^n" class="latex" width="19" height="11" srcset="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5En&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. This means that the data in <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(26).php" alt="A" title="A" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> contains a full-rank submatrix. The data does not lie in any smaller-dimensional subspace. This is what you’d expect from real data.</p>
<p style="text-align:left;">Alternatively,&nbsp;you could&nbsp;get to a stage&nbsp;<img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(43).php" alt="v_k" title="v_k" class="latex" width="14" height="10" srcset="https://s0.wp.com/latex.php?latex=v_k&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> with <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(50).php" alt="k &lt; n" title="k &lt; n" class="latex" width="41" height="11" srcset="https://s0.wp.com/latex.php?latex=k+%3C+n&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> and when you try to solve the optimization problem you find that every perpendicular <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(9).php" alt="v" title="v" class="latex" width="8" height="7" srcset="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> has <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(51).php" alt="Av = 0" title="Av = 0" class="latex" width="50" height="12" srcset="https://s0.wp.com/latex.php?latex=Av+%3D+0&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. In this case, the data actually does lie in a <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex.php" alt="k" title="k" class="latex" width="9" height="11" srcset="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">-dimensional subspace, and the first-through-<img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex.php" alt="k" title="k" class="latex" width="9" height="11" srcset="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">-th singular vectors you computed span this subspace.</p>
<p style="text-align:left;">Let’s do a quick sanity check: how do we know that the&nbsp;singular vectors <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(49).php" alt="v_i" title="v_i" class="latex" width="12" height="10" srcset="https://s0.wp.com/latex.php?latex=v_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> form a basis? Well formally they only span a basis of the&nbsp;<em><a href="https://en.wikipedia.org/wiki/Rank%E2%80%93nullity_theorem">row space</a></em> of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(26).php" alt="A" title="A" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, i.e. a basis of the subspace spanned by the data contained in the rows&nbsp;of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(26).php" alt="A" title="A" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">.&nbsp;But either way the point is that each <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(52).php" alt="v_{i+1}" title="v_{i+1}" class="latex" width="26" height="11" srcset="https://s0.wp.com/latex.php?latex=v_%7Bi%2B1%7D&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> spans a new dimension from the previous <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(53).php" alt="v_1, \dots, v_i" title="v_1, \dots, v_i" class="latex" width="63" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1%2C+%5Cdots%2C+v_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> because we’re choosing <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(52).php" alt="v_{i+1}" title="v_{i+1}" class="latex" width="26" height="11" srcset="https://s0.wp.com/latex.php?latex=v_%7Bi%2B1%7D&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> to be orthogonal to&nbsp;all the previous <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(49).php" alt="v_i" title="v_i" class="latex" width="12" height="10" srcset="https://s0.wp.com/latex.php?latex=v_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">.&nbsp;So the answer to our sanity check is “by construction.”</p>
<p style="text-align:left;">Back to the singular vectors, the discussion from the&nbsp;last&nbsp;post tells us intuitively that&nbsp;the data is probably never&nbsp;in a small subspace. &nbsp;You never expect the process of finding singular vectors to stop before step <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(48).php" alt="n" title="n" class="latex" width="10" height="7" srcset="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, and if it does you take a step back and ask if something deeper is going on. Instead, in real life&nbsp;you specify how much of the data you want to capture, and you keep computing singular vectors until you’ve passed the threshold. Alternatively, you specify the amount of computing resources you’d like to spend by fixing the&nbsp;number of singular vectors you’ll compute ahead of time, and settle for however good the <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex.php" alt="k" title="k" class="latex" width="9" height="11" srcset="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">-dimensional approximation is.</p>
<p style="text-align:left;">Before we get into any code or solve the 1-dimensional optimization problem, let’s prove the SVD theorem.</p>
<p style="text-align:left;"><em>Proof of SVD theorem.</em></p>
<p style="text-align:left;">Recall we’re trying to prove that the first <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex.php" alt="k" title="k" class="latex" width="9" height="11" srcset="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> singular vectors provide a&nbsp;linear subspace <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(54).php" alt="W" title="W" class="latex" width="18" height="11" srcset="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> which maximizes the squared-sum of the projections of the data onto <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(54).php" alt="W" title="W" class="latex" width="18" height="11" srcset="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. For <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(55).php" alt="k=1" title="k=1" class="latex" width="38" height="13" srcset="https://s0.wp.com/latex.php?latex=k%3D1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> this is trivial, because we defined <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(32).php" alt="v_1" title="v_1" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> to be the solution to that optimization problem. The case&nbsp;of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(56).php" alt="k=2" title="k=2" class="latex" width="39" height="12" srcset="https://s0.wp.com/latex.php?latex=k%3D2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> contains all the important features of the general inductive step. Let <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(54).php" alt="W" title="W" class="latex" width="18" height="11" srcset="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> be&nbsp;<em>any</em>&nbsp;best-approximating 2-dimensional linear subspace for the rows of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(26).php" alt="A" title="A" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. We’ll show that the subspace spanned by the two singular&nbsp;vectors <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(57).php" alt="v_1, v_2" title="v_1, v_2" class="latex" width="36" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1%2C+v_2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is at least as good (and hence equally good).</p>
<p style="text-align:left;">Let <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(58).php" alt="w_1, w_2" title="w_1, w_2" class="latex" width="43" height="11" srcset="https://s0.wp.com/latex.php?latex=w_1%2C+w_2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> be any orthonormal basis for <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(54).php" alt="W" title="W" class="latex" width="18" height="11" srcset="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> and let <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(59).php" alt="|Aw_1|^2 + |Aw_2|^2" title="|Aw_1|^2 + |Aw_2|^2" class="latex" width="111" height="18" srcset="https://s0.wp.com/latex.php?latex=%7CAw_1%7C%5E2+%2B+%7CAw_2%7C%5E2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> be the quantity that we’re trying to maximize (and which <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(54).php" alt="W" title="W" class="latex" width="18" height="11" srcset="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> maximizes by assumption). Moreover,&nbsp;we can pick&nbsp;the basis vector <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(60).php" alt="w_2" title="w_2" class="latex" width="18" height="10" srcset="https://s0.wp.com/latex.php?latex=w_2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">&nbsp;to be perpendicular to <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(32).php" alt="v_1" title="v_1" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">.&nbsp;To prove this we consider two cases: either <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(32).php" alt="v_1" title="v_1" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is already perpendicular to <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(54).php" alt="W" title="W" class="latex" width="18" height="11" srcset="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> in which case&nbsp;it’s trivial, or else <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(32).php" alt="v_1" title="v_1" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> isn’t perpendicular to <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(54).php" alt="W" title="W" class="latex" width="18" height="11" srcset="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> and you can choose <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(61).php" alt="w_1" title="w_1" class="latex" width="17" height="11" srcset="https://s0.wp.com/latex.php?latex=w_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> to be <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(62).php" alt="\textup{proj}_W(v_1)" title="\textup{proj}_W(v_1)" class="latex" width="68" height="18" srcset="https://s0.wp.com/latex.php?latex=%5Ctextup%7Bproj%7D_W%28v_1%29&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> and choose <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(60).php" alt="w_2" title="w_2" class="latex" width="18" height="10" srcset="https://s0.wp.com/latex.php?latex=w_2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> to be any unit vector perpendicular to <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(61).php" alt="w_1" title="w_1" class="latex" width="17" height="11" srcset="https://s0.wp.com/latex.php?latex=w_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">.</p>
<p style="text-align:left;">Now since <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(32).php" alt="v_1" title="v_1" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> maximizes <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(30).php" alt="|Av|" title="|Av|" class="latex" width="27" height="17" srcset="https://s0.wp.com/latex.php?latex=%7CAv%7C&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, we have <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(63).php" alt="|Av_1|^2 \geq |Aw_1|^2" title="|Av_1|^2 \geq |Aw_1|^2" class="latex" width="110" height="18" srcset="https://s0.wp.com/latex.php?latex=%7CAv_1%7C%5E2+%5Cgeq+%7CAw_1%7C%5E2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. Moreover, since <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(60).php" alt="w_2" title="w_2" class="latex" width="18" height="10" srcset="https://s0.wp.com/latex.php?latex=w_2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is perpendicular to <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(32).php" alt="v_1" title="v_1" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, the way we chose <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(42).php" alt="v_2" title="v_2" class="latex" width="14" height="10" srcset="https://s0.wp.com/latex.php?latex=v_2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> also makes <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(64).php" alt="|Av_2|^2 \geq |Aw_2|^2" title="|Av_2|^2 \geq |Aw_2|^2" class="latex" width="110" height="18" srcset="https://s0.wp.com/latex.php?latex=%7CAv_2%7C%5E2+%5Cgeq+%7CAw_2%7C%5E2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. Hence the objective <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(65).php" alt="|Av_1|^2 + |Av_2|^2 \geq |Aw_1|^2 + |Aw_2|^2" title="|Av_1|^2 + |Av_2|^2 \geq |Aw_1|^2 + |Aw_2|^2" class="latex" width="238" height="18" srcset="https://s0.wp.com/latex.php?latex=%7CAv_1%7C%5E2+%2B+%7CAv_2%7C%5E2+%5Cgeq+%7CAw_1%7C%5E2+%2B+%7CAw_2%7C%5E2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, as desired.</p>
<p style="text-align:left;">For the general case of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex.php" alt="k" title="k" class="latex" width="9" height="11" srcset="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">,&nbsp;the inductive hypothesis&nbsp;tells us that the first <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex.php" alt="k" title="k" class="latex" width="9" height="11" srcset="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> terms of the objective for <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(66).php" alt="k+1" title="k+1" class="latex" width="36" height="13" srcset="https://s0.wp.com/latex.php?latex=k%2B1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> singular vectors is maximized, and we just have to pick any vector <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(67).php" alt="w_{k+1}" title="w_{k+1}" class="latex" width="32" height="11" srcset="https://s0.wp.com/latex.php?latex=w_%7Bk%2B1%7D&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> that is perpendicular to all <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(68).php" alt="v_1, v_2, \dots, v_k" title="v_1, v_2, \dots, v_k" class="latex" width="87" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1%2C+v_2%2C+%5Cdots%2C+v_k&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, and the rest of the proof is just like the 2-dimensional case.</p>
<p style="text-align:right;"><img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(69).php" alt="\square" title="\square" class="latex" width="11" height="12" srcset="https://s0.wp.com/latex.php?latex=%5Csquare&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"></p>
<p style="text-align:left;">Now remember that in the last&nbsp;post we started with&nbsp;the definition of the SVD&nbsp;as&nbsp;a decomposition of a matrix <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(70).php" alt="A = U\Sigma V^T" title="A = U\Sigma V^T" class="latex" width="81" height="14" srcset="https://s0.wp.com/latex.php?latex=A+%3D+U%5CSigma+V%5ET&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">? And then we said that this is a certain kind of change of basis? Well&nbsp;the&nbsp;singular vectors <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(49).php" alt="v_i" title="v_i" class="latex" width="12" height="10" srcset="https://s0.wp.com/latex.php?latex=v_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> together form&nbsp;the columns of the&nbsp;matrix <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(6).php" alt="V" title="V" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> (the rows of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(71).php" alt="V^T" title="V^T" class="latex" width="22" height="14" srcset="https://s0.wp.com/latex.php?latex=V%5ET&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">), and the corresponding singular values <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(72).php" alt="\sigma_i(A)" title="\sigma_i(A)" class="latex" width="37" height="18" srcset="https://s0.wp.com/latex.php?latex=%5Csigma_i%28A%29&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> are the diagonal entries of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(73).php" alt="\Sigma" title="\Sigma" class="latex" width="11" height="11" srcset="https://s0.wp.com/latex.php?latex=%5CSigma&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. When <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(26).php" alt="A" title="A" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is understood we’ll abbreviate the singular value as <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(74).php" alt="\sigma_i" title="\sigma_i" class="latex" width="13" height="10" srcset="https://s0.wp.com/latex.php?latex=%5Csigma_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">.</p>
<p style="text-align:left;">To reiterate with the thoughts from&nbsp;<a href="https://jeremykun.com/2016/04/18/singular-value-decomposition-part-1-perspectives-on-linear-algebra/">last&nbsp;post</a>, the process of applying <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(26).php" alt="A" title="A" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is exactly recovered by the process of&nbsp;first projecting onto the (full-rank space of) singular vectors <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(75).php" alt="v_1, \dots, v_k" title="v_1, \dots, v_k" class="latex" width="65" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1%2C+%5Cdots%2C+v_k&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, scaling each coordinate of that projection according to the corresponding singular values, and then applying this <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(76).php" alt="U" title="U" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> thing we haven’t talked about yet.</p>
<p style="text-align:left;">So let’s&nbsp;determine what <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(76).php" alt="U" title="U" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> has to be.&nbsp;The way we picked <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(49).php" alt="v_i" title="v_i" class="latex" width="12" height="10" srcset="https://s0.wp.com/latex.php?latex=v_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> to make <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(26).php" alt="A" title="A" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> diagonal gives us an immediate suggestion: use the <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(77).php" alt="Av_i" title="Av_i" class="latex" width="24" height="14" srcset="https://s0.wp.com/latex.php?latex=Av_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> as the columns of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(76).php" alt="U" title="U" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. Indeed, define <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(78).php" alt="u_i = Av_i" title="u_i = Av_i" class="latex" width="60" height="14" srcset="https://s0.wp.com/latex.php?latex=u_i+%3D+Av_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, the images of the singular vectors under <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(26).php" alt="A" title="A" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. We can swiftly show&nbsp;the <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(79).php" alt="u_i" title="u_i" class="latex" width="13" height="10" srcset="https://s0.wp.com/latex.php?latex=u_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> form a basis of the image of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(26).php" alt="A" title="A" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. The reason is because if <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(80).php" alt="v = \sum_i c_i v_i" title="v = \sum_i c_i v_i" class="latex" width="79" height="17" srcset="https://s0.wp.com/latex.php?latex=v+%3D+%5Csum_i+c_i+v_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> (using all <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(48).php" alt="n" title="n" class="latex" width="10" height="7" srcset="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> of the singular vectors <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(49).php" alt="v_i" title="v_i" class="latex" width="12" height="10" srcset="https://s0.wp.com/latex.php?latex=v_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">), then by linearity <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(81).php" alt="Av = \sum_{i} c_i Av_i = \sum_i c_i u_i" title="Av = \sum_{i} c_i Av_i = \sum_i c_i u_i" class="latex" width="175" height="17" srcset="https://s0.wp.com/latex.php?latex=Av+%3D+%5Csum_%7Bi%7D+c_i+Av_i+%3D+%5Csum_i+c_i+u_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. It is also easy to see why the <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(79).php" alt="u_i" title="u_i" class="latex" width="13" height="10" srcset="https://s0.wp.com/latex.php?latex=u_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> are orthogonal (prove it as an exercise). Let’s further make sure the <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(79).php" alt="u_i" title="u_i" class="latex" width="13" height="10" srcset="https://s0.wp.com/latex.php?latex=u_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> are unit vectors and redefine them as <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(82).php" alt="u_i = \frac{1}{\sigma_i}Av_i" title="u_i = \frac{1}{\sigma_i}Av_i" class="latex" width="74" height="22" srcset="https://s0.wp.com/latex.php?latex=u_i+%3D+%5Cfrac%7B1%7D%7B%5Csigma_i%7DAv_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"></p>
<p style="text-align:left;">If you put these thoughts together, you can say exactly what <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(26).php" alt="A" title="A" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> does to any given vector <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(10).php" alt="x" title="x" class="latex" width="9" height="7" srcset="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. Since the <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(49).php" alt="v_i" title="v_i" class="latex" width="12" height="10" srcset="https://s0.wp.com/latex.php?latex=v_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> form an orthonormal basis, <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(83).php" alt="x = \sum_i (x \cdot v_i) v_i" title="x = \sum_i (x \cdot v_i) v_i" class="latex" width="111" height="19" srcset="https://s0.wp.com/latex.php?latex=x+%3D+%5Csum_i+%28x+%5Ccdot+v_i%29+v_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, and then applying <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(26).php" alt="A" title="A" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> gives</p>
<p style="text-align:center;"><img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(84).php" alt="\displaystyle \begin{aligned}Ax &amp;= A \left ( \sum_i (x \cdot v_i) v_i \right ) \\  &amp;= \sum_i (x \cdot v_i) A_i v_i \\ &amp;= \sum_i (x \cdot v_i) \sigma_i u_i \end{aligned}" title="\displaystyle \begin{aligned}Ax &amp;= A \left ( \sum_i (x \cdot v_i) v_i \right ) \\  &amp;= \sum_i (x \cdot v_i) A_i v_i \\ &amp;= \sum_i (x \cdot v_i) \sigma_i u_i \end{aligned}" class="latex" width="164" height="137" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Baligned%7DAx+%26%3D+A+%5Cleft+%28+%5Csum_i+%28x+%5Ccdot+v_i%29+v_i+%5Cright+%29+%5C%5C+%C2%A0%26%3D+%5Csum_i+%28x+%5Ccdot+v_i%29+A_i+v_i+%5C%5C+%26%3D+%5Csum_i+%28x+%5Ccdot+v_i%29+%5Csigma_i+u_i+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"></p>
<p style="text-align:left;">If you’ve been closely reading this blog in the last few months, you’ll recognize a very nice way to write the last line of the above equation. It’s an <a href="https://jeremykun.com/2016/03/28/tensorphobia-outer-product/">outer product</a>. So depending on your favorite symbols,&nbsp;you’d write this as either <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(85).php" alt="A = \sum_{i} \sigma_i u_i \otimes v_i" title="A = \sum_{i} \sigma_i u_i \otimes v_i" class="latex" width="119" height="17" srcset="https://s0.wp.com/latex.php?latex=A+%3D+%5Csum_%7Bi%7D+%5Csigma_i+u_i+%5Cotimes+v_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> or <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(86).php" alt="A = \sum_i \sigma_i u_i v_i^T" title="A = \sum_i \sigma_i u_i v_i^T" class="latex" width="104" height="19" srcset="https://s0.wp.com/latex.php?latex=A+%3D+%5Csum_i+%5Csigma_i+u_i+v_i%5ET&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. Or, if you like expressing things as matrix factorizations, as <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(70).php" alt="A = U\Sigma V^T" title="A = U\Sigma V^T" class="latex" width="81" height="14" srcset="https://s0.wp.com/latex.php?latex=A+%3D+U%5CSigma+V%5ET&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. All three are describing the same object.</p>
<p style="text-align:left;">Let’s move on to some code.</p>
<h2 style="text-align:center;">A black box example</h2>
<p>Before we implement SVD from scratch (an urge that commands me from the depths of my soul!), let’s see a black-box&nbsp;example that uses existing tools. For this we’ll use the <a href="http://www.numpy.org/">numpy</a> library.</p>
<p>Recall our movie-rating matrix from the last post:</p>
<p><a href="https://jeremykun.com/2016/04/18/singular-value-decomposition-part-1-perspectives-on-linear-algebra/movieratings/#main" rel="attachment wp-att-6234" class="single-image-gallery"><img data-attachment-id="6234" data-permalink="https://jeremykun.com/2016/04/18/singular-value-decomposition-part-1-perspectives-on-linear-algebra/movieratings/#main" data-orig-file="https://jeremykun.files.wordpress.com/2015/11/movieratings.png" data-orig-size="812,521" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="movieratings" data-image-description="" data-medium-file="https://jeremykun.files.wordpress.com/2015/11/movieratings.png?w=300" data-large-file="https://jeremykun.files.wordpress.com/2015/11/movieratings.png?w=812" class="aligncenter size-full wp-image-6234" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/movieratings.png" alt="movieratings" srcset="https://jeremykun.files.wordpress.com/2015/11/movieratings.png 812w, https://jeremykun.files.wordpress.com/2015/11/movieratings.png?w=150 150w, https://jeremykun.files.wordpress.com/2015/11/movieratings.png?w=300 300w, https://jeremykun.files.wordpress.com/2015/11/movieratings.png?w=768 768w" sizes="(max-width: 812px) 100vw, 812px"></a></p>
<p>The code to compute the svd of this matrix is as simple as it gets:</p>
<div><div id="highlighter_572050" class="syntaxhighlighter  python"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div><div class="line number9 index8 alt2">9</div><div class="line number10 index9 alt1">10</div><div class="line number11 index10 alt2">11</div><div class="line number12 index11 alt1">12</div><div class="line number13 index12 alt2">13</div><div class="line number14 index13 alt1">14</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python keyword">from</code> <code class="python plain">numpy.linalg </code><code class="python keyword">import</code> <code class="python plain">svd</code></div><div class="line number2 index1 alt1">&nbsp;</div><div class="line number3 index2 alt2"><code class="python plain">movieRatings </code><code class="python keyword">=</code> <code class="python plain">[</code></div><div class="line number4 index3 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[</code><code class="python value">2</code><code class="python plain">, </code><code class="python value">5</code><code class="python plain">, </code><code class="python value">3</code><code class="python plain">],</code></div><div class="line number5 index4 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[</code><code class="python value">1</code><code class="python plain">, </code><code class="python value">2</code><code class="python plain">, </code><code class="python value">1</code><code class="python plain">],</code></div><div class="line number6 index5 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[</code><code class="python value">4</code><code class="python plain">, </code><code class="python value">1</code><code class="python plain">, </code><code class="python value">1</code><code class="python plain">],</code></div><div class="line number7 index6 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[</code><code class="python value">3</code><code class="python plain">, </code><code class="python value">5</code><code class="python plain">, </code><code class="python value">2</code><code class="python plain">],</code></div><div class="line number8 index7 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[</code><code class="python value">5</code><code class="python plain">, </code><code class="python value">3</code><code class="python plain">, </code><code class="python value">1</code><code class="python plain">],</code></div><div class="line number9 index8 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[</code><code class="python value">4</code><code class="python plain">, </code><code class="python value">5</code><code class="python plain">, </code><code class="python value">5</code><code class="python plain">],</code></div><div class="line number10 index9 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[</code><code class="python value">2</code><code class="python plain">, </code><code class="python value">4</code><code class="python plain">, </code><code class="python value">2</code><code class="python plain">],</code></div><div class="line number11 index10 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[</code><code class="python value">2</code><code class="python plain">, </code><code class="python value">2</code><code class="python plain">, </code><code class="python value">5</code><code class="python plain">],</code></div><div class="line number12 index11 alt1"><code class="python plain">]</code></div><div class="line number13 index12 alt2">&nbsp;</div><div class="line number14 index13 alt1"><code class="python plain">U, singularValues, V </code><code class="python keyword">=</code> <code class="python plain">svd(movieRatings)</code></div></div></td></tr></tbody></table></div></div>
<p>Printing these values out gives</p>
<div><div id="highlighter_349471" class="syntaxhighlighter  plain"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div><div class="line number9 index8 alt2">9</div><div class="line number10 index9 alt1">10</div><div class="line number11 index10 alt2">11</div><div class="line number12 index11 alt1">12</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="plain plain">[[-0.39458526&nbsp; 0.23923575 -0.35445911 -0.38062172 -0.29836818 -0.49464816 -0.30703202 -0.29763321]</code></div><div class="line number2 index1 alt1"><code class="plain spaces">&nbsp;</code><code class="plain plain">[-0.15830232&nbsp; 0.03054913 -0.15299759 -0.45334816&nbsp; 0.31122898&nbsp; 0.23892035 -0.37313346&nbsp; 0.67223457]</code></div><div class="line number3 index2 alt2"><code class="plain spaces">&nbsp;</code><code class="plain plain">[-0.22155201 -0.52086121&nbsp; 0.39334917 -0.14974792 -0.65963979&nbsp; 0.00488292 -0.00783684&nbsp; 0.25934607]</code></div><div class="line number4 index3 alt1"><code class="plain spaces">&nbsp;</code><code class="plain plain">[-0.39692635 -0.08649009 -0.41052882&nbsp; 0.74387448 -0.10629499&nbsp; 0.01372565 -0.17959298&nbsp; 0.26333462]</code></div><div class="line number5 index4 alt2"><code class="plain spaces">&nbsp;</code><code class="plain plain">[-0.34630257 -0.64128825&nbsp; 0.07382859 -0.04494155&nbsp; 0.58000668 -0.25806239&nbsp; 0.00211823 -0.24154726]</code></div><div class="line number6 index5 alt1"><code class="plain spaces">&nbsp;</code><code class="plain plain">[-0.53347449&nbsp; 0.19168874&nbsp; 0.19949342 -0.03942604&nbsp; 0.00424495&nbsp; 0.68715732 -0.06957561 -0.40033035]</code></div><div class="line number7 index6 alt2"><code class="plain spaces">&nbsp;</code><code class="plain plain">[-0.31660464&nbsp; 0.06109826 -0.30599517 -0.19611823 -0.01334272&nbsp; 0.01446975&nbsp; 0.85185852&nbsp; 0.19463493]</code></div><div class="line number8 index7 alt1"><code class="plain spaces">&nbsp;</code><code class="plain plain">[-0.32840223&nbsp; 0.45970413&nbsp; 0.62354764&nbsp; 0.1783041&nbsp;&nbsp; 0.17631186 -0.39879476&nbsp; 0.06065902&nbsp; 0.25771578]]</code></div><div class="line number9 index8 alt2"><code class="plain plain">[ 15.09626916&nbsp;&nbsp; 4.30056855&nbsp;&nbsp; 3.40701739]</code></div><div class="line number10 index9 alt1"><code class="plain plain">[[-0.54184808 -0.67070995 -0.50650649]</code></div><div class="line number11 index10 alt2"><code class="plain spaces">&nbsp;</code><code class="plain plain">[-0.75152295&nbsp; 0.11680911&nbsp; 0.64928336]</code></div><div class="line number12 index11 alt1"><code class="plain spaces">&nbsp;</code><code class="plain plain">[ 0.37631623 -0.73246419&nbsp; 0.56734672]]</code></div></div></td></tr></tbody></table></div></div>
<p>Now this is a bit weird, because the matrices <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(87).php" alt="U, V" title="U, V" class="latex" width="30" height="14" srcset="https://s0.wp.com/latex.php?latex=U%2C+V&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> are the wrong shape! Remember, there are only supposed to be three vectors since the input matrix has rank three. So what gives? This is a distinction that goes by the name “full” versus “reduced” SVD. The idea goes back to our original statement that <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(88).php" alt="U \Sigma V^T" title="U \Sigma V^T" class="latex" width="46" height="14" srcset="https://s0.wp.com/latex.php?latex=U+%5CSigma+V%5ET&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is a decomposition with <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(89).php" alt="U, V^T" title="U, V^T" class="latex" width="39" height="17" srcset="https://s0.wp.com/latex.php?latex=U%2C+V%5ET&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> both orthogonal and&nbsp;<em>square</em>&nbsp;matrices. But in the derivation we did in the last section, the <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(76).php" alt="U" title="U" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> and <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(6).php" alt="V" title="V" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> were not square. The singular vectors <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(49).php" alt="v_i" title="v_i" class="latex" width="12" height="10" srcset="https://s0.wp.com/latex.php?latex=v_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> could potentially stop before even becoming full rank.</p>
<p>In order to get to square matrices, what people sometimes do is take the two bases <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(75).php" alt="v_1, \dots, v_k" title="v_1, \dots, v_k" class="latex" width="65" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1%2C+%5Cdots%2C+v_k&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> and <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(90).php" alt="u_1, \dots, u_k" title="u_1, \dots, u_k" class="latex" width="67" height="11" srcset="https://s0.wp.com/latex.php?latex=u_1%2C+%5Cdots%2C+u_k&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> and arbitrarily choose ways to <a href="https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process">complete them</a> to a full orthonormal basis of their respective vector spaces. In other words, they just make the matrix square by filling it with data for no reason other than that it’s sometimes nice to have a complete basis. We don’t care about this. To be honest, I think the only place this comes in useful is in the desire to be particularly tidy in a mathematical formulation of something.</p>
<p>We can still work with it programmatically.&nbsp;By fudging around a bit with numpy’s shapes to get a diagonal matrix, we can reconstruct the input rating matrix from the factors.</p>
<div><div id="highlighter_315801" class="syntaxhighlighter  python"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python plain">Sigma </code><code class="python keyword">=</code> <code class="python plain">np.vstack([</code></div><div class="line number2 index1 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">np.diag(singularValues),</code></div><div class="line number3 index2 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">np.zeros((</code><code class="python value">5</code><code class="python plain">, </code><code class="python value">3</code><code class="python plain">)),</code></div><div class="line number4 index3 alt1"><code class="python plain">])</code></div><div class="line number5 index4 alt2">&nbsp;</div><div class="line number6 index5 alt1"><code class="python functions">print</code><code class="python plain">(np.</code><code class="python functions">round</code><code class="python plain">(movieRatings </code><code class="python keyword">-</code> <code class="python plain">np.dot(U, np.dot(Sigma, V)), decimals</code><code class="python keyword">=</code><code class="python value">10</code><code class="python plain">))</code></div></div></td></tr></tbody></table></div></div>
<p>And the output is, as one expects, a matrix of all zeros. Meaning that we decomposed the movie rating matrix, and built it back up from the factors.</p>
<p>We can actually get the SVD as we defined it (with rectangular matrices) by passing a special flag to numpy’s svd.</p>
<div><div id="highlighter_541678" class="syntaxhighlighter  python"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python plain">U, singularValues, V </code><code class="python keyword">=</code> <code class="python plain">svd(movieRatings, full_matrices</code><code class="python keyword">=</code><code class="python color1">False</code><code class="python plain">)</code></div><div class="line number2 index1 alt1"><code class="python functions">print</code><code class="python plain">(U)</code></div><div class="line number3 index2 alt2"><code class="python functions">print</code><code class="python plain">(singularValues)</code></div><div class="line number4 index3 alt1"><code class="python functions">print</code><code class="python plain">(V)</code></div><div class="line number5 index4 alt2">&nbsp;</div><div class="line number6 index5 alt1"><code class="python plain">Sigma </code><code class="python keyword">=</code> <code class="python plain">np.diag(singularValues)</code></div><div class="line number7 index6 alt2"><code class="python functions">print</code><code class="python plain">(np.</code><code class="python functions">round</code><code class="python plain">(movieRatings </code><code class="python keyword">-</code> <code class="python plain">np.dot(U, np.dot(Sigma, V)), decimals</code><code class="python keyword">=</code><code class="python value">10</code><code class="python plain">))</code></div></div></td></tr></tbody></table></div></div>
<p>And the result</p>
<div><div id="highlighter_741431" class="syntaxhighlighter  plain"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div><div class="line number9 index8 alt2">9</div><div class="line number10 index9 alt1">10</div><div class="line number11 index10 alt2">11</div><div class="line number12 index11 alt1">12</div><div class="line number13 index12 alt2">13</div><div class="line number14 index13 alt1">14</div><div class="line number15 index14 alt2">15</div><div class="line number16 index15 alt1">16</div><div class="line number17 index16 alt2">17</div><div class="line number18 index17 alt1">18</div><div class="line number19 index18 alt2">19</div><div class="line number20 index19 alt1">20</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="plain plain">[[-0.39458526&nbsp; 0.23923575 -0.35445911]</code></div><div class="line number2 index1 alt1"><code class="plain spaces">&nbsp;</code><code class="plain plain">[-0.15830232&nbsp; 0.03054913 -0.15299759]</code></div><div class="line number3 index2 alt2"><code class="plain spaces">&nbsp;</code><code class="plain plain">[-0.22155201 -0.52086121&nbsp; 0.39334917]</code></div><div class="line number4 index3 alt1"><code class="plain spaces">&nbsp;</code><code class="plain plain">[-0.39692635 -0.08649009 -0.41052882]</code></div><div class="line number5 index4 alt2"><code class="plain spaces">&nbsp;</code><code class="plain plain">[-0.34630257 -0.64128825&nbsp; 0.07382859]</code></div><div class="line number6 index5 alt1"><code class="plain spaces">&nbsp;</code><code class="plain plain">[-0.53347449&nbsp; 0.19168874&nbsp; 0.19949342]</code></div><div class="line number7 index6 alt2"><code class="plain spaces">&nbsp;</code><code class="plain plain">[-0.31660464&nbsp; 0.06109826 -0.30599517]</code></div><div class="line number8 index7 alt1"><code class="plain spaces">&nbsp;</code><code class="plain plain">[-0.32840223&nbsp; 0.45970413&nbsp; 0.62354764]]</code></div><div class="line number9 index8 alt2"><code class="plain plain">[ 15.09626916&nbsp;&nbsp; 4.30056855&nbsp;&nbsp; 3.40701739]</code></div><div class="line number10 index9 alt1"><code class="plain plain">[[-0.54184808 -0.67070995 -0.50650649]</code></div><div class="line number11 index10 alt2"><code class="plain spaces">&nbsp;</code><code class="plain plain">[-0.75152295&nbsp; 0.11680911&nbsp; 0.64928336]</code></div><div class="line number12 index11 alt1"><code class="plain spaces">&nbsp;</code><code class="plain plain">[ 0.37631623 -0.73246419&nbsp; 0.56734672]]</code></div><div class="line number13 index12 alt2"><code class="plain plain">[[-0. -0. -0.]</code></div><div class="line number14 index13 alt1"><code class="plain spaces">&nbsp;</code><code class="plain plain">[-0. -0.&nbsp; 0.]</code></div><div class="line number15 index14 alt2"><code class="plain spaces">&nbsp;</code><code class="plain plain">[ 0. -0.&nbsp; 0.]</code></div><div class="line number16 index15 alt1"><code class="plain spaces">&nbsp;</code><code class="plain plain">[-0. -0. -0.]</code></div><div class="line number17 index16 alt2"><code class="plain spaces">&nbsp;</code><code class="plain plain">[-0. -0. -0.]</code></div><div class="line number18 index17 alt1"><code class="plain spaces">&nbsp;</code><code class="plain plain">[-0. -0. -0.]</code></div><div class="line number19 index18 alt2"><code class="plain spaces">&nbsp;</code><code class="plain plain">[-0. -0. -0.]</code></div><div class="line number20 index19 alt1"><code class="plain spaces">&nbsp;</code><code class="plain plain">[ 0. -0. -0.]]</code></div></div></td></tr></tbody></table></div></div>
<p>This makes the reconstruction less messy, since we can just multiply everything without having to add extra rows of zeros to <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(73).php" alt="\Sigma" title="\Sigma" class="latex" width="11" height="11" srcset="https://s0.wp.com/latex.php?latex=%5CSigma&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">.</p>
<p>What do the singular vectors and values tell us about the movie rating matrix? (Besides nothing, since it’s a contrived example) You’ll notice that the first singular vector <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(91).php" alt="\sigma_1 &gt; 15" title="\sigma_1 &gt; 15" class="latex" width="54" height="17" srcset="https://s0.wp.com/latex.php?latex=%5Csigma_1+%3E+15&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> while the other two singular values are around <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(92).php" alt="4" title="4" class="latex" width="8" height="13" srcset="https://s0.wp.com/latex.php?latex=4&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. This tells us that the first singular vector covers a large part&nbsp;of the structure of the matrix. I.e., a rank-1&nbsp;matrix would be a pretty&nbsp;good approximation to the whole thing. As an exercise to the reader, write a program that evaluates this claim (how good is “good”?).</p>
<h2 style="text-align:center;">The greedy optimization routine</h2>
<p style="text-align:left;">Now we’re going to write SVD from scratch. We’ll first implement the greedy algorithm for the 1-d optimization problem, and then we’ll perform the inductive step to get a full algorithm. Then we’ll run it on the CNN data set.</p>
<p style="text-align:left;">The method we’ll use to solve the 1-dimensional problem isn’t necessarily industry strength (see <a href="http://www.math.iit.edu/~fass/477577_Chapter_12.pdf">this document</a> for a hint of what industry strength looks like), but it is simple conceptually. It’s called&nbsp;the<em> power method</em>. Now that we have our decomposition of theorem, understanding how the power method works is quite easy.</p>
<p style="text-align:left;">Let’s work in the language of a matrix decomposition <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(93).php" alt="A = U \Sigma V^T" title="A = U \Sigma V^T" class="latex" width="81" height="14" srcset="https://s0.wp.com/latex.php?latex=A+%3D+U+%5CSigma+V%5ET&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, more for practice with that language than anything else (using outer products would give us the same result with slightly different computations). Then let’s observe <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(94).php" alt="A^T A" title="A^T A" class="latex" width="33" height="14" srcset="https://s0.wp.com/latex.php?latex=A%5ET+A&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, wherein we’ll use the fact that <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(76).php" alt="U" title="U" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is orthonormal and so <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(95).php" alt="U^TU" title="U^TU" class="latex" width="34" height="14" srcset="https://s0.wp.com/latex.php?latex=U%5ETU&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is the identity matrix:</p>
<p style="text-align:center;"><img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(96).php" alt="\displaystyle A^TA = (U \Sigma V^T)^T(U \Sigma V^T) = V \Sigma U^TU \Sigma V^T = V \Sigma^2 V^T" title="\displaystyle A^TA = (U \Sigma V^T)^T(U \Sigma V^T) = V \Sigma U^TU \Sigma V^T = V \Sigma^2 V^T" class="latex" width="374" height="18" srcset="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+A%5ETA+%3D+%28U+%5CSigma+V%5ET%29%5ET%28U+%5CSigma+V%5ET%29+%3D+V+%5CSigma+U%5ETU+%5CSigma+V%5ET+%3D+V+%5CSigma%5E2+V%5ET&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"></p>
<p style="text-align:left;">So we can completely eliminate <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(76).php" alt="U" title="U" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> from the discussion, and look at just <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(97).php" alt="V \Sigma^2 V^T" title="V \Sigma^2 V^T" class="latex" width="53" height="14" srcset="https://s0.wp.com/latex.php?latex=V+%5CSigma%5E2+V%5ET&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. And what’s nice about this matrix is that we can compute its eigenvectors, and eigenvectors turn out to be exactly the singular vectors. The corresponding eigenvalues are the squared singular values. This should be clear from the above derivation. If you apply <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(98).php" alt="(V \Sigma^2 V^T)" title="(V \Sigma^2 V^T)" class="latex" width="64" height="18" srcset="https://s0.wp.com/latex.php?latex=%28V+%5CSigma%5E2+V%5ET%29&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> to any <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(49).php" alt="v_i" title="v_i" class="latex" width="12" height="10" srcset="https://s0.wp.com/latex.php?latex=v_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, the only parts of the product that aren’t zero are the ones involving <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(49).php" alt="v_i" title="v_i" class="latex" width="12" height="10" srcset="https://s0.wp.com/latex.php?latex=v_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> with itself, and the scalar <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(99).php" alt="\sigma_i^2" title="\sigma_i^2" class="latex" width="16" height="18" srcset="https://s0.wp.com/latex.php?latex=%5Csigma_i%5E2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> factors in smoothly. It’s dead simple&nbsp;to check.</p>
<p style="text-align:left;"><strong>Theorem:</strong>&nbsp;Let <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(10).php" alt="x" title="x" class="latex" width="9" height="7" srcset="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> be a random unit vector and let <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(100).php" alt="B = A^TA = V \Sigma^2 V^T" title="B = A^TA = V \Sigma^2 V^T" class="latex" width="144" height="14" srcset="https://s0.wp.com/latex.php?latex=B+%3D+A%5ETA+%3D+V+%5CSigma%5E2+V%5ET&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. Then with high probability, <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(101).php" alt="\lim_{s \to \infty} B^s x" title="\lim_{s \to \infty} B^s x" class="latex" width="83" height="17" srcset="https://s0.wp.com/latex.php?latex=%5Clim_%7Bs+%5Cto+%5Cinfty%7D+B%5Es+x&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is in the span of the first singular vector <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(32).php" alt="v_1" title="v_1" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. If we normalize <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(102).php" alt="B^s x" title="B^s x" class="latex" width="28" height="11" srcset="https://s0.wp.com/latex.php?latex=B%5Es+x&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> to a unit vector at each&nbsp;<img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(103).php" alt="s" title="s" class="latex" width="7" height="7" srcset="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, then furthermore the limit is <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(32).php" alt="v_1" title="v_1" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">.</p>
<p style="text-align:left;"><em>Proof. </em>Start with a random unit vector <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(10).php" alt="x" title="x" class="latex" width="9" height="7" srcset="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, and write it in terms of the singular vectors <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(104).php" alt="x = \sum_i c_i v_i" title="x = \sum_i c_i v_i" class="latex" width="80" height="17" srcset="https://s0.wp.com/latex.php?latex=x+%3D+%5Csum_i+c_i+v_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. That means&nbsp;<img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(105).php" alt="Bx = \sum_i c_i \sigma_i^2 v_i" title="Bx = \sum_i c_i \sigma_i^2 v_i" class="latex" width="109" height="19" srcset="https://s0.wp.com/latex.php?latex=Bx+%3D+%5Csum_i+c_i+%5Csigma_i%5E2+v_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. If you recursively apply this logic, you get <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(106).php" alt="B^s x = \sum_i c_i \sigma_i^{2s} v_i" title="B^s x = \sum_i c_i \sigma_i^{2s} v_i" class="latex" width="121" height="19" srcset="https://s0.wp.com/latex.php?latex=B%5Es+x+%3D+%5Csum_i+c_i+%5Csigma_i%5E%7B2s%7D+v_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. In particular, the dot product of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(107).php" alt="(B^s x)" title="(B^s x)" class="latex" width="39" height="18" srcset="https://s0.wp.com/latex.php?latex=%28B%5Es+x%29&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> with any <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(108).php" alt="v_j" title="v_j" class="latex" width="13" height="12" srcset="https://s0.wp.com/latex.php?latex=v_j&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(109).php" alt="c_i \sigma_j^{2s}" title="c_i \sigma_j^{2s}" class="latex" width="32" height="20" srcset="https://s0.wp.com/latex.php?latex=c_i+%5Csigma_j%5E%7B2s%7D&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">.</p>
<p style="text-align:left;">What this means is that so long as the first singular value&nbsp;<img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(110).php" alt="\sigma_1" title="\sigma_1" class="latex" width="14" height="11" srcset="https://s0.wp.com/latex.php?latex=%5Csigma_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is sufficiently larger than the second one <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(111).php" alt="\sigma_2" title="\sigma_2" class="latex" width="15" height="10" srcset="https://s0.wp.com/latex.php?latex=%5Csigma_2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, and in turn all the other singular values, the&nbsp;part of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(102).php" alt="B^s x" title="B^s x" class="latex" width="28" height="11" srcset="https://s0.wp.com/latex.php?latex=B%5Es+x&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> &nbsp;corresponding to <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(32).php" alt="v_1" title="v_1" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> will be much larger than the rest. Recall that if you expand a vector in terms of an orthonormal basis, in this case <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(102).php" alt="B^s x" title="B^s x" class="latex" width="28" height="11" srcset="https://s0.wp.com/latex.php?latex=B%5Es+x&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> expanded in the <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(49).php" alt="v_i" title="v_i" class="latex" width="12" height="10" srcset="https://s0.wp.com/latex.php?latex=v_i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">,&nbsp;the coefficient of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(102).php" alt="B^s x" title="B^s x" class="latex" width="28" height="11" srcset="https://s0.wp.com/latex.php?latex=B%5Es+x&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> on <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(108).php" alt="v_j" title="v_j" class="latex" width="13" height="12" srcset="https://s0.wp.com/latex.php?latex=v_j&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is <em>exactly the dot product</em>. So to say that <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(112).php" alt="B^sx" title="B^sx" class="latex" width="28" height="11" srcset="https://s0.wp.com/latex.php?latex=B%5Esx&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> converges to being in the span of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(32).php" alt="v_1" title="v_1" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is the same as&nbsp;saying that the ratio of these coefficients, <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(113).php" alt="|(B^s x \cdot v_1)| / |(B^s x \cdot v_j)| \to \infty" title="|(B^s x \cdot v_1)| / |(B^s x \cdot v_j)| \to \infty" class="latex" width="202" height="19" srcset="https://s0.wp.com/latex.php?latex=%7C%28B%5Es+x+%5Ccdot+v_1%29%7C+%2F+%7C%28B%5Es+x+%5Ccdot+v_j%29%7C+%5Cto+%5Cinfty&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> for any <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(114).php" alt="j" title="j" class="latex" width="8" height="15" srcset="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. In other words, the coefficient corresponding to the first singular vector dominates all of the others. And so if we normalize, the coefficient of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(102).php" alt="B^s x" title="B^s x" class="latex" width="28" height="11" srcset="https://s0.wp.com/latex.php?latex=B%5Es+x&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">&nbsp;corresponding to <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(32).php" alt="v_1" title="v_1" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> tends to 1, while the rest tend to zero.</p>
<p style="text-align:left;">Indeed, this ratio is just <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(115).php" alt="(\sigma_1 / \sigma_j)^{2s}" title="(\sigma_1 / \sigma_j)^{2s}" class="latex" width="62" height="19" srcset="https://s0.wp.com/latex.php?latex=%28%5Csigma_1+%2F+%5Csigma_j%29%5E%7B2s%7D&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> and the base of this exponential is bigger than 1.</p>
<p style="text-align:right;"><img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(69).php" alt="\square" title="\square" class="latex" width="11" height="12" srcset="https://s0.wp.com/latex.php?latex=%5Csquare&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"></p>
<p style="text-align:left;">If you want to be a little more precise and find bounds on the number of iterations required to converge, you can. The worry is that your random starting vector is “too close” to one of the smaller singular vectors <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(108).php" alt="v_j" title="v_j" class="latex" width="13" height="12" srcset="https://s0.wp.com/latex.php?latex=v_j&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, so that if the ratio of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(116).php" alt="\sigma_1 / \sigma_j" title="\sigma_1 / \sigma_j" class="latex" width="38" height="17" srcset="https://s0.wp.com/latex.php?latex=%5Csigma_1+%2F+%5Csigma_j&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is small, then the “pull” of&nbsp;<img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(32).php" alt="v_1" title="v_1" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">&nbsp;won’t outweigh the pull of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(108).php" alt="v_j" title="v_j" class="latex" width="13" height="12" srcset="https://s0.wp.com/latex.php?latex=v_j&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> fast enough. Choosing a random unit vector allows you to ensure with high probability that this doesn’t happen. And conditioned on it not happening (or measuring “how far the event is from happening” precisely), you can compute a precise number of iterations required to converge. The last two pages of <a href="http://www.cs.yale.edu/homes/el327/datamining2013aFiles/07_singular_value_decomposition.pdf">these lecture notes</a> have all the&nbsp;details.</p>
<p style="text-align:left;">We won’t compute a precise number of iterations. Instead we’ll just compute until the angle between <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(117).php" alt="B^{s+1}x" title="B^{s+1}x" class="latex" width="43" height="14" srcset="https://s0.wp.com/latex.php?latex=B%5E%7Bs%2B1%7Dx&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> and <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(102).php" alt="B^s x" title="B^s x" class="latex" width="28" height="11" srcset="https://s0.wp.com/latex.php?latex=B%5Es+x&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is very small. Here’s the algorithm</p>
<div><div id="highlighter_840911" class="syntaxhighlighter  python"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div><div class="line number9 index8 alt2">9</div><div class="line number10 index9 alt1">10</div><div class="line number11 index10 alt2">11</div><div class="line number12 index11 alt1">12</div><div class="line number13 index12 alt2">13</div><div class="line number14 index13 alt1">14</div><div class="line number15 index14 alt2">15</div><div class="line number16 index15 alt1">16</div><div class="line number17 index16 alt2">17</div><div class="line number18 index17 alt1">18</div><div class="line number19 index18 alt2">19</div><div class="line number20 index19 alt1">20</div><div class="line number21 index20 alt2">21</div><div class="line number22 index21 alt1">22</div><div class="line number23 index22 alt2">23</div><div class="line number24 index23 alt1">24</div><div class="line number25 index24 alt2">25</div><div class="line number26 index25 alt1">26</div><div class="line number27 index26 alt2">27</div><div class="line number28 index27 alt1">28</div><div class="line number29 index28 alt2">29</div><div class="line number30 index29 alt1">30</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python keyword">import</code> <code class="python plain">numpy as np</code></div><div class="line number2 index1 alt1"><code class="python keyword">from</code> <code class="python plain">numpy.linalg </code><code class="python keyword">import</code> <code class="python plain">norm</code></div><div class="line number3 index2 alt2">&nbsp;</div><div class="line number4 index3 alt1"><code class="python keyword">from</code> <code class="python plain">random </code><code class="python keyword">import</code> <code class="python plain">normalvariate</code></div><div class="line number5 index4 alt2"><code class="python keyword">from</code> <code class="python plain">math </code><code class="python keyword">import</code> <code class="python plain">sqrt</code></div><div class="line number6 index5 alt1">&nbsp;</div><div class="line number7 index6 alt2"><code class="python keyword">def</code> <code class="python plain">randomUnitVector(n):</code></div><div class="line number8 index7 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">unnormalized </code><code class="python keyword">=</code> <code class="python plain">[normalvariate(</code><code class="python value">0</code><code class="python plain">, </code><code class="python value">1</code><code class="python plain">) </code><code class="python keyword">for</code> <code class="python plain">_ </code><code class="python keyword">in</code> <code class="python functions">range</code><code class="python plain">(n)]</code></div><div class="line number9 index8 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">theNorm </code><code class="python keyword">=</code> <code class="python plain">sqrt(</code><code class="python functions">sum</code><code class="python plain">(x </code><code class="python keyword">*</code> <code class="python plain">x </code><code class="python keyword">for</code> <code class="python plain">x </code><code class="python keyword">in</code> <code class="python plain">unnormalized))</code></div><div class="line number10 index9 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">return</code> <code class="python plain">[x </code><code class="python keyword">/</code> <code class="python plain">theNorm </code><code class="python keyword">for</code> <code class="python plain">x </code><code class="python keyword">in</code> <code class="python plain">unnormalized]</code></div><div class="line number11 index10 alt2">&nbsp;</div><div class="line number12 index11 alt1"><code class="python keyword">def</code> <code class="python plain">svd_1d(A, epsilon</code><code class="python keyword">=</code><code class="python value">1e</code><code class="python keyword">-</code><code class="python value">10</code><code class="python plain">):</code></div><div class="line number13 index12 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python comments">''' The one-dimensional SVD '''</code></div><div class="line number14 index13 alt1">&nbsp;</div><div class="line number15 index14 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">n, m </code><code class="python keyword">=</code> <code class="python plain">A.shape</code></div><div class="line number16 index15 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">x </code><code class="python keyword">=</code> <code class="python plain">randomUnitVector(m)</code></div><div class="line number17 index16 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">lastV </code><code class="python keyword">=</code> <code class="python color1">None</code></div><div class="line number18 index17 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">currentV </code><code class="python keyword">=</code> <code class="python plain">x</code></div><div class="line number19 index18 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">B </code><code class="python keyword">=</code> <code class="python plain">np.dot(A.T, A)</code></div><div class="line number20 index19 alt1">&nbsp;</div><div class="line number21 index20 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">iterations </code><code class="python keyword">=</code> <code class="python value">0</code></div><div class="line number22 index21 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">while</code> <code class="python color1">True</code><code class="python plain">:</code></div><div class="line number23 index22 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">iterations </code><code class="python keyword">+</code><code class="python keyword">=</code> <code class="python value">1</code></div><div class="line number24 index23 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">lastV </code><code class="python keyword">=</code> <code class="python plain">currentV</code></div><div class="line number25 index24 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">currentV </code><code class="python keyword">=</code> <code class="python plain">np.dot(B, lastV)</code></div><div class="line number26 index25 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">currentV </code><code class="python keyword">=</code> <code class="python plain">currentV </code><code class="python keyword">/</code> <code class="python plain">norm(currentV)</code></div><div class="line number27 index26 alt2">&nbsp;</div><div class="line number28 index27 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">if</code> <code class="python functions">abs</code><code class="python plain">(np.dot(currentV, lastV)) &gt; </code><code class="python value">1</code> <code class="python keyword">-</code> <code class="python plain">epsilon:</code></div><div class="line number29 index28 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python functions">print</code><code class="python plain">(</code><code class="python string">"converged in {} iterations!"</code><code class="python plain">.</code><code class="python functions">format</code><code class="python plain">(iterations))</code></div><div class="line number30 index29 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">return</code> <code class="python plain">currentV</code></div></div></td></tr></tbody></table></div></div>
<p style="text-align:left;">We start with a random unit vector <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(10).php" alt="x" title="x" class="latex" width="9" height="7" srcset="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, and then loop computing <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(118).php" alt="x_{t+1} = Bx_t" title="x_{t+1} = Bx_t" class="latex" width="77" height="15" srcset="https://s0.wp.com/latex.php?latex=x_%7Bt%2B1%7D+%3D+Bx_t&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, renormalizing at each step. The condition for stopping is that the magnitude of the dot product between <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(119).php" alt="x_t" title="x_t" class="latex" width="13" height="10" srcset="https://s0.wp.com/latex.php?latex=x_t&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> and <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(120).php" alt="x_{t+1}" title="x_{t+1}" class="latex" width="27" height="11" srcset="https://s0.wp.com/latex.php?latex=x_%7Bt%2B1%7D&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> (since they’re unit vectors, this is the cosine of the angle between them) is very close to 1.</p>
<p style="text-align:left;">And using it on our movie ratings example:</p>
<div><div id="highlighter_92473" class="syntaxhighlighter  python"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div><div class="line number9 index8 alt2">9</div><div class="line number10 index9 alt1">10</div><div class="line number11 index10 alt2">11</div><div class="line number12 index11 alt1">12</div><div class="line number13 index12 alt2">13</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python keyword">if</code> <code class="python plain">__name__ </code><code class="python keyword">=</code><code class="python keyword">=</code> <code class="python string">"__main__"</code><code class="python plain">:</code></div><div class="line number2 index1 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">movieRatings </code><code class="python keyword">=</code> <code class="python plain">np.array([</code></div><div class="line number3 index2 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[</code><code class="python value">2</code><code class="python plain">, </code><code class="python value">5</code><code class="python plain">, </code><code class="python value">3</code><code class="python plain">],</code></div><div class="line number4 index3 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[</code><code class="python value">1</code><code class="python plain">, </code><code class="python value">2</code><code class="python plain">, </code><code class="python value">1</code><code class="python plain">],</code></div><div class="line number5 index4 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[</code><code class="python value">4</code><code class="python plain">, </code><code class="python value">1</code><code class="python plain">, </code><code class="python value">1</code><code class="python plain">],</code></div><div class="line number6 index5 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[</code><code class="python value">3</code><code class="python plain">, </code><code class="python value">5</code><code class="python plain">, </code><code class="python value">2</code><code class="python plain">],</code></div><div class="line number7 index6 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[</code><code class="python value">5</code><code class="python plain">, </code><code class="python value">3</code><code class="python plain">, </code><code class="python value">1</code><code class="python plain">],</code></div><div class="line number8 index7 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[</code><code class="python value">4</code><code class="python plain">, </code><code class="python value">5</code><code class="python plain">, </code><code class="python value">5</code><code class="python plain">],</code></div><div class="line number9 index8 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[</code><code class="python value">2</code><code class="python plain">, </code><code class="python value">4</code><code class="python plain">, </code><code class="python value">2</code><code class="python plain">],</code></div><div class="line number10 index9 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[</code><code class="python value">2</code><code class="python plain">, </code><code class="python value">2</code><code class="python plain">, </code><code class="python value">5</code><code class="python plain">],</code></div><div class="line number11 index10 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">], dtype</code><code class="python keyword">=</code><code class="python string">'float64'</code><code class="python plain">)</code></div><div class="line number12 index11 alt1">&nbsp;</div><div class="line number13 index12 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python functions">print</code><code class="python plain">(svd_1d(movieRatings))</code></div></div></td></tr></tbody></table></div></div>
<p>With the result</p>
<div><div id="highlighter_512250" class="syntaxhighlighter  plain"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="plain plain">converged in 6 iterations!</code></div><div class="line number2 index1 alt1"><code class="plain plain">[-0.54184805 -0.67070993 -0.50650655]</code></div></div></td></tr></tbody></table></div></div>
<p style="text-align:left;">Note that the sign of the vector may be different from numpy’s output because we start with a random vector to begin with.</p>
<p style="text-align:left;">The recursive step, getting from <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(32).php" alt="v_1" title="v_1" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> to the entire SVD, is equally straightforward. Say&nbsp;you start with the matrix <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(26).php" alt="A" title="A" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> and you compute&nbsp;<img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(32).php" alt="v_1" title="v_1" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. You can use <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(32).php" alt="v_1" title="v_1" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">&nbsp;to compute <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(121).php" alt="u_1" title="u_1" class="latex" width="14" height="11" srcset="https://s0.wp.com/latex.php?latex=u_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> and <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(34).php" alt="\sigma_1(A)" title="\sigma_1(A)" class="latex" width="39" height="18" srcset="https://s0.wp.com/latex.php?latex=%5Csigma_1%28A%29&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. Then you want to ensure you’re ignoring all vectors in the span of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(32).php" alt="v_1" title="v_1" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> for your next greedy optimization, and to do this you can simply subtract the rank 1 component of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(26).php" alt="A" title="A" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> corresponding to <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(32).php" alt="v_1" title="v_1" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. I.e., set <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(122).php" alt="A&#39; = A - \sigma_1(A) u_1 v_1^T" title="A&#39; = A - \sigma_1(A) u_1 v_1^T" class="latex" width="144" height="19" srcset="https://s0.wp.com/latex.php?latex=A%27+%3D+A+-+%5Csigma_1%28A%29+u_1+v_1%5ET&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. Then it’s easy to see that <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(123).php" alt="\sigma_1(A&#39;) = \sigma_2(A)" title="\sigma_1(A&#39;) = \sigma_2(A)" class="latex" width="105" height="18" srcset="https://s0.wp.com/latex.php?latex=%5Csigma_1%28A%27%29+%3D+%5Csigma_2%28A%29&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> and basically all the singular vectors shift indices by 1 when going from <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(26).php" alt="A" title="A" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> to <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(124).php" alt="A&#39;" title="A&#39;" class="latex" width="16" height="13" srcset="https://s0.wp.com/latex.php?latex=A%27&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. Then you repeat.</p>
<p style="text-align:left;">If that’s not clear enough, here’s the code.</p>
<div><div id="highlighter_357692" class="syntaxhighlighter  python"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div><div class="line number9 index8 alt2">9</div><div class="line number10 index9 alt1">10</div><div class="line number11 index10 alt2">11</div><div class="line number12 index11 alt1">12</div><div class="line number13 index12 alt2">13</div><div class="line number14 index13 alt1">14</div><div class="line number15 index14 alt2">15</div><div class="line number16 index15 alt1">16</div><div class="line number17 index16 alt2">17</div><div class="line number18 index17 alt1">18</div><div class="line number19 index18 alt2">19</div><div class="line number20 index19 alt1">20</div><div class="line number21 index20 alt2">21</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python keyword">def</code> <code class="python plain">svd(A, epsilon</code><code class="python keyword">=</code><code class="python value">1e</code><code class="python keyword">-</code><code class="python value">10</code><code class="python plain">):</code></div><div class="line number2 index1 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">n, m </code><code class="python keyword">=</code> <code class="python plain">A.shape</code></div><div class="line number3 index2 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">svdSoFar </code><code class="python keyword">=</code> <code class="python plain">[]</code></div><div class="line number4 index3 alt1">&nbsp;</div><div class="line number5 index4 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">for</code> <code class="python plain">i </code><code class="python keyword">in</code> <code class="python functions">range</code><code class="python plain">(m):</code></div><div class="line number6 index5 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">matrixFor1D </code><code class="python keyword">=</code> <code class="python plain">A.copy()</code></div><div class="line number7 index6 alt2">&nbsp;</div><div class="line number8 index7 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">for</code> <code class="python plain">singularValue, u, v </code><code class="python keyword">in</code> <code class="python plain">svdSoFar[:i]:</code></div><div class="line number9 index8 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">matrixFor1D </code><code class="python keyword">-</code><code class="python keyword">=</code> <code class="python plain">singularValue </code><code class="python keyword">*</code> <code class="python plain">np.outer(u, v)</code></div><div class="line number10 index9 alt1">&nbsp;</div><div class="line number11 index10 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">v </code><code class="python keyword">=</code> <code class="python plain">svd_1d(matrixFor1D, epsilon</code><code class="python keyword">=</code><code class="python plain">epsilon)&nbsp; </code><code class="python comments"># next singular vector</code></div><div class="line number12 index11 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">u_unnormalized </code><code class="python keyword">=</code> <code class="python plain">np.dot(A, v)</code></div><div class="line number13 index12 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">sigma </code><code class="python keyword">=</code> <code class="python plain">norm(u_unnormalized)&nbsp; </code><code class="python comments"># next singular value</code></div><div class="line number14 index13 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">u </code><code class="python keyword">=</code> <code class="python plain">u_unnormalized </code><code class="python keyword">/</code> <code class="python plain">sigma</code></div><div class="line number15 index14 alt2">&nbsp;</div><div class="line number16 index15 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">svdSoFar.append((sigma, u, v))</code></div><div class="line number17 index16 alt2">&nbsp;</div><div class="line number18 index17 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python comments"># transform it into matrices of the right shape</code></div><div class="line number19 index18 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">singularValues, us, vs </code><code class="python keyword">=</code> <code class="python plain">[np.array(x) </code><code class="python keyword">for</code> <code class="python plain">x </code><code class="python keyword">in</code> <code class="python functions">zip</code><code class="python plain">(</code><code class="python keyword">*</code><code class="python plain">svdSoFar)]</code></div><div class="line number20 index19 alt1">&nbsp;</div><div class="line number21 index20 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">return</code> <code class="python plain">singularValues, us.T, vs</code></div></div></td></tr></tbody></table></div></div>
<p style="text-align:left;">And we can run this on our movie rating matrix to get the following</p>
<div><div id="highlighter_92703" class="syntaxhighlighter  python"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div><div class="line number9 index8 alt2">9</div><div class="line number10 index9 alt1">10</div><div class="line number11 index10 alt2">11</div><div class="line number12 index11 alt1">12</div><div class="line number13 index12 alt2">13</div><div class="line number14 index13 alt1">14</div><div class="line number15 index14 alt2">15</div><div class="line number16 index15 alt1">16</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python plain">&gt;&gt;&gt; theSVD </code><code class="python keyword">=</code> <code class="python plain">svd(movieRatings)</code></div><div class="line number2 index1 alt1"><code class="python plain">&gt;&gt;&gt; theSVD[</code><code class="python value">0</code><code class="python plain">]</code></div><div class="line number3 index2 alt2"><code class="python plain">array([ </code><code class="python value">15.09626916</code><code class="python plain">,&nbsp;&nbsp; </code><code class="python value">4.30056855</code><code class="python plain">,&nbsp;&nbsp; </code><code class="python value">3.40701739</code><code class="python plain">])</code></div><div class="line number4 index3 alt1"><code class="python plain">&gt;&gt;&gt; theSVD[</code><code class="python value">1</code><code class="python plain">]</code></div><div class="line number5 index4 alt2"><code class="python plain">array([[ </code><code class="python value">0.39458528</code><code class="python plain">, </code><code class="python keyword">-</code><code class="python value">0.23923093</code><code class="python plain">,&nbsp; </code><code class="python value">0.35446407</code><code class="python plain">],</code></div><div class="line number6 index5 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[ </code><code class="python value">0.15830233</code><code class="python plain">, </code><code class="python keyword">-</code><code class="python value">0.03054705</code><code class="python plain">,&nbsp; </code><code class="python value">0.15299815</code><code class="python plain">],</code></div><div class="line number7 index6 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[ </code><code class="python value">0.221552</code>&nbsp; <code class="python plain">,&nbsp; </code><code class="python value">0.52085578</code><code class="python plain">, </code><code class="python keyword">-</code><code class="python value">0.39336072</code><code class="python plain">],</code></div><div class="line number8 index7 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[ </code><code class="python value">0.39692636</code><code class="python plain">,&nbsp; </code><code class="python value">0.08649568</code><code class="python plain">,&nbsp; </code><code class="python value">0.41052666</code><code class="python plain">],</code></div><div class="line number9 index8 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[ </code><code class="python value">0.34630257</code><code class="python plain">,&nbsp; </code><code class="python value">0.64128719</code><code class="python plain">, </code><code class="python keyword">-</code><code class="python value">0.07384286</code><code class="python plain">],</code></div><div class="line number10 index9 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[ </code><code class="python value">0.53347448</code><code class="python plain">, </code><code class="python keyword">-</code><code class="python value">0.19169154</code><code class="python plain">, </code><code class="python keyword">-</code><code class="python value">0.19948959</code><code class="python plain">],</code></div><div class="line number11 index10 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[ </code><code class="python value">0.31660465</code><code class="python plain">, </code><code class="python keyword">-</code><code class="python value">0.0610941</code> <code class="python plain">,&nbsp; </code><code class="python value">0.30599629</code><code class="python plain">],</code></div><div class="line number12 index11 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[ </code><code class="python value">0.32840221</code><code class="python plain">, </code><code class="python keyword">-</code><code class="python value">0.45971273</code><code class="python plain">, </code><code class="python keyword">-</code><code class="python value">0.62353781</code><code class="python plain">]])</code></div><div class="line number13 index12 alt2"><code class="python plain">&gt;&gt;&gt; theSVD[</code><code class="python value">2</code><code class="python plain">]</code></div><div class="line number14 index13 alt1"><code class="python plain">array([[ </code><code class="python value">0.54184805</code><code class="python plain">,&nbsp; </code><code class="python value">0.67071006</code><code class="python plain">,&nbsp; </code><code class="python value">0.50650638</code><code class="python plain">],</code></div><div class="line number15 index14 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[ </code><code class="python value">0.75151641</code><code class="python plain">, </code><code class="python keyword">-</code><code class="python value">0.11679644</code><code class="python plain">, </code><code class="python keyword">-</code><code class="python value">0.64929321</code><code class="python plain">],</code></div><div class="line number16 index15 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[</code><code class="python keyword">-</code><code class="python value">0.37632934</code><code class="python plain">,&nbsp; </code><code class="python value">0.73246611</code><code class="python plain">, </code><code class="python keyword">-</code><code class="python value">0.56733554</code><code class="python plain">]])</code></div></div></td></tr></tbody></table></div></div>
<p style="text-align:left;">Checking this against our numpy output shows it’s within a reasonable level of precision (considering the power method took on the order of ten iterations!)</p>
<div><div id="highlighter_61524" class="syntaxhighlighter  plain"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div><div class="line number9 index8 alt2">9</div><div class="line number10 index9 alt1">10</div><div class="line number11 index10 alt2">11</div><div class="line number12 index11 alt1">12</div><div class="line number13 index12 alt2">13</div><div class="line number14 index13 alt1">14</div><div class="line number15 index14 alt2">15</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="plain plain">&gt;&gt;&gt; np.round(np.abs(npSVD[0]) - np.abs(theSVD[1]), decimals=5)</code></div><div class="line number2 index1 alt1"><code class="plain plain">array([[ -0.00000000e+00,&nbsp; -0.00000000e+00,&nbsp;&nbsp; 0.00000000e+00],</code></div><div class="line number3 index2 alt2"><code class="plain spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="plain plain">[&nbsp; 0.00000000e+00,&nbsp; -0.00000000e+00,&nbsp;&nbsp; 0.00000000e+00],</code></div><div class="line number4 index3 alt1"><code class="plain spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="plain plain">[&nbsp; 0.00000000e+00,&nbsp; -1.00000000e-05,&nbsp;&nbsp; 1.00000000e-05],</code></div><div class="line number5 index4 alt2"><code class="plain spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="plain plain">[&nbsp; 0.00000000e+00,&nbsp;&nbsp; 0.00000000e+00,&nbsp; -0.00000000e+00],</code></div><div class="line number6 index5 alt1"><code class="plain spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="plain plain">[&nbsp; 0.00000000e+00,&nbsp; -0.00000000e+00,&nbsp;&nbsp; 1.00000000e-05],</code></div><div class="line number7 index6 alt2"><code class="plain spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="plain plain">[ -0.00000000e+00,&nbsp;&nbsp; 0.00000000e+00,&nbsp; -0.00000000e+00],</code></div><div class="line number8 index7 alt1"><code class="plain spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="plain plain">[&nbsp; 0.00000000e+00,&nbsp; -0.00000000e+00,&nbsp;&nbsp; 0.00000000e+00],</code></div><div class="line number9 index8 alt2"><code class="plain spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="plain plain">[ -0.00000000e+00,&nbsp;&nbsp; 1.00000000e-05,&nbsp; -1.00000000e-05]])</code></div><div class="line number10 index9 alt1"><code class="plain plain">&gt;&gt;&gt; np.round(np.abs(npSVD[2]) - np.abs(theSVD[2]), decimals=5)</code></div><div class="line number11 index10 alt2"><code class="plain plain">array([[&nbsp; 0.00000000e+00,&nbsp;&nbsp; 0.00000000e+00,&nbsp; -0.00000000e+00],</code></div><div class="line number12 index11 alt1"><code class="plain spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="plain plain">[ -1.00000000e-05,&nbsp; -1.00000000e-05,&nbsp;&nbsp; 1.00000000e-05],</code></div><div class="line number13 index12 alt2"><code class="plain spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="plain plain">[&nbsp; 1.00000000e-05,&nbsp;&nbsp; 0.00000000e+00,&nbsp; -1.00000000e-05]])</code></div><div class="line number14 index13 alt1"><code class="plain plain">&gt;&gt;&gt; np.round(np.abs(npSVD[1]) - np.abs(theSVD[0]), decimals=5)</code></div><div class="line number15 index14 alt2"><code class="plain plain">array([ 0.,&nbsp; 0., -0.])</code></div></div></td></tr></tbody></table></div></div>
<p>So there we have it. We added an extra little bit to the svd function, an argument <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex.php" alt="k" title="k" class="latex" width="9" height="11" srcset="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> which stops computing the svd after it reaches rank <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex.php" alt="k" title="k" class="latex" width="9" height="11" srcset="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">.</p>
<h2 style="text-align:center;">CNN stories</h2>
<p>One interesting use of the SVD is in topic modeling. Topic modeling is the process of taking a bunch of documents (news stories, or emails, or movie scripts, whatever) and grouping them by topic, where the algorithm gets to choose what counts as a “topic.” Topic modeling&nbsp;is just the name that natural language processing folks use instead of&nbsp;clustering.</p>
<p>The SVD can help one model topics as follows. First you construct a matrix <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(26).php" alt="A" title="A" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> called a <em>document-term matrix</em>&nbsp;whose rows correspond to words in some fixed dictionary and whose columns correspond to documents. The <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(125).php" alt="(i,j)" title="(i,j)" class="latex" width="31" height="18" srcset="https://s0.wp.com/latex.php?latex=%28i%2Cj%29&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> entry of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(26).php" alt="A" title="A" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> contains the number of times word <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(126).php" alt="i" title="i" class="latex" width="5" height="12" srcset="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> shows up in document <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(114).php" alt="j" title="j" class="latex" width="8" height="15" srcset="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. Or, more precisely, some quantity&nbsp;<em>derived</em> from that count, like a normalized count. See <a href="https://en.wikipedia.org/wiki/Latent_semantic_indexing#Term-document_matrix">this table on wikipedia for a list of options</a>&nbsp;related to that. We’ll just pick one arbitrarily for use in this post.</p>
<p>The point isn’t how we normalize the data, but what the SVD of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(93).php" alt="A = U \Sigma V^T" title="A = U \Sigma V^T" class="latex" width="81" height="14" srcset="https://s0.wp.com/latex.php?latex=A+%3D+U+%5CSigma+V%5ET&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> means in this context. Recall that the domain of <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(26).php" alt="A" title="A" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">, as a linear map, is a vector space whose dimension is the number of stories. We think of the vectors in this space as <em>documents</em>, or rather as an “embedding” of the abstract concept of a&nbsp;document&nbsp;using the counts of how often each&nbsp;word shows up in a&nbsp;document as a proxy for the semantic meaning of the document. Likewise, the codomain is the space of all words, and each word&nbsp;is embedded by which documents it occurs in. If we compare this to the movie rating example, it’s the same thing: a movie is the vector of ratings it receives from people, and a person is the vector of ratings of various movies.</p>
<p>Say you take a rank 3 approximation to <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(26).php" alt="A" title="A" class="latex" width="12" height="11" srcset="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. Then you get three singular vectors <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(127).php" alt="v_1, v_2, v_3" title="v_1, v_2, v_3" class="latex" width="57" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1%2C+v_2%2C+v_3&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> which form a basis for a subspace of words, i.e., the “idealized” words. These idealized words are your topics, and you can compute where a “new word” falls by looking at which documents it appears in (writing it as a vector in the domain) and saying its “topic” is the closest of the <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(127).php" alt="v_1, v_2, v_3" title="v_1, v_2, v_3" class="latex" width="57" height="11" srcset="https://s0.wp.com/latex.php?latex=v_1%2C+v_2%2C+v_3&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. The same process applies to new documents. You can use this to cluster existing documents as well.</p>
<p>The dataset we’ll use for this post is a relatively small corpus of a thousand CNN stories picked from 2012. Here’s an excerpt from one of them</p>
<div><div id="highlighter_249653" class="syntaxhighlighter  plain"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="plain plain">$ cat data/cnn-stories/story479.txt</code></div><div class="line number2 index1 alt1"><code class="plain plain">3 things to watch on Super Tuesday</code></div><div class="line number3 index2 alt2"><code class="plain plain">Here are three things to watch for: Romney's big day. He's been the off-and-on frontrunner throughout the race, but a big Super Tuesday could begin an end game toward a sometimes hesitant base coalescing behind former Massachusetts Gov. Mitt Romney. Romney should win his home state of Massachusetts, neighboring Vermont and Virginia, ...</code></div></div></td></tr></tbody></table></div></div>
<p>So let’s first build this document-term matrix, with the normalized values, and then we’ll compute it’s SVD and see what the topics look like.</p>
<p>Step 1 is cleaning the data. We used a bunch of routines from the <a href="http://www.nltk.org/">nltk</a>&nbsp;library that boils down to this loop:</p>
<div><div id="highlighter_962369" class="syntaxhighlighter  python"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python keyword">for</code> <code class="python plain">filename, documentText </code><code class="python keyword">in</code> <code class="python plain">documentDict.items():</code></div><div class="line number2 index1 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">tokens </code><code class="python keyword">=</code> <code class="python plain">tokenize(documentText)</code></div><div class="line number3 index2 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">tagged_tokens </code><code class="python keyword">=</code> <code class="python plain">pos_tag(tokens)</code></div><div class="line number4 index3 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">wnl </code><code class="python keyword">=</code> <code class="python plain">WordNetLemmatizer()</code></div><div class="line number5 index4 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">stemmedTokens </code><code class="python keyword">=</code> <code class="python plain">[wnl.lemmatize(word, wordnetPos(tag)).lower()</code></div><div class="line number6 index5 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">for</code> <code class="python plain">word, tag </code><code class="python keyword">in</code> <code class="python plain">tagged_tokens]</code></div></div></td></tr></tbody></table></div></div>
<p>This turns the Super Tuesday story into a list of words (with repetition):</p>
<div><div id="highlighter_861990" class="syntaxhighlighter  plain"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="plain plain">["thing", "watch", "three", "thing", "watch", "big", ... ]</code></div></div></td></tr></tbody></table></div></div>
<p>If you’ll notice the name Romney doesn’t show up in the list of words. I’m only keeping the words that show up in the top 100,000 most common English words, and then lemmatizing all of the words to their roots. It’s not a perfect data cleaning job, but it’s simple and good enough for our purposes.</p>
<p>Now we can create the document term matrix.</p>
<div><div id="highlighter_764068" class="syntaxhighlighter  python"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div><div class="line number9 index8 alt2">9</div><div class="line number10 index9 alt1">10</div><div class="line number11 index10 alt2">11</div><div class="line number12 index11 alt1">12</div><div class="line number13 index12 alt2">13</div><div class="line number14 index13 alt1">14</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python keyword">def</code> <code class="python plain">makeDocumentTermMatrix(data):</code></div><div class="line number2 index1 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">words </code><code class="python keyword">=</code> <code class="python plain">allWords(data)&nbsp; </code><code class="python comments"># get the set of all unique words</code></div><div class="line number3 index2 alt2">&nbsp;</div><div class="line number4 index3 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">wordToIndex </code><code class="python keyword">=</code> <code class="python functions">dict</code><code class="python plain">((word, i) </code><code class="python keyword">for</code> <code class="python plain">i, word </code><code class="python keyword">in</code> <code class="python functions">enumerate</code><code class="python plain">(words))</code></div><div class="line number5 index4 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">indexToWord </code><code class="python keyword">=</code> <code class="python functions">dict</code><code class="python plain">(</code><code class="python functions">enumerate</code><code class="python plain">(words))</code></div><div class="line number6 index5 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">indexToDocument </code><code class="python keyword">=</code> <code class="python functions">dict</code><code class="python plain">(</code><code class="python functions">enumerate</code><code class="python plain">(data))</code></div><div class="line number7 index6 alt2">&nbsp;</div><div class="line number8 index7 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">matrix </code><code class="python keyword">=</code> <code class="python plain">np.zeros((</code><code class="python functions">len</code><code class="python plain">(words), </code><code class="python functions">len</code><code class="python plain">(data)))</code></div><div class="line number9 index8 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">for</code> <code class="python plain">docID, document </code><code class="python keyword">in</code> <code class="python functions">enumerate</code><code class="python plain">(data):</code></div><div class="line number10 index9 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">docWords </code><code class="python keyword">=</code> <code class="python plain">Counter(document[</code><code class="python string">'words'</code><code class="python plain">])</code></div><div class="line number11 index10 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">for</code> <code class="python plain">word, count </code><code class="python keyword">in</code> <code class="python plain">docWords.items():</code></div><div class="line number12 index11 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">matrix[wordToIndex[word], docID] </code><code class="python keyword">=</code> <code class="python plain">count</code></div><div class="line number13 index12 alt2">&nbsp;</div><div class="line number14 index13 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">return</code> <code class="python plain">matrix, (indexToWord, indexToDocument)</code></div></div></td></tr></tbody></table></div></div>
<p>This creates a matrix with the raw integer counts. But what we need is a normalized count. The idea is that a common word like “thing” shows up disproportionately more often than “election,” and we don’t want raw magnitude of a word count to outweigh its semantic contribution to the classification. This is the applied math part of the algorithm design. So what we’ll do (and this technique together with SVD is called latent semantic indexing) is normalize each entry so that it measures both the frequency of a term in a document and the relative frequency of a term compared to the global frequency of that term. There are <a href="https://en.wikipedia.org/wiki/Latent_semantic_indexing#Term-document_matrix">many ways</a> to do this, and we’ll just pick one. See the <a href="https://github.com/j2kun/svd">github repository</a> if you’re interested.</p>
<p>So now lets compute a rank 10 decomposition and see how to cluster the results.</p>
<div><div id="highlighter_978860" class="syntaxhighlighter  python"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python plain">data </code><code class="python keyword">=</code> <code class="python plain">load()</code></div><div class="line number2 index1 alt1"><code class="python plain">matrix, (indexToWord, indexToDocument) </code><code class="python keyword">=</code> <code class="python plain">makeDocumentTermMatrix(data)</code></div><div class="line number3 index2 alt2"><code class="python plain">matrix </code><code class="python keyword">=</code> <code class="python plain">normalize(matrix)</code></div><div class="line number4 index3 alt1"><code class="python plain">sigma, U, V </code><code class="python keyword">=</code> <code class="python plain">svd(matrix, k</code><code class="python keyword">=</code><code class="python value">10</code><code class="python plain">)</code></div></div></td></tr></tbody></table></div></div>
<p>This uses our svd, not numpy’s. Though numpy’s routine is much faster, it’s fun to see things work with code written from scratch. The result is too large to display here, but I can report the singular values.</p>
<div><div id="highlighter_582729" class="syntaxhighlighter  plain"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="plain plain">&gt;&gt;&gt; sigma</code></div><div class="line number2 index1 alt1"><code class="plain plain">array([ 42.85249098,&nbsp; 21.85641975,&nbsp; 19.15989197,&nbsp; 16.2403354 ,</code></div><div class="line number3 index2 alt2"><code class="plain spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="plain plain">15.40456779,&nbsp; 14.3172779 ,&nbsp; 13.47860033,&nbsp; 13.23795002,</code></div><div class="line number4 index3 alt1"><code class="plain spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="plain plain">12.98866537,&nbsp; 12.51307445])</code></div></div></td></tr></tbody></table></div></div>
<p>Now we take our original inputs and project them onto the subspace spanned by the singular vectors. This is the part that represents each word (resp., document) in terms of the idealized words (resp., documents), the singular vectors. Then we can apply a simple <a href="https://jeremykun.com/2013/02/04/k-means-clustering-and-birth-rates/">k-means clustering algorithm</a> to the result, and observe the resulting clusters as documents.</p>
<div><div id="highlighter_506677" class="syntaxhighlighter  python"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div><div class="line number9 index8 alt2">9</div><div class="line number10 index9 alt1">10</div><div class="line number11 index10 alt2">11</div><div class="line number12 index11 alt1">12</div><div class="line number13 index12 alt2">13</div><div class="line number14 index13 alt1">14</div><div class="line number15 index14 alt2">15</div><div class="line number16 index15 alt1">16</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python plain">projectedDocuments </code><code class="python keyword">=</code> <code class="python plain">np.dot(matrix.T, U)</code></div><div class="line number2 index1 alt1"><code class="python plain">projectedWords </code><code class="python keyword">=</code> <code class="python plain">np.dot(matrix, V.T)</code></div><div class="line number3 index2 alt2">&nbsp;</div><div class="line number4 index3 alt1"><code class="python plain">documentCenters, documentClustering </code><code class="python keyword">=</code> <code class="python plain">cluster(projectedDocuments)</code></div><div class="line number5 index4 alt2"><code class="python plain">wordCenters, wordClustering </code><code class="python keyword">=</code> <code class="python plain">cluster(projectedWords)</code></div><div class="line number6 index5 alt1">&nbsp;</div><div class="line number7 index6 alt2"><code class="python plain">wordClusters </code><code class="python keyword">=</code> <code class="python plain">[</code></div><div class="line number8 index7 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[indexToWord[i] </code><code class="python keyword">for</code> <code class="python plain">(i, x) </code><code class="python keyword">in</code> <code class="python functions">enumerate</code><code class="python plain">(wordClustering) </code><code class="python keyword">if</code> <code class="python plain">x </code><code class="python keyword">=</code><code class="python keyword">=</code> <code class="python plain">j]</code></div><div class="line number9 index8 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">for</code> <code class="python plain">j </code><code class="python keyword">in</code> <code class="python functions">range</code><code class="python plain">(</code><code class="python functions">len</code><code class="python plain">(</code><code class="python functions">set</code><code class="python plain">(wordClustering)))</code></div><div class="line number10 index9 alt1"><code class="python plain">]</code></div><div class="line number11 index10 alt2">&nbsp;</div><div class="line number12 index11 alt1"><code class="python plain">documentClusters </code><code class="python keyword">=</code> <code class="python plain">[</code></div><div class="line number13 index12 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">[indexToDocument[i][</code><code class="python string">'text'</code><code class="python plain">]</code></div><div class="line number14 index13 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">for</code> <code class="python plain">(i, x) </code><code class="python keyword">in</code> <code class="python functions">enumerate</code><code class="python plain">(documentClustering) </code><code class="python keyword">if</code> <code class="python plain">x </code><code class="python keyword">=</code><code class="python keyword">=</code> <code class="python plain">j]</code></div><div class="line number15 index14 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">for</code> <code class="python plain">j </code><code class="python keyword">in</code> <code class="python functions">range</code><code class="python plain">(</code><code class="python functions">len</code><code class="python plain">(</code><code class="python functions">set</code><code class="python plain">(documentClustering)))</code></div><div class="line number16 index15 alt1"><code class="python plain">]</code></div></div></td></tr></tbody></table></div></div>
<p>And now we can inspect individual clusters. Right off the bat we can tell the clusters aren’t quite right simply by looking at the sizes of each cluster.</p>
<div><div id="highlighter_976395" class="syntaxhighlighter  plain"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="plain plain">&gt;&gt;&gt; Counter(wordClustering)</code></div><div class="line number2 index1 alt1"><code class="plain plain">Counter({1: 9689, 2: 1051, 8: 680, 5: 557, 3: 321, 7: 225, 4: 174, 6: 124, 9: 123})</code></div><div class="line number3 index2 alt2"><code class="plain plain">&gt;&gt;&gt; Counter(documentClustering)</code></div><div class="line number4 index3 alt1"><code class="plain plain">Counter({7: 407, 6: 109, 0: 102, 5: 87, 9: 85, 2: 65, 8: 55, 4: 47, 3: 23, 1: 15})</code></div></div></td></tr></tbody></table></div></div>
<p>What looks wrong to me is the size of the largest word cluster. If we could group words by topic, then this is saying there’s a topic with over nine thousand words associated with it! Inspecting it even closer, it includes words like “vegan,” “skunk,” and “pope.” On the other hand, some word clusters are spot on. Examine, for example, the fifth cluster which includes words very clearly associated with crime stories.</p>
<div><div id="highlighter_839066" class="syntaxhighlighter  plain"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="plain plain">&gt;&gt;&gt; wordClusters[4]</code></div><div class="line number2 index1 alt1"><code class="plain plain">['account', 'accuse', 'act', 'affiliate', 'allegation', 'allege', 'altercation', 'anything', 'apartment', 'arrest', 'arrive', 'assault', 'attorney', 'authority', 'bag', 'black', 'blood', 'boy', 'brother', 'bullet', 'candy', 'car', 'carry', 'case', 'charge', 'chief', 'child', 'claim', 'client', 'commit', 'community', 'contact', 'convenience', 'court', 'crime', 'criminal', 'cry', 'dead', 'deadly', 'death', 'defense', 'department', 'describe', 'detail', 'determine', 'dispatcher', 'district', 'document', 'enforcement', 'evidence', 'extremely', 'family', 'father', 'fear', 'fiancee', 'file', 'five', 'foot', 'friend', 'front', 'gate', 'girl', 'girlfriend', 'grand', 'ground', 'guilty', 'gun', 'gunman', 'gunshot', 'hand', 'happen', 'harm', 'head', 'hear', 'heard', 'hoodie', 'hour', 'house', 'identify', 'immediately', 'incident', 'information', 'injury', 'investigate', 'investigation', 'investigator', 'involve', 'judge', 'jury', 'justice', 'kid', 'killing', 'lawyer', 'legal', 'letter', 'life', 'local', 'man', 'men', 'mile', 'morning', 'mother', 'murder', 'near', 'nearby', 'neighbor', 'newspaper', 'night', 'nothing', 'office', 'officer', 'online', 'outside', 'parent', 'person', 'phone', 'police', 'post', 'prison', 'profile', 'prosecute', 'prosecution', 'prosecutor', 'pull', 'racial', 'racist', 'release', 'responsible', 'return', 'review', 'role', 'saw', 'scene', 'school', 'scream', 'search', 'sentence', 'serve', 'several', 'shoot', 'shooter', 'shooting', 'shot', 'slur', 'someone', 'son', 'sound', 'spark', 'speak', 'staff', 'stand', 'store', 'story', 'student', 'surveillance', 'suspect', 'suspicious', 'tape', 'teacher', 'teen', 'teenager', 'told', 'tragedy', 'trial', 'vehicle', 'victim', 'video', 'walk', 'watch', 'wear', 'whether', 'white', 'witness', 'young']</code></div></div></td></tr></tbody></table></div></div>
<p>As sad as it makes me to see that ‘black’ and ‘slur’ and ‘racial’ appear in this category, it’s a reminder that naively using the output of a machine learning algorithm <a href="https://jeremykun.com/2015/07/13/what-does-it-mean-for-an-algorithm-to-be-fair/">can perpetuate racism</a>.</p>
<p>Here’s another interesting cluster corresponding to economic words:</p>
<div><div id="highlighter_651962" class="syntaxhighlighter  plain"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="plain plain">&gt;&gt;&gt; wordClusters[6]</code></div><div class="line number2 index1 alt1"><code class="plain plain">['agreement', 'aide', 'analyst', 'approval', 'approve', 'austerity', 'average', 'bailout', 'beneficiary', 'benefit', 'bill', 'billion', 'break', 'broadband', 'budget', 'class', 'combine', 'committee', 'compromise', 'conference', 'congressional', 'contribution', 'core', 'cost', 'currently', 'cut', 'deal', 'debt', 'defender', 'deficit', 'doc', 'drop', 'economic', 'economy', 'employee', 'employer', 'erode', 'eurozone', 'expire', 'extend', 'extension', 'fee', 'finance', 'fiscal', 'fix', 'fully', 'fund', 'funding', 'game', 'generally', 'gleefully', 'growth', 'hamper', 'highlight', 'hike', 'hire', 'holiday', 'increase', 'indifferent', 'insistence', 'insurance', 'job', 'juncture', 'latter', 'legislation', 'loser', 'low', 'lower', 'majority', 'maximum', 'measure', 'middle', 'negotiation', 'offset', 'oppose', 'package', 'pass', 'patient', 'pay', 'payment', 'payroll', 'pension', 'plight', 'portray', 'priority', 'proposal', 'provision', 'rate', 'recession', 'recovery', 'reduce', 'reduction', 'reluctance', 'repercussion', 'rest', 'revenue', 'rich', 'roughly', 'sale', 'saving', 'scientist', 'separate', 'sharp', 'showdown', 'sign', 'specialist', 'spectrum', 'spending', 'strength', 'tax', 'tea', 'tentative', 'term', 'test', 'top', 'trillion', 'turnaround', 'unemployed', 'unemployment', 'union', 'wage', 'welfare', 'worker', 'worth']</code></div></div></td></tr></tbody></table></div></div>
<p>One can also inspect the stories, though the clusters are harder to print out here. Interestingly the first cluster of documents are stories exclusively about Trayvon Martin. The second cluster is mostly international military conflicts. The third cluster also appears to be about international conflict, but what distinguishes it from the first cluster is that every story in the second cluster discusses Syria.</p>
<div><div id="highlighter_518894" class="syntaxhighlighter  plain"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="plain plain">&gt;&gt;&gt; len([x for x in documentClusters[1] if 'Syria' in x]) / len(documentClusters[1])</code></div><div class="line number2 index1 alt1"><code class="plain plain">0.05555555555555555</code></div><div class="line number3 index2 alt2"><code class="plain plain">&gt;&gt;&gt; len([x for x in documentClusters[2] if 'Syria' in x]) / len(documentClusters[2])</code></div><div class="line number4 index3 alt1"><code class="plain plain">1.0</code></div></div></td></tr></tbody></table></div></div>
<p>Anyway, you can explore the data more at your leisure (and tinker with the parameters to improve it!).</p>
<h2 style="text-align:center;">Issues with the power method</h2>
<p>Though&nbsp;I mentioned that the power method isn’t an industry strength algorithm I didn’t say why. Let’s revisit that before we finish. The problem is that the convergence rate of even the 1-dimensional problem depends on the ratio of the first and second singular values, <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(128).php" alt="\sigma_1 / \sigma_2" title="\sigma_1 / \sigma_2" class="latex" width="39" height="16" srcset="https://s0.wp.com/latex.php?latex=%5Csigma_1+%2F+%5Csigma_2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. If that ratio is very close to 1, then the convergence will take a long time and need many many matrix-vector multiplications.</p>
<p>One way to alleviate that is to do the trick where, to compute a large power of a matrix, you iteratively square <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(129).php" alt="B" title="B" class="latex" width="13" height="11" srcset="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5">. But that requires computing a matrix square (instead of a bunch of matrix-vector products), and that requires a lot of time and memory if the matrix isn’t sparse. When the matrix is sparse, you can actually do the power method quite quickly, from what I’ve heard and read.</p>
<p>But nevertheless, the industry standard methods involve computing a particular matrix decomposition that is not only faster than the power method, but also numerically stable. That means that the algorithm’s runtime and accuracy doesn’t depend on slight changes in the entries of the input matrix. Indeed, you can have two matrices where <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(128).php" alt="\sigma_1 / \sigma_2" title="\sigma_1 / \sigma_2" class="latex" width="39" height="16" srcset="https://s0.wp.com/latex.php?latex=%5Csigma_1+%2F+%5Csigma_2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> is very close to 1, but changing a single entry will make that ratio much larger. The power method depends on this, so it’s not numerically stable. But the industry standard technique is not. This technique involves something called <a href="https://en.wikipedia.org/wiki/Bidiagonalization">Householder reflections</a>. So while the power method was great for a proof of concept, there’s much more work to do if you want true SVD power.</p>
<p>Until next time!</p>
<div id="jp-post-flair" class="sharedaddy sd-like-enabled sd-sharing-enabled"><div class="sharedaddy sd-sharing-enabled"><div class="robots-nocontent sd-block sd-social sd-social-icon sd-sharing"><h3 class="sd-title">Share this:</h3><div class="sd-content"><ul><li class="share-facebook"><a rel="nofollow noopener noreferrer" data-shared="sharing-facebook-8329" class="share-facebook sd-button share-icon no-text" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?share=facebook&amp;nb=1" target="_blank" title="Click to share on Facebook"><span></span><span class="sharing-screen-reader-text">Click to share on Facebook (Opens in new window)</span></a></li><li class="share-reddit"><a rel="nofollow noopener noreferrer" data-shared="" class="share-reddit sd-button share-icon no-text" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?share=reddit&amp;nb=1" target="_blank" title="Click to share on Reddit"><span></span><span class="sharing-screen-reader-text">Click to share on Reddit (Opens in new window)</span></a></li><li class="share-twitter"><a rel="nofollow noopener noreferrer" data-shared="sharing-twitter-8329" class="share-twitter sd-button share-icon no-text" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?share=twitter&amp;nb=1" target="_blank" title="Click to share on Twitter"><span></span><span class="sharing-screen-reader-text">Click to share on Twitter (Opens in new window)</span></a></li><li><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#" class="sharing-anchor sd-button share-more"><span>More</span></a></li><li class="share-end"></li></ul><div class="sharing-hidden"><div class="inner" style="display: none;"><ul><li class="share-email share-service-visible"><a rel="nofollow noopener noreferrer" data-shared="" class="share-email sd-button share-icon no-text" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?share=email&amp;nb=1" target="_blank" title="Click to email this to a friend"><span></span><span class="sharing-screen-reader-text">Click to email this to a friend (Opens in new window)</span></a></li><li class="share-pinterest"><a rel="nofollow noopener noreferrer" data-shared="sharing-pinterest-8329" class="share-pinterest sd-button share-icon no-text" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?share=pinterest&amp;nb=1" target="_blank" title="Click to share on Pinterest"><span></span><span class="sharing-screen-reader-text">Click to share on Pinterest (Opens in new window)</span></a></li><li class="share-end"></li><li class="share-linkedin"><a rel="nofollow noopener noreferrer" data-shared="sharing-linkedin-8329" class="share-linkedin sd-button share-icon no-text" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?share=linkedin&amp;nb=1" target="_blank" title="Click to share on LinkedIn"><span></span><span class="sharing-screen-reader-text">Click to share on LinkedIn (Opens in new window)</span></a></li><li class="share-tumblr"><a rel="nofollow noopener noreferrer" data-shared="" class="share-tumblr sd-button share-icon no-text" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?share=tumblr&amp;nb=1" target="_blank" title="Click to share on Tumblr"><span></span><span class="sharing-screen-reader-text">Click to share on Tumblr (Opens in new window)</span></a></li><li class="share-end"></li><li class="share-end"></li></ul></div></div></div></div></div><div class="sharedaddy sd-block sd-like jetpack-likes-widget-wrapper jetpack-likes-widget-loaded" id="like-post-wrapper-23934684-8329-5dc100ce17986" data-src="//widgets.wp.com/likes/index.html?ver=20190321#blog_id=23934684&amp;post_id=8329&amp;origin=jeremykun.wordpress.com&amp;obj_id=23934684-8329-5dc100ce17986&amp;domain=jeremykun.com" data-name="like-post-frame-23934684-8329-5dc100ce17986"><h3 class="sd-title">Like this:</h3><div class="likes-widget-placeholder post-likes-widget-placeholder" style="height: 55px; display: none;"><span class="button"><span>Like</span></span> <span class="loading">Loading...</span></div><iframe class="post-likes-widget jetpack-likes-widget" name="like-post-frame-23934684-8329-5dc100ce17986" height="55px" width="100%" frameborder="0" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/index.html"></iframe><span class="sd-text-color"></span><a class="sd-link-color"></a></div>
<div id="jp-relatedposts" class="jp-relatedposts">
	
</div></div>			</div><!-- .entry-content -->

	<footer class="entry-meta">
		
		This entry was posted in <a href="https://jeremykun.com/category/algorithms/" rel="category tag">Algorithms</a>, <a href="https://jeremykun.com/category/data-mining-2/" rel="category tag">Data mining</a>, <a href="https://jeremykun.com/category/linear-algebra/" rel="category tag">Linear Algebra</a>, <a href="https://jeremykun.com/category/optimization-2/" rel="category tag">Optimization</a>, <a href="https://jeremykun.com/category/statistics/" rel="category tag">Statistics</a> and tagged <a href="https://jeremykun.com/tag/greedy-algorithm/" rel="tag">greedy algorithm</a>, <a href="https://jeremykun.com/tag/mathematics/" rel="tag">mathematics</a>, <a href="https://jeremykun.com/tag/optimization/" rel="tag">optimization</a>, <a href="https://jeremykun.com/tag/programming/" rel="tag">programming</a>, <a href="https://jeremykun.com/tag/python/" rel="tag">python</a>, <a href="https://jeremykun.com/tag/singular-value-decomposition/" rel="tag">singular value decomposition</a>. Bookmark the <a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/" title="Permalink to Singular Value Decomposition Part 2: Theorem, Proof, Algorithm" rel="bookmark">permalink</a>.
			</footer><!-- .entry-meta -->
</article><!-- #post-8329 -->

					<nav role="navigation" id="nav-below" class="site-navigation post-navigation">
		<h1 class="assistive-text">Post navigation</h1>

	
		<div class="nav-previous"><a href="https://jeremykun.com/2016/04/25/book-mailing-list/" rel="prev"><span class="meta-nav">←</span> Book mailing list</a></div>		<div class="nav-next"><a href="https://jeremykun.com/2016/07/05/zero-knowledge-proofs-a-primer/" rel="next">Zero Knowledge Proofs — A Primer <span class="meta-nav">→</span></a></div>
	
	</nav><!-- #nav-below -->
	
				

	<div id="comments" class="comments-area">

	
			<h2 class="comments-title">
			24 thoughts on “<span>Singular Value Decomposition Part 2: Theorem, Proof, Algorithm</span>”		</h2>

		<ol class="commentlist">
				<li class="comment even thread-even depth-1 highlander-comment" id="li-comment-53971">
		<article id="comment-53971" class="comment">
			<footer class="clear">
				<div class="comment-author vcard">
					<span><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/899b321d1e724bf1e214fc96e596771c" class="avatar avatar-44 grav-hashed grav-hijack" height="44" width="44" originals="44" src-orig="https://2.gravatar.com/avatar/899b321d1e724bf1e214fc96e596771c?s=44&amp;d=identicon&amp;r=G" scale="1.5" id="grav-899b321d1e724bf1e214fc96e596771c-0"></span>
					<cite class="fn">AnlamK</cite>				</div><!-- .comment-author .vcard -->

				<div class="comment-meta commentmetadata">
					<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-53971"><time pubdate="" datetime="2016-05-16T14:51:28-07:00">
					May 16, 2016 at 2:51 pm					</time></a>
										<a rel="nofollow" class="comment-reply-link" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?replytocom=53971#respond" data-commentid="53971" data-postid="8329" data-belowelement="comment-53971" data-respondelement="respond" aria-label="Reply to AnlamK">Reply</a>				</div><!-- .comment-meta .commentmetadata -->
			</footer>

			<div class="comment-content">
				<p>“It is also easy to see why the u_i are orthogonal (prove it as an exercise)”</p>
<p>Well, I know that A can be polar decomposed as A = S sqrt(T*T), where S is an isometry and T*T (T* is the Hilbert-adjoint of T) is positive semi-definite, whose eigenvectors are the v_i. Wtih few more details, this explains why the u_i are orthogonal. (See Linear Algebra Done Right by Axler for more details.)</p>
<p>But I can’t quite see how we can make a simpler argument just based on the contents of this article. I’ll keep thinking though.</p>
<p id="comment-like-53971" data-liked="comment-not-liked" class="comment-likes comment-not-liked"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?like_comment=53971&amp;_wpnonce=e6a3290395" class="comment-like-link needs-login" rel="nofollow" data-blog="23934684"><span>Like</span></a><span id="comment-like-count-53971" class="comment-like-feedback">Like</span></p>
							</div>

		</article><!-- #comment-## -->

	<ul class="children">
	<li class="comment byuser comment-author-efcholla odd alt depth-2 highlander-comment" id="li-comment-53976">
		<article id="comment-53976" class="comment">
			<footer class="clear">
				<div class="comment-author vcard">
					<span><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/709674d8a8b5c54d4b785d40a71be503.jpeg" class="avatar avatar-44 grav-hashed grav-hijack" height="44" width="44" originals="44" src-orig="https://1.gravatar.com/avatar/709674d8a8b5c54d4b785d40a71be503?s=44&amp;d=identicon&amp;r=G" scale="1.5" id="grav-709674d8a8b5c54d4b785d40a71be503-0"></span>
					<cite class="fn"><a href="http://efcholla.wordpress.com/" rel="external nofollow ugc" class="url">EFCHolla</a></cite>				</div><!-- .comment-author .vcard -->

				<div class="comment-meta commentmetadata">
					<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-53976"><time pubdate="" datetime="2016-05-17T02:20:17-07:00">
					May 17, 2016 at 2:20 am					</time></a>
										<a rel="nofollow" class="comment-reply-link" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?replytocom=53976#respond" data-commentid="53976" data-postid="8329" data-belowelement="comment-53976" data-respondelement="respond" aria-label="Reply to EFCHolla">Reply</a>				</div><!-- .comment-meta .commentmetadata -->
			</footer>

			<div class="comment-content">
				<p>Can’t figure out a proof for the orthogonality of u_i too.</p>
<p id="comment-like-53976" data-liked="comment-not-liked" class="comment-likes comment-not-liked"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?like_comment=53976&amp;_wpnonce=a913e1755b" class="comment-like-link needs-login" rel="nofollow" data-blog="23934684"><span>Like</span></a><span id="comment-like-count-53976" class="comment-like-feedback">Like</span></p>
							</div>

		</article><!-- #comment-## -->

	</li><!-- #comment-## -->
	<li class="comment even depth-2 highlander-comment" id="li-comment-54356">
		<article id="comment-54356" class="comment">
			<footer class="clear">
				<div class="comment-author vcard">
					<span><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/589f2a3d31656708eb697e68826c8553" class="avatar avatar-44 grav-hashed grav-hijack" height="44" width="44" originals="44" src-orig="https://2.gravatar.com/avatar/589f2a3d31656708eb697e68826c8553?s=44&amp;d=identicon&amp;r=G" scale="1.5" id="grav-589f2a3d31656708eb697e68826c8553-0"></span>
					<cite class="fn">D</cite>				</div><!-- .comment-author .vcard -->

				<div class="comment-meta commentmetadata">
					<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-54356"><time pubdate="" datetime="2016-07-15T17:27:44-07:00">
					July 15, 2016 at 5:27 pm					</time></a>
										<a rel="nofollow" class="comment-reply-link" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?replytocom=54356#respond" data-commentid="54356" data-postid="8329" data-belowelement="comment-54356" data-respondelement="respond" aria-label="Reply to D">Reply</a>				</div><!-- .comment-meta .commentmetadata -->
			</footer>

			<div class="comment-content">
				<p>My approach is straightforward.  It feels like a mix of a sandwich and perhaps cheating.  It is to ask that you calculate the SVD for this matrix A, as in the article, and for this other matrix B.  In both cases you get some kind of factorization of U, Diagonal Matrix with Singular Values, and then the V, which in its transposed form has orthogonal vectors in its rows.  </p>
<p>Then I tell you that B is just $A^T$.  So if you transpose your original factorisation of A, you get the new factorisation for B.  The Diagonal Matrix is unchanged (at least if A is square, otherwise it is still the ‘same’ but with different dimensions).  The key thing is that when you decomposed B, you knew the third matrix — $V^T$ — had orthogonal rows.  But if you tranpose B and ‘convert’ it back into A, the $V^T$ for B’s factorisation is transposed into the U position and hence those orthogonal rows became orthogonal columns for U in A.  </p>
<p>Alternatively, there is a mathy-er explanation here:<br>
<a href="http://codingthematrix.com/proof-that-U-is-column-orthogonal0.pdf" rel="nofollow ugc">http://codingthematrix.com/proof-that-U-is-column-orthogonal0.pdf</a></p>
<p id="comment-like-54356" data-liked="comment-not-liked" class="comment-likes comment-not-liked"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?like_comment=54356&amp;_wpnonce=4547a23f14" class="comment-like-link needs-login" rel="nofollow" data-blog="23934684"><span>Like</span></a><span id="comment-like-count-54356" class="comment-like-feedback">Like</span></p>
							</div>

		</article><!-- #comment-## -->

	<ul class="children">
	<li class="comment odd alt depth-3 highlander-comment" id="li-comment-54493">
		<article id="comment-54493" class="comment">
			<footer class="clear">
				<div class="comment-author vcard">
					<span><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/74fb05adf8ebc3e0a8af02762f1bd0b0" class="avatar avatar-44 grav-hashed grav-hijack" height="44" width="44" originals="44" src-orig="https://1.gravatar.com/avatar/74fb05adf8ebc3e0a8af02762f1bd0b0?s=44&amp;d=identicon&amp;r=G" scale="1.5" id="grav-74fb05adf8ebc3e0a8af02762f1bd0b0-0"></span>
					<cite class="fn">ab</cite>				</div><!-- .comment-author .vcard -->

				<div class="comment-meta commentmetadata">
					<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-54493"><time pubdate="" datetime="2016-08-04T21:25:09-07:00">
					August 4, 2016 at 9:25 pm					</time></a>
														</div><!-- .comment-meta .commentmetadata -->
			</footer>

			<div class="comment-content">
				<p>Another solution:</p>
<p>Let 1 ≤ i,j ≤ r</p>
<p> = uᵢᵀ ⋅ uⱼ<br>
= (A ⋅ vᵢ / 𝜎ᵢ)ᵀ ⋅ (A ⋅ vⱼ / 𝜎ⱼ)<br>
= vᵢᵀ ⋅ Aᵀ ⋅ A ⋅ vⱼ / (𝜎ᵢ * 𝜎ⱼ)</p>
<p>We know that vⱼ is an eigenvector of (Aᵀ ⋅ A) with corresponding eigenvalue 𝜎ⱼ²</p>
<p> = 𝜎ⱼ² vᵢᵀ ⋅ vⱼ / (𝜎ᵢ * 𝜎ⱼ) = (𝜎ⱼ/𝜎ᵢ) </p>
<p>and, since {v₁, … , vₙ} is orthonormal,</p>
<p> = 𝛿(i,j)</p>
<p id="comment-like-54493" data-liked="comment-not-liked" class="comment-likes comment-not-liked"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?like_comment=54493&amp;_wpnonce=5353928494" class="comment-like-link needs-login" rel="nofollow" data-blog="23934684"><span>Like</span></a><span id="comment-like-count-54493" class="comment-like-feedback">Like</span></p>
							</div>

		</article><!-- #comment-## -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment even depth-2 highlander-comment" id="li-comment-93211">
		<article id="comment-93211" class="comment">
			<footer class="clear">
				<div class="comment-author vcard">
					<span><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/34147608ed4560acae55f4858aeb0ab7" class="avatar avatar-44 grav-hashed grav-hijack" height="44" width="44" originals="44" src-orig="https://0.gravatar.com/avatar/34147608ed4560acae55f4858aeb0ab7?s=44&amp;d=identicon&amp;r=G" scale="1.5" id="grav-34147608ed4560acae55f4858aeb0ab7-0"></span>
					<cite class="fn">mihnea</cite>				</div><!-- .comment-author .vcard -->

				<div class="comment-meta commentmetadata">
					<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-93211"><time pubdate="" datetime="2019-07-06T03:22:49-07:00">
					July 6, 2019 at 3:22 am					</time></a>
										<a rel="nofollow" class="comment-reply-link" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?replytocom=93211#respond" data-commentid="93211" data-postid="8329" data-belowelement="comment-93211" data-respondelement="respond" aria-label="Reply to mihnea">Reply</a>				</div><!-- .comment-meta .commentmetadata -->
			</footer>

			<div class="comment-content">
				<p>Great post! Could you please elaborate on how the u_i can be proven orthogonal, following the line of reasoning in the article?</p>
<p id="comment-like-93211" data-liked="comment-not-liked" class="comment-likes comment-not-liked"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?like_comment=93211&amp;_wpnonce=f970268975" class="comment-like-link needs-login" rel="nofollow" data-blog="23934684"><span>Like</span></a><span id="comment-like-count-93211" class="comment-like-feedback">Like</span></p>
							</div>

		</article><!-- #comment-## -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment odd alt thread-odd thread-alt depth-1 highlander-comment" id="li-comment-53978">
		<article id="comment-53978" class="comment">
			<footer class="clear">
				<div class="comment-author vcard">
					<span><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/a7e744113723dd9b1d6d4e5294358bad" class="avatar avatar-44 grav-hashed grav-hijack" height="44" width="44" originals="44" src-orig="https://1.gravatar.com/avatar/a7e744113723dd9b1d6d4e5294358bad?s=44&amp;d=identicon&amp;r=G" scale="1.5" id="grav-a7e744113723dd9b1d6d4e5294358bad-0"></span>
					<cite class="fn">daniel</cite>				</div><!-- .comment-author .vcard -->

				<div class="comment-meta commentmetadata">
					<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-53978"><time pubdate="" datetime="2016-05-17T06:57:40-07:00">
					May 17, 2016 at 6:57 am					</time></a>
										<a rel="nofollow" class="comment-reply-link" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?replytocom=53978#respond" data-commentid="53978" data-postid="8329" data-belowelement="comment-53978" data-respondelement="respond" aria-label="Reply to daniel">Reply</a>				</div><!-- .comment-meta .commentmetadata -->
			</footer>

			<div class="comment-content">
				<p>I just read the first lines, but I  think there is an error in the first equation, if y= av is the projection of x over the unit vector v then<br>
 x = x-av + av = x-y + y and now x-y and y are ortogonal, so<br>
|x|^2 = |x-av|^2 + |av|^2, but |x – av| is not the distance between x and v.   So the equation is wrong.</p>
<p id="comment-like-53978" data-liked="comment-not-liked" class="comment-likes comment-not-liked"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?like_comment=53978&amp;_wpnonce=4548b00aa7" class="comment-like-link needs-login" rel="nofollow" data-blog="23934684"><span>Like</span></a><span id="comment-like-count-53978" class="comment-like-feedback">Like</span></p>
							</div>

		</article><!-- #comment-## -->

	</li><!-- #comment-## -->
	<li class="comment even thread-even depth-1 highlander-comment" id="li-comment-53979">
		<article id="comment-53979" class="comment">
			<footer class="clear">
				<div class="comment-author vcard">
					<span><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/a7e744113723dd9b1d6d4e5294358bad" class="avatar avatar-44 grav-hashed grav-hijack" height="44" width="44" originals="44" src-orig="https://1.gravatar.com/avatar/a7e744113723dd9b1d6d4e5294358bad?s=44&amp;d=identicon&amp;r=G" scale="1.5" id="grav-a7e744113723dd9b1d6d4e5294358bad-1"></span>
					<cite class="fn">daniel</cite>				</div><!-- .comment-author .vcard -->

				<div class="comment-meta commentmetadata">
					<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-53979"><time pubdate="" datetime="2016-05-17T07:07:03-07:00">
					May 17, 2016 at 7:07 am					</time></a>
										<a rel="nofollow" class="comment-reply-link" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?replytocom=53979#respond" data-commentid="53979" data-postid="8329" data-belowelement="comment-53979" data-respondelement="respond" aria-label="Reply to daniel">Reply</a>				</div><!-- .comment-meta .commentmetadata -->
			</footer>

			<div class="comment-content">
				<p>Sorry for the noise, I reread the post and you define d_v(x) as   d(L(v),x)  with L(v) the linear span of v.  So the equation is right.</p>
<p id="comment-like-53979" data-liked="comment-not-liked" class="comment-likes comment-not-liked"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?like_comment=53979&amp;_wpnonce=d0c9ab50aa" class="comment-like-link needs-login" rel="nofollow" data-blog="23934684"><span>Like</span></a><span id="comment-like-count-53979" class="comment-like-feedback">Like</span></p>
							</div>

		</article><!-- #comment-## -->

	</li><!-- #comment-## -->
	<li class="comment odd alt thread-odd thread-alt depth-1 highlander-comment" id="li-comment-54008">
		<article id="comment-54008" class="comment">
			<footer class="clear">
				<div class="comment-author vcard">
					<span><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/5bc5aaf4d3a7d64f5121b605f046d930" class="avatar avatar-44 grav-hashed grav-hijack" height="44" width="44" originals="44" src-orig="https://2.gravatar.com/avatar/5bc5aaf4d3a7d64f5121b605f046d930?s=44&amp;d=identicon&amp;r=G" scale="1.5" id="grav-5bc5aaf4d3a7d64f5121b605f046d930-0"></span>
					<cite class="fn">Nir</cite>				</div><!-- .comment-author .vcard -->

				<div class="comment-meta commentmetadata">
					<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-54008"><time pubdate="" datetime="2016-05-22T02:52:46-07:00">
					May 22, 2016 at 2:52 am					</time></a>
										<a rel="nofollow" class="comment-reply-link" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?replytocom=54008#respond" data-commentid="54008" data-postid="8329" data-belowelement="comment-54008" data-respondelement="respond" aria-label="Reply to Nir">Reply</a>				</div><!-- .comment-meta .commentmetadata -->
			</footer>

			<div class="comment-content">
				<p>״Well formally they only span a basis of the column space of A…”<br>
Should this be row space?</p>
<p>Great post.</p>
<p id="comment-like-54008" data-liked="comment-not-liked" class="comment-likes comment-not-liked"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?like_comment=54008&amp;_wpnonce=33cee5a08c" class="comment-like-link needs-login" rel="nofollow" data-blog="23934684"><span>Like</span></a><span id="comment-like-count-54008" class="comment-like-feedback">Like</span></p>
							</div>

		</article><!-- #comment-## -->

	<ul class="children">
	<li class="comment byuser comment-author-jeremykun bypostauthor even depth-2 highlander-comment" id="li-comment-55277">
		<article id="comment-55277" class="comment">
			<footer class="clear">
				<div class="comment-author vcard">
					<span><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/90b179348780a6e7fe8e502968dc534a.jpeg" class="avatar avatar-44 grav-hashed grav-hijack" height="44" width="44" originals="44" src-orig="https://0.gravatar.com/avatar/90b179348780a6e7fe8e502968dc534a?s=44&amp;d=identicon&amp;r=G" scale="1.5" id="grav-90b179348780a6e7fe8e502968dc534a-0"></span>
					<cite class="fn"><a href="https://jeremykun.wordpress.com/" rel="external nofollow ugc" class="url">j2kun</a></cite>				</div><!-- .comment-author .vcard -->

				<div class="comment-meta commentmetadata">
					<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-55277"><time pubdate="" datetime="2016-12-01T08:04:38-08:00">
					December 1, 2016 at 8:04 am					</time></a>
										<a rel="nofollow" class="comment-reply-link" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?replytocom=55277#respond" data-commentid="55277" data-postid="8329" data-belowelement="comment-55277" data-respondelement="respond" aria-label="Reply to j2kun">Reply</a>				</div><!-- .comment-meta .commentmetadata -->
			</footer>

			<div class="comment-content">
				<p>Yes you’re right. Fixed. Ironic how that mistake was in a sanity check <img draggable="false" role="img" class="emoji" alt="🙂" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/1f642.svg" scale="0"></p>
<p id="comment-like-55277" data-liked="comment-not-liked" class="comment-likes comment-not-liked"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?like_comment=55277&amp;_wpnonce=8ae6087167" class="comment-like-link needs-login" rel="nofollow" data-blog="23934684"><span>Like</span></a><span id="comment-like-count-55277" class="comment-like-feedback">Like</span></p>
							</div>

		</article><!-- #comment-## -->

	<ul class="children">
	<li class="comment odd alt depth-3 highlander-comment" id="li-comment-62041">
		<article id="comment-62041" class="comment">
			<footer class="clear">
				<div class="comment-author vcard">
					<span><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/acaa01eedaf2f4341cedb808705bc910" class="avatar avatar-44 grav-hashed grav-hijack" height="44" width="44" originals="44" src-orig="https://1.gravatar.com/avatar/acaa01eedaf2f4341cedb808705bc910?s=44&amp;d=identicon&amp;r=G" scale="1.5" id="grav-acaa01eedaf2f4341cedb808705bc910-0"></span>
					<cite class="fn">Andy</cite>				</div><!-- .comment-author .vcard -->

				<div class="comment-meta commentmetadata">
					<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-62041"><time pubdate="" datetime="2018-06-13T14:56:31-07:00">
					June 13, 2018 at 2:56 pm					</time></a>
														</div><!-- .comment-meta .commentmetadata -->
			</footer>

			<div class="comment-content">
				<p>Hey, are you sure the decomposition would work, in that U would be an orthonormal matrix? I think if we project onto any orthogonal V of our choosing there is a chance U will not be orthogonal.</p>
<p id="comment-like-62041" data-liked="comment-not-liked" class="comment-likes comment-not-liked"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?like_comment=62041&amp;_wpnonce=45fd242f75" class="comment-like-link needs-login" rel="nofollow" data-blog="23934684"><span>Like</span></a><span id="comment-like-count-62041" class="comment-like-feedback">Like</span></p>
							</div>

		</article><!-- #comment-## -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment even thread-even depth-1 highlander-comment" id="li-comment-54028">
		<article id="comment-54028" class="comment">
			<footer class="clear">
				<div class="comment-author vcard">
					<span><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/32f8f96ce5e384abf5dda6dcd60d089a" class="avatar avatar-44 grav-hashed grav-hijack" height="44" width="44" originals="44" src-orig="https://0.gravatar.com/avatar/32f8f96ce5e384abf5dda6dcd60d089a?s=44&amp;d=identicon&amp;r=G" scale="1.5" id="grav-32f8f96ce5e384abf5dda6dcd60d089a-0"></span>
					<cite class="fn"><a href="http://gravatar.com/lancexnorskog" rel="external nofollow ugc" class="url">Lance Norskog</a></cite>				</div><!-- .comment-author .vcard -->

				<div class="comment-meta commentmetadata">
					<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-54028"><time pubdate="" datetime="2016-05-25T14:52:52-07:00">
					May 25, 2016 at 2:52 pm					</time></a>
										<a rel="nofollow" class="comment-reply-link" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?replytocom=54028#respond" data-commentid="54028" data-postid="8329" data-belowelement="comment-54028" data-respondelement="respond" aria-label="Reply to Lance Norskog">Reply</a>				</div><!-- .comment-meta .commentmetadata -->
			</footer>

			<div class="comment-content">
				<p>An idle question about SVD: suppose I take a series of digital photos with the ‘hold down for multiple’ feature on my camera. I do an SVD of the first photo, set the trailing singular values to 0, multiply the UeV matrics back together to get a denoised version of my photo.</p>
<p>    The SVD output from a photo creates a data model for denoising that photo. Is there any way to use the SVD output of the one photo to denoise the remaining photos? After all, the remaining photos are very similar to the first, since they were shot in sequence with the same sensor, lighting, etc.</p>
<p id="comment-like-54028" data-liked="comment-not-liked" class="comment-likes comment-not-liked"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?like_comment=54028&amp;_wpnonce=62b26707c7" class="comment-like-link needs-login" rel="nofollow" data-blog="23934684"><span>Like</span></a><span id="comment-like-count-54028" class="comment-like-feedback">Like</span></p>
							</div>

		</article><!-- #comment-## -->

	</li><!-- #comment-## -->
	<li class="comment odd alt thread-odd thread-alt depth-1 highlander-comment" id="li-comment-54248">
		<article id="comment-54248" class="comment">
			<footer class="clear">
				<div class="comment-author vcard">
					<span><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/0f7dcfffea377349e74559a09945c013" class="avatar avatar-44 grav-hashed grav-hijack" height="44" width="44" originals="44" src-orig="https://0.gravatar.com/avatar/0f7dcfffea377349e74559a09945c013?s=44&amp;d=identicon&amp;r=G" scale="1.5" id="grav-0f7dcfffea377349e74559a09945c013-0"></span>
					<cite class="fn"><a href="http://junpenglao.xyz/" rel="external nofollow ugc" class="url">Charles Lao</a></cite>				</div><!-- .comment-author .vcard -->

				<div class="comment-meta commentmetadata">
					<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-54248"><time pubdate="" datetime="2016-07-01T01:56:26-07:00">
					July 1, 2016 at 1:56 am					</time></a>
										<a rel="nofollow" class="comment-reply-link" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?replytocom=54248#respond" data-commentid="54248" data-postid="8329" data-belowelement="comment-54248" data-respondelement="respond" aria-label="Reply to Charles Lao">Reply</a>				</div><!-- .comment-meta .commentmetadata -->
			</footer>

			<div class="comment-content">
				<p>Thanks Jeremy, great posts as always.<br>
After reading the two posts, I have to say the greedy algorithm analogy click for me as well <img draggable="false" role="img" class="emoji" alt="😉" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/1f609.svg" scale="0"></p>
<p id="comment-like-54248" data-liked="comment-not-liked" class="comment-likes comment-not-liked"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?like_comment=54248&amp;_wpnonce=d20ce678c9" class="comment-like-link needs-login" rel="nofollow" data-blog="23934684"><span>Like</span></a><span id="comment-like-count-54248" class="comment-like-feedback">Like</span></p>
							</div>

		</article><!-- #comment-## -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-sethuiyer even thread-even depth-1 highlander-comment" id="li-comment-54283">
		<article id="comment-54283" class="comment">
			<footer class="clear">
				<div class="comment-author vcard">
					<span><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/f1f1ba12bbcb225b4d7af4e791e0b7d1(1).png" class="avatar avatar-44 grav-hashed grav-hijack" height="44" width="44" originals="44" src-orig="https://0.gravatar.com/avatar/f1f1ba12bbcb225b4d7af4e791e0b7d1?s=44&amp;d=identicon&amp;r=G" scale="1.5" id="grav-f1f1ba12bbcb225b4d7af4e791e0b7d1-0"></span>
					<cite class="fn"><a href="http://brobear1995.github.io/" rel="external nofollow ugc" class="url">sethuiyer</a></cite>				</div><!-- .comment-author .vcard -->

				<div class="comment-meta commentmetadata">
					<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-54283"><time pubdate="" datetime="2016-07-06T11:01:59-07:00">
					July 6, 2016 at 11:01 am					</time></a>
										<a rel="nofollow" class="comment-reply-link" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?replytocom=54283#respond" data-commentid="54283" data-postid="8329" data-belowelement="comment-54283" data-respondelement="respond" aria-label="Reply to sethuiyer">Reply</a>				</div><!-- .comment-meta .commentmetadata -->
			</footer>

			<div class="comment-content">
				<p>Spent the entire day reading both the parts and understood this concept very well. Thanks for explaining so clearly.</p>
<p id="comment-like-54283" data-liked="comment-not-liked" class="comment-likes comment-not-liked"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?like_comment=54283&amp;_wpnonce=a7086721b9" class="comment-like-link needs-login" rel="nofollow" data-blog="23934684"><span>Like</span></a><span id="comment-like-count-54283" class="comment-like-feedback">Like</span></p>
							</div>

		</article><!-- #comment-## -->

	</li><!-- #comment-## -->
	<li class="comment odd alt thread-odd thread-alt depth-1 highlander-comment" id="li-comment-54357">
		<article id="comment-54357" class="comment">
			<footer class="clear">
				<div class="comment-author vcard">
					<span><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/589f2a3d31656708eb697e68826c8553" class="avatar avatar-44 grav-hashed grav-hijack" height="44" width="44" originals="44" src-orig="https://2.gravatar.com/avatar/589f2a3d31656708eb697e68826c8553?s=44&amp;d=identicon&amp;r=G" scale="1.5" id="grav-589f2a3d31656708eb697e68826c8553-1"></span>
					<cite class="fn">D</cite>				</div><!-- .comment-author .vcard -->

				<div class="comment-meta commentmetadata">
					<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-54357"><time pubdate="" datetime="2016-07-15T17:51:20-07:00">
					July 15, 2016 at 5:51 pm					</time></a>
										<a rel="nofollow" class="comment-reply-link" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?replytocom=54357#respond" data-commentid="54357" data-postid="8329" data-belowelement="comment-54357" data-respondelement="respond" aria-label="Reply to D">Reply</a>				</div><!-- .comment-meta .commentmetadata -->
			</footer>

			<div class="comment-content">
				<p>Overall a very good read.  </p>
<p>One nit at the end:  shouldn’t the end really say the the rate of convergence in the power method is <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(130).php" alt="\propto \lambda_1/ \lambda_2" title="\propto \lambda_1/ \lambda_2" class="latex" width="56" height="16" srcset="https://s0.wp.com/latex.php?latex=%5Cpropto+%5Clambda_1%2F+%5Clambda_2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> where <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(131).php" alt="\lambda_1 = \sigma_1^2" title="\lambda_1 = \sigma_1^2" class="latex" width="54" height="19" srcset="https://s0.wp.com/latex.php?latex=%5Clambda_1+%3D+%5Csigma_1%5E2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"> and <img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/latex(132).php" alt="\lambda_2 = \sigma_2^2" title="\lambda_2 = \sigma_2^2" class="latex" width="54" height="18" srcset="https://s0.wp.com/latex.php?latex=%5Clambda_2+%3D+%5Csigma_2%5E2&amp;bg=ffffff&amp;fg=36312d&amp;s=0&amp;zoom=2 1.5x" scale="1.5"></p>
<p>It is after all the eigs that determine convergence for the Power Method.</p>
<p id="comment-like-54357" data-liked="comment-not-liked" class="comment-likes comment-not-liked"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?like_comment=54357&amp;_wpnonce=b86afb0425" class="comment-like-link needs-login" rel="nofollow" data-blog="23934684"><span>Like</span></a><span id="comment-like-count-54357" class="comment-like-feedback">Like</span></p>
							</div>

		</article><!-- #comment-## -->

	</li><!-- #comment-## -->
	<li class="comment even thread-even depth-1 highlander-comment" id="li-comment-55276">
		<article id="comment-55276" class="comment">
			<footer class="clear">
				<div class="comment-author vcard">
					<span><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/42aace5028b0b87571be854212620104" class="avatar avatar-44 grav-hashed grav-hijack" height="44" width="44" originals="44" src-orig="https://1.gravatar.com/avatar/42aace5028b0b87571be854212620104?s=44&amp;d=identicon&amp;r=G" scale="1.5" id="grav-42aace5028b0b87571be854212620104-0"></span>
					<cite class="fn">drz</cite>				</div><!-- .comment-author .vcard -->

				<div class="comment-meta commentmetadata">
					<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-55276"><time pubdate="" datetime="2016-12-01T07:28:15-08:00">
					December 1, 2016 at 7:28 am					</time></a>
										<a rel="nofollow" class="comment-reply-link" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?replytocom=55276#respond" data-commentid="55276" data-postid="8329" data-belowelement="comment-55276" data-respondelement="respond" aria-label="Reply to drz">Reply</a>				</div><!-- .comment-meta .commentmetadata -->
			</footer>

			<div class="comment-content">
				<p>I agree the comment with Nir, could anyone pls given some explanation regarding this point?</p>
<p id="comment-like-55276" data-liked="comment-not-liked" class="comment-likes comment-not-liked"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?like_comment=55276&amp;_wpnonce=9745500178" class="comment-like-link needs-login" rel="nofollow" data-blog="23934684"><span>Like</span></a><span id="comment-like-count-55276" class="comment-like-feedback">Like</span></p>
							</div>

		</article><!-- #comment-## -->

	<ul class="children">
	<li class="comment byuser comment-author-jeremykun bypostauthor odd alt depth-2 highlander-comment" id="li-comment-55278">
		<article id="comment-55278" class="comment">
			<footer class="clear">
				<div class="comment-author vcard">
					<span><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/90b179348780a6e7fe8e502968dc534a.jpeg" class="avatar avatar-44 grav-hashed grav-hijack" height="44" width="44" originals="44" src-orig="https://0.gravatar.com/avatar/90b179348780a6e7fe8e502968dc534a?s=44&amp;d=identicon&amp;r=G" scale="1.5" id="grav-90b179348780a6e7fe8e502968dc534a-1"></span>
					<cite class="fn"><a href="https://jeremykun.wordpress.com/" rel="external nofollow ugc" class="url">j2kun</a></cite>				</div><!-- .comment-author .vcard -->

				<div class="comment-meta commentmetadata">
					<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-55278"><time pubdate="" datetime="2016-12-01T08:04:54-08:00">
					December 1, 2016 at 8:04 am					</time></a>
										<a rel="nofollow" class="comment-reply-link" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?replytocom=55278#respond" data-commentid="55278" data-postid="8329" data-belowelement="comment-55278" data-respondelement="respond" aria-label="Reply to j2kun">Reply</a>				</div><!-- .comment-meta .commentmetadata -->
			</footer>

			<div class="comment-content">
				<p>Nir is correct. I have fixed the post.</p>
<p id="comment-like-55278" data-liked="comment-not-liked" class="comment-likes comment-not-liked"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?like_comment=55278&amp;_wpnonce=28b1404ab2" class="comment-like-link needs-login" rel="nofollow" data-blog="23934684"><span>Like</span></a><span id="comment-like-count-55278" class="comment-like-feedback">Like</span></p>
							</div>

		</article><!-- #comment-## -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-amitm02 even thread-odd thread-alt depth-1 highlander-comment" id="li-comment-55599">
		<article id="comment-55599" class="comment">
			<footer class="clear">
				<div class="comment-author vcard">
					<span><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/8b27349917970925b591f026bf23d3bb.jpeg" class="avatar avatar-44 grav-hashed grav-hijack" height="44" width="44" originals="44" src-orig="https://2.gravatar.com/avatar/8b27349917970925b591f026bf23d3bb?s=44&amp;d=identicon&amp;r=G" scale="1.5" id="grav-8b27349917970925b591f026bf23d3bb-0"></span>
					<cite class="fn">amitm02</cite>				</div><!-- .comment-author .vcard -->

				<div class="comment-meta commentmetadata">
					<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-55599"><time pubdate="" datetime="2017-01-18T08:10:18-08:00">
					January 18, 2017 at 8:10 am					</time></a>
										<a rel="nofollow" class="comment-reply-link" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?replytocom=55599#respond" data-commentid="55599" data-postid="8329" data-belowelement="comment-55599" data-respondelement="respond" aria-label="Reply to amitm02">Reply</a>				</div><!-- .comment-meta .commentmetadata -->
			</footer>

			<div class="comment-content">
				<p>Awesome article,</p>
<p>One thing confuses me.<br>
The way you constructed the SVD make it seems like i could generate an alternative SVD decompostion by picking a random orthogonal matrix V, calculate the sigmas as the sum squared distance of A from the columns of V and set up U columns with the formula you provided (u_i=A*v_i/sigma_i).<br>
But SVD decomposition should be unique, so what am i missing?<br>
Why this decomposition method only works when selecting V columns as the vectors with the minimum least squares distance from of A rows?</p>
<p id="comment-like-55599" data-liked="comment-not-liked" class="comment-likes comment-not-liked"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?like_comment=55599&amp;_wpnonce=199d7497b9" class="comment-like-link needs-login" rel="nofollow" data-blog="23934684"><span>Like</span></a><span id="comment-like-count-55599" class="comment-like-feedback">Like</span></p>
							</div>

		</article><!-- #comment-## -->

	<ul class="children">
	<li class="comment byuser comment-author-jeremykun bypostauthor odd alt depth-2 highlander-comment" id="li-comment-55600">
		<article id="comment-55600" class="comment">
			<footer class="clear">
				<div class="comment-author vcard">
					<span><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/90b179348780a6e7fe8e502968dc534a.jpeg" class="avatar avatar-44 grav-hashed grav-hijack" height="44" width="44" originals="44" src-orig="https://0.gravatar.com/avatar/90b179348780a6e7fe8e502968dc534a?s=44&amp;d=identicon&amp;r=G" scale="1.5" id="grav-90b179348780a6e7fe8e502968dc534a-2"></span>
					<cite class="fn"><a href="https://jeremykun.wordpress.com/" rel="external nofollow ugc" class="url">j2kun</a></cite>				</div><!-- .comment-author .vcard -->

				<div class="comment-meta commentmetadata">
					<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-55600"><time pubdate="" datetime="2017-01-18T10:22:10-08:00">
					January 18, 2017 at 10:22 am					</time></a>
										<a rel="nofollow" class="comment-reply-link" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?replytocom=55600#respond" data-commentid="55600" data-postid="8329" data-belowelement="comment-55600" data-respondelement="respond" aria-label="Reply to j2kun">Reply</a>				</div><!-- .comment-meta .commentmetadata -->
			</footer>

			<div class="comment-content">
				<p>You’re right, you could compute a decomposition that way. In other words, SVD is not particular in the syntax of its decomposition, but rather in the semantics of it. </p>
<p>Indeed, if you picked a random orthogonal matrix, you’re essentially picking random unit vectors and projecting a dataset onto those. This is actually useful in some situations.</p>
<p>However, the subspaces you get don’t approximate the subspaces spanned by the original data, and in particular they don’t form a  sequence of increasingly good approximations. In other words, you don’t get any of the theorems we claimed about the SVD. The process is not unique, but the subspaces you arrive at when doing the SVD are unique.</p>
<p id="comment-like-55600" data-liked="comment-not-liked" class="comment-likes comment-not-liked"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?like_comment=55600&amp;_wpnonce=8aad5956b5" class="comment-like-link needs-login" rel="nofollow" data-blog="23934684"><span>Like</span></a><span id="comment-like-count-55600" class="comment-like-feedback">Like</span></p>
							</div>

		</article><!-- #comment-## -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment even thread-even depth-1 highlander-comment" id="li-comment-55601">
		<article id="comment-55601" class="comment">
			<footer class="clear">
				<div class="comment-author vcard">
					<span><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/589f2a3d31656708eb697e68826c8553" class="avatar avatar-44 grav-hashed grav-hijack" height="44" width="44" originals="44" src-orig="https://2.gravatar.com/avatar/589f2a3d31656708eb697e68826c8553?s=44&amp;d=identicon&amp;r=G" scale="1.5" id="grav-589f2a3d31656708eb697e68826c8553-2"></span>
					<cite class="fn">D</cite>				</div><!-- .comment-author .vcard -->

				<div class="comment-meta commentmetadata">
					<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-55601"><time pubdate="" datetime="2017-01-18T11:28:05-08:00">
					January 18, 2017 at 11:28 am					</time></a>
										<a rel="nofollow" class="comment-reply-link" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?replytocom=55601#respond" data-commentid="55601" data-postid="8329" data-belowelement="comment-55601" data-respondelement="respond" aria-label="Reply to D">Reply</a>				</div><!-- .comment-meta .commentmetadata -->
			</footer>

			<div class="comment-content">
				<p>I still think this is a good article — and the coding examples are nice.  </p>
<p>That said, I really think “Linear Algebra Done Wrong” –a great freely available text– has the best constructive approach to describing the SVD and proofs of its attributes.  The issue, though, is to really understand where these values and orthogonal matrices come from, you really need to start with the Schur Decomposition.  Arguably this is the single most important result in Linear Algebra, but for whatever reason I don’t think that many people are familiar with Schur. </p>
<p>You really can’t pick a random orthogonal matrix — it must be one that uses the eigenvectors of AA^T or ##A^T A##.  (If one of said matrices have eigs == 0, there may be a bit more flexibility, which is quite common and actually inevitable when dealing with non-square A — but you can relegate said flexibility to the nullspace which isn’t that interesting in my view.)  From here you of course could permute the orderings of the eigenvalues and their mutually orthonormal eigenvectors.  But that’s really it.</p>
<p id="comment-like-55601" data-liked="comment-not-liked" class="comment-likes comment-not-liked"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?like_comment=55601&amp;_wpnonce=5ac79819da" class="comment-like-link needs-login" rel="nofollow" data-blog="23934684"><span>Like</span></a><span id="comment-like-count-55601" class="comment-like-feedback">Liked by <a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#" class="view-likers" data-like-count="1">1 person</a></span></p>
							</div>

		</article><!-- #comment-## -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-amitm02 odd alt thread-odd thread-alt depth-1 highlander-comment" id="li-comment-55609">
		<article id="comment-55609" class="comment">
			<footer class="clear">
				<div class="comment-author vcard">
					<span><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/8b27349917970925b591f026bf23d3bb.jpeg" class="avatar avatar-44 grav-hashed grav-hijack" height="44" width="44" originals="44" src-orig="https://2.gravatar.com/avatar/8b27349917970925b591f026bf23d3bb?s=44&amp;d=identicon&amp;r=G" scale="1.5" id="grav-8b27349917970925b591f026bf23d3bb-1"></span>
					<cite class="fn">amitm02</cite>				</div><!-- .comment-author .vcard -->

				<div class="comment-meta commentmetadata">
					<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-55609"><time pubdate="" datetime="2017-01-19T07:06:03-08:00">
					January 19, 2017 at 7:06 am					</time></a>
										<a rel="nofollow" class="comment-reply-link" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?replytocom=55609#respond" data-commentid="55609" data-postid="8329" data-belowelement="comment-55609" data-respondelement="respond" aria-label="Reply to amitm02">Reply</a>				</div><!-- .comment-meta .commentmetadata -->
			</footer>

			<div class="comment-content">
				<p>j2kun, D,</p>
<p>I’ve looked into the proof in “Linear Algebra Done Wrong” (indeed a great book). From what i gathered, if you want U to be an orthogonal base (like we do in SVD), then V has to be the eigenvectors of AA^T. If you don’t care about U orthogonality, and just want some general decomposition of the structure UDV^T, there is nothing i mange to see in the proof that prevent you to choose V and sigma at random..</p>
<p id="comment-like-55609" data-liked="comment-not-liked" class="comment-likes comment-not-liked"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?like_comment=55609&amp;_wpnonce=0aa48065d9" class="comment-like-link needs-login" rel="nofollow" data-blog="23934684"><span>Like</span></a><span id="comment-like-count-55609" class="comment-like-feedback">Like</span></p>
							</div>

		</article><!-- #comment-## -->

	<ul class="children">
	<li class="comment byuser comment-author-jeremykun bypostauthor even depth-2 highlander-comment" id="li-comment-55610">
		<article id="comment-55610" class="comment">
			<footer class="clear">
				<div class="comment-author vcard">
					<span><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/90b179348780a6e7fe8e502968dc534a.jpeg" class="avatar avatar-44 grav-hashed grav-hijack" height="44" width="44" originals="44" src-orig="https://0.gravatar.com/avatar/90b179348780a6e7fe8e502968dc534a?s=44&amp;d=identicon&amp;r=G" scale="1.5" id="grav-90b179348780a6e7fe8e502968dc534a-3"></span>
					<cite class="fn"><a href="https://jeremykun.wordpress.com/" rel="external nofollow ugc" class="url">j2kun</a></cite>				</div><!-- .comment-author .vcard -->

				<div class="comment-meta commentmetadata">
					<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-55610"><time pubdate="" datetime="2017-01-19T07:49:19-08:00">
					January 19, 2017 at 7:49 am					</time></a>
										<a rel="nofollow" class="comment-reply-link" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?replytocom=55610#respond" data-commentid="55610" data-postid="8329" data-belowelement="comment-55610" data-respondelement="respond" aria-label="Reply to j2kun">Reply</a>				</div><!-- .comment-meta .commentmetadata -->
			</footer>

			<div class="comment-content">
				<p>Well, in order for D to be diagonal, yes you need to choose V and U special. But if D can be any old matrix, then the decomposition is just the expression of A in a new, randomly chosen basis.</p>
<p id="comment-like-55610" data-liked="comment-not-liked" class="comment-likes comment-not-liked"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?like_comment=55610&amp;_wpnonce=4539d9bd71" class="comment-like-link needs-login" rel="nofollow" data-blog="23934684"><span>Like</span></a><span id="comment-like-count-55610" class="comment-like-feedback">Liked by <a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#" class="view-likers" data-like-count="1">1 person</a></span></p>
							</div>

		</article><!-- #comment-## -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment odd alt thread-even depth-1 highlander-comment" id="li-comment-55612">
		<article id="comment-55612" class="comment">
			<footer class="clear">
				<div class="comment-author vcard">
					<span><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/589f2a3d31656708eb697e68826c8553" class="avatar avatar-44 grav-hashed grav-hijack" height="44" width="44" originals="44" src-orig="https://2.gravatar.com/avatar/589f2a3d31656708eb697e68826c8553?s=44&amp;d=identicon&amp;r=G" scale="1.5" id="grav-589f2a3d31656708eb697e68826c8553-3"></span>
					<cite class="fn">D</cite>				</div><!-- .comment-author .vcard -->

				<div class="comment-meta commentmetadata">
					<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-55612"><time pubdate="" datetime="2017-01-19T10:51:10-08:00">
					January 19, 2017 at 10:51 am					</time></a>
										<a rel="nofollow" class="comment-reply-link" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?replytocom=55612#respond" data-commentid="55612" data-postid="8329" data-belowelement="comment-55612" data-respondelement="respond" aria-label="Reply to D">Reply</a>				</div><!-- .comment-meta .commentmetadata -->
			</footer>

			<div class="comment-content">
				<p>amitm02,</p>
<p>The thrust is that eigenvalues (or spectrum) are perhaps the most important thing in Linear Algebra.  But they only apply to square matrices.  The SVD was designed to allow you to generalize a lot of the power of eigenvalues to non-square matrices.  If you don’t insist on U and V being orthogonal, you break that link.  </p>
<p>Btw, are you aware that trace(AA^T) = trace(A^TA) = squared Frobenius norm of A? You can follow this by blocking the matrix multiplication and looking at the diagonal — then follow up and look at the eigenvalues for AA^T and A^TA (because trace is also always the sum of eigenvalues — via cyclic property of trace and Schur decomposition).  One big well known use for SVD is to get best low rank approximation of a matrix and your measuring stick typically is the Frobenius norm.  Using orthogonal matrices in SVD allows you to get a clean cut and determine the best k-rank approximation.  If you don’t select U and V to be orthogonal matrices, you have no reason to believe that D (or more commonly Sigma) tells you anything directly about the Frobenius norm / best k rank approximation of the matrix.  Only orthogonal matrices (or unitary in complex space) ‘disappear’ as part of an inner product.  Orthogonal matrices also behave well numerically, so the SVD allows you to isolate where instability comes into play in solving / approximating systems of equations– so called ill conditioning, by looking at the singular values.</p>
<p>Ultimately you use the appropriate factorization to suit your goals.</p>
<p id="comment-like-55612" data-liked="comment-not-liked" class="comment-likes comment-not-liked"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?like_comment=55612&amp;_wpnonce=21f9816794" class="comment-like-link needs-login" rel="nofollow" data-blog="23934684"><span>Like</span></a><span id="comment-like-count-55612" class="comment-like-feedback">Like</span></p>
							</div>

		</article><!-- #comment-## -->

	</li><!-- #comment-## -->
	<li class="comment even thread-odd thread-alt depth-1 highlander-comment" id="li-comment-59806">
		<article id="comment-59806" class="comment">
			<footer class="clear">
				<div class="comment-author vcard">
					<span><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/f7db3ed455bbf1d29857645c686efa92" class="avatar avatar-44 grav-hashed grav-hijack" height="44" width="44" originals="44" src-orig="https://0.gravatar.com/avatar/f7db3ed455bbf1d29857645c686efa92?s=44&amp;d=identicon&amp;r=G" scale="1.5" id="grav-f7db3ed455bbf1d29857645c686efa92-0"></span>
					<cite class="fn">Wayne Small</cite>				</div><!-- .comment-author .vcard -->

				<div class="comment-meta commentmetadata">
					<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-59806"><time pubdate="" datetime="2017-12-28T14:13:49-08:00">
					December 28, 2017 at 2:13 pm					</time></a>
										<a rel="nofollow" class="comment-reply-link" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?replytocom=59806#respond" data-commentid="59806" data-postid="8329" data-belowelement="comment-59806" data-respondelement="respond" aria-label="Reply to Wayne Small">Reply</a>				</div><!-- .comment-meta .commentmetadata -->
			</footer>

			<div class="comment-content">
				<p>Awesome post! Thank you for the great blog, this post in particular. I wanted to note a typo: $c_i \sigma_j^{2s}$ should be $c_j \sigma_j^{2s}$ during the proof of the lim $B^sx$, when you dot product $B^sx$ with $v_j$.</p>
<p id="comment-like-59806" data-liked="comment-not-liked" class="comment-likes comment-not-liked"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?like_comment=59806&amp;_wpnonce=a8dac763d2" class="comment-like-link needs-login" rel="nofollow" data-blog="23934684"><span>Like</span></a><span id="comment-like-count-59806" class="comment-like-feedback">Like</span></p>
							</div>

		</article><!-- #comment-## -->

	</li><!-- #comment-## -->
	<li class="comment odd alt thread-even depth-1 highlander-comment" id="li-comment-62040">
		<article id="comment-62040" class="comment">
			<footer class="clear">
				<div class="comment-author vcard">
					<span><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/acaa01eedaf2f4341cedb808705bc910" class="avatar avatar-44 grav-hashed grav-hijack" height="44" width="44" originals="44" src-orig="https://1.gravatar.com/avatar/acaa01eedaf2f4341cedb808705bc910?s=44&amp;d=identicon&amp;r=G" scale="1.5" id="grav-acaa01eedaf2f4341cedb808705bc910-1"></span>
					<cite class="fn">Andy</cite>				</div><!-- .comment-author .vcard -->

				<div class="comment-meta commentmetadata">
					<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-62040"><time pubdate="" datetime="2018-06-13T14:54:02-07:00">
					June 13, 2018 at 2:54 pm					</time></a>
										<a rel="nofollow" class="comment-reply-link" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?replytocom=62040#respond" data-commentid="62040" data-postid="8329" data-belowelement="comment-62040" data-respondelement="respond" aria-label="Reply to Andy">Reply</a>				</div><!-- .comment-meta .commentmetadata -->
			</footer>

			<div class="comment-content">
				<p>Correct me if I’m wrong but I see this post as showing two orthogonal things which are important:<br>
1) The best decomposition (in terms of approximations up to rank K) are solved by a greedy method. To me this is super clear geometrically and I like your approach.<br>
—<br>
2) From the part of the blog that says “If you put these thoughts together”, I gather that we could actually apply the same logic for any orthonormal basis V (not just our best one):<br>
– We can represent any vector as a sum of projections onto each v_i.<br>
– We can pull out a factor for each i (the inner product), and by linearity focus on how A acts on each vector v_i.<br>
– Define Av_i = sigma_i * u_i.<br>
– If we can show that u_i is also a basis for the image of A (which is good enough since we want to reconstruct A), then we have a decomposition (that is not necessarily optimal unless we take the procedure from 1)<br>
—<br>
Do these two points overlap in anyway or are they each separately true?<br>
According to this proof, posted in the above comment, it would appear these two facts are actually intimately tied: <a href="http://codingthematrix.com/proof-that-U-is-column-orthogonal0.pdf" rel="nofollow">http://codingthematrix.com/proof-that-U-is-column-orthogonal0.pdf</a><br>
Although not explicitly proven, it appears we cannot guaranty we have a basis U for some arbitrary basis V if we do not explicitly follow the procedure of SVD to obtain V.</p>
<p id="comment-like-62040" data-liked="comment-not-liked" class="comment-likes comment-not-liked"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/?like_comment=62040&amp;_wpnonce=19411b9c05" class="comment-like-link needs-login" rel="nofollow" data-blog="23934684"><span>Like</span></a><span id="comment-like-count-62040" class="comment-like-feedback">Like</span></p>
							</div>

		</article><!-- #comment-## -->

	</li><!-- #comment-## -->
		</ol><!-- .commentlist -->

		
	
	
		<div id="respond" class="comment-respond js">
		<h3 id="reply-title" class="comment-reply-title">Leave a Reply <small><a rel="nofollow" id="cancel-comment-reply-link" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#respond" style="display:none;">Cancel reply</a></small></h3><form action="https://jeremykun.com/wp-comments-post.php" method="post" id="commentform" class="comment-form"><input type="hidden" id="highlander_comment_nonce" name="highlander_comment_nonce" value="62d59a8cb3"><input type="hidden" name="_wp_http_referer" value="/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/">
<input type="hidden" name="hc_post_as" id="hc_post_as" value="guest">

<div class="comment-form-field comment-textarea">
	
	<div id="comment-form-comment"><textarea aria-hidden="true" tabindex="-1" style="position: absolute; top: -999px; left: 0px; right: auto; bottom: auto; border: 0px; padding: 0px; box-sizing: content-box; overflow-wrap: break-word; overflow: hidden; transition: none 0s ease 0s; height: 0px !important; min-height: 0px !important; font-family: Arial, Helvetica, Tahoma, Verdana, sans-serif; font-size: 14px; font-weight: 400; font-style: normal; letter-spacing: 0px; text-transform: none; text-decoration: none solid rgba(0, 0, 0, 0.7); word-spacing: 0px; text-indent: 0px; line-height: 22.4px; width: 564.9px;" class="autosizejs "></textarea><textarea id="comment" name="comment" title="Enter your comment here..." placeholder="Enter your comment here..." style="height: 42px; overflow: hidden; overflow-wrap: break-word; resize: none;"></textarea></div>
</div>

<div id="comment-form-identity" style="display: none;">
	<div id="comment-form-nascar">
		<p>Fill in your details below or click an icon to log in:</p>
		<ul>
			<li class="selected" style="display:none;">
				<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-form-guest" id="postas-guest" class="nascar-signin-link" title="Login via Guest">
									</a>
			</li>
			<li>
				<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-form-load-service:WordPress.com" id="postas-wordpress" class="nascar-signin-link" title="Login via WordPress.com">
					<svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24"><rect x="0" fill="none" width="24" height="24"></rect><g><path fill="#0087be" d="M12.158 12.786l-2.698 7.84c.806.236 1.657.365 2.54.365 1.047 0 2.05-.18 2.986-.51-.024-.037-.046-.078-.065-.123l-2.762-7.57zM3.008 12c0 3.56 2.07 6.634 5.068 8.092L3.788 8.342c-.5 1.117-.78 2.354-.78 3.658zm15.06-.454c0-1.112-.398-1.88-.74-2.48-.456-.74-.883-1.368-.883-2.11 0-.825.627-1.595 1.51-1.595.04 0 .078.006.116.008-1.598-1.464-3.73-2.36-6.07-2.36-3.14 0-5.904 1.613-7.512 4.053.21.008.41.012.58.012.94 0 2.395-.114 2.395-.114.484-.028.54.684.057.74 0 0-.487.058-1.03.086l3.275 9.74 1.968-5.902-1.4-3.838c-.485-.028-.944-.085-.944-.085-.486-.03-.43-.77.056-.742 0 0 1.484.114 2.368.114.94 0 2.397-.114 2.397-.114.486-.028.543.684.058.74 0 0-.488.058-1.03.086l3.25 9.665.897-2.997c.456-1.17.684-2.137.684-2.907zm1.82-3.86c.04.286.06.593.06.924 0 .912-.17 1.938-.683 3.22l-2.746 7.94c2.672-1.558 4.47-4.454 4.47-7.77 0-1.564-.4-3.033-1.1-4.314zM12 22C6.486 22 2 17.514 2 12S6.486 2 12 2s10 4.486 10 10-4.486 10-10 10z"></path></g></svg>				</a>
			</li>
			<li>
			</li><li>
				<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-form-load-service:Twitter" id="postas-twitter" class="nascar-signin-link" title="Login via Twitter">
					<svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24"><rect x="0" fill="none" width="24" height="24"></rect><g><path fill="#1DA1F2" d="M22.23 5.924c-.736.326-1.527.547-2.357.646.847-.508 1.498-1.312 1.804-2.27-.793.47-1.67.812-2.606.996C18.325 4.498 17.258 4 16.078 4c-2.266 0-4.103 1.837-4.103 4.103 0 .322.036.635.106.935-3.41-.17-6.433-1.804-8.457-4.287-.353.607-.556 1.312-.556 2.064 0 1.424.724 2.68 1.825 3.415-.673-.022-1.305-.207-1.86-.514v.052c0 1.988 1.415 3.647 3.293 4.023-.344.095-.707.145-1.08.145-.265 0-.522-.026-.773-.074.522 1.63 2.038 2.817 3.833 2.85-1.404 1.1-3.174 1.757-5.096 1.757-.332 0-.66-.02-.98-.057 1.816 1.164 3.973 1.843 6.29 1.843 7.547 0 11.675-6.252 11.675-11.675 0-.178-.004-.355-.012-.53.802-.578 1.497-1.3 2.047-2.124z"></path></g></svg>				</a>
			</li>
			<li>
				<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#comment-form-load-service:Facebook" id="postas-facebook" class="nascar-signin-link" title="Login via Facebook">
					<svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24"><rect x="0" fill="none" width="24" height="24"></rect><g><path fill="#3B5998" d="M20.007 3H3.993C3.445 3 3 3.445 3 3.993v16.013c0 .55.445.994.993.994h8.62v-6.97H10.27V11.31h2.346V9.31c0-2.325 1.42-3.59 3.494-3.59.993 0 1.847.073 2.096.106v2.43h-1.438c-1.128 0-1.346.537-1.346 1.324v1.734h2.69l-.35 2.717h-2.34V21h4.587c.548 0 .993-.445.993-.993V3.993c0-.548-.445-.993-.993-.993z"></path></g></svg>				</a>
			</li>
		</ul>
	</div>

	<div id="comment-form-guest" class="comment-form-service selected">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
<a href="https://gravatar.com/site/signup/" target="_blank">				<img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/ad516503a11cd5ca435acc9bb6523536" alt="Gravatar" width="25" class="no-grav" originals="25" src-orig="https://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&amp;d=identicon&amp;forcedefault=y&amp;r=G" scale="1.5">
</a>			</div>

				<div class="comment-form-fields">
				<div class="comment-form-field comment-form-email">
					<label for="email">Email <span class="required">(required)</span> <span class="nopublish">(Address never made public)</span></label>
					<div class="comment-form-input"><input id="email" name="email" type="email" value=""></div>
				</div>
				<div class="comment-form-field comment-form-author">
					<label for="author">Name <span class="required">(required)</span></label>
					<div class="comment-form-input"><input id="author" name="author" type="text" value=""></div>
				</div>
				<div class="comment-form-field comment-form-url">
					<label for="url">Website</label>
					<div class="comment-form-input"><input id="url" name="url" type="url" value=""></div>
				</div>
			</div>
			
		</div>
	</div>

	<div id="comment-form-wordpress" class="comment-form-service">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
				<img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/ad516503a11cd5ca435acc9bb6523536(1)" alt="WordPress.com Logo" width="25" class="no-grav" originals="25" scale="1.5">
			</div>

				<div class="comment-form-fields">
				<input type="hidden" name="wp_avatar" id="wordpress-avatar" class="comment-meta-wordpress" value="">
				<input type="hidden" name="wp_user_id" id="wordpress-user_id" class="comment-meta-wordpress" value="">
				<input type="hidden" name="wp_access_token" id="wordpress-access_token" class="comment-meta-wordpress" value="">
						<p class="comment-form-posting-as pa-wordpress">
			<strong></strong>
			You are commenting using your WordPress.com account.			<span class="comment-form-log-out">
				(&nbsp;<a href="javascript:HighlanderComments.doExternalLogout( &#39;wordpress&#39; );">Log&nbsp;Out</a>&nbsp;/&nbsp;
				<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)
			</span>
			<span class="pa-icon"><svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24"><rect x="0" fill="none" width="24" height="24"></rect><g><path fill="#0087be" d="M12.158 12.786l-2.698 7.84c.806.236 1.657.365 2.54.365 1.047 0 2.05-.18 2.986-.51-.024-.037-.046-.078-.065-.123l-2.762-7.57zM3.008 12c0 3.56 2.07 6.634 5.068 8.092L3.788 8.342c-.5 1.117-.78 2.354-.78 3.658zm15.06-.454c0-1.112-.398-1.88-.74-2.48-.456-.74-.883-1.368-.883-2.11 0-.825.627-1.595 1.51-1.595.04 0 .078.006.116.008-1.598-1.464-3.73-2.36-6.07-2.36-3.14 0-5.904 1.613-7.512 4.053.21.008.41.012.58.012.94 0 2.395-.114 2.395-.114.484-.028.54.684.057.74 0 0-.487.058-1.03.086l3.275 9.74 1.968-5.902-1.4-3.838c-.485-.028-.944-.085-.944-.085-.486-.03-.43-.77.056-.742 0 0 1.484.114 2.368.114.94 0 2.397-.114 2.397-.114.486-.028.543.684.058.74 0 0-.488.058-1.03.086l3.25 9.665.897-2.997c.456-1.17.684-2.137.684-2.907zm1.82-3.86c.04.286.06.593.06.924 0 .912-.17 1.938-.683 3.22l-2.746 7.94c2.672-1.558 4.47-4.454 4.47-7.77 0-1.564-.4-3.033-1.1-4.314zM12 22C6.486 22 2 17.514 2 12S6.486 2 12 2s10 4.486 10 10-4.486 10-10 10z"></path></g></svg></span>
		</p>
					</div>
	
		</div>
	</div>

	<div id="comment-form-googleplus" class="comment-form-service">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
				<img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/ad516503a11cd5ca435acc9bb6523536(1)" alt="Google photo" width="25" class="no-grav" originals="25" scale="1.5">
			</div>

				<div class="comment-form-fields">
				<input type="hidden" name="googleplus_avatar" id="googleplus-avatar" class="comment-meta-googleplus" value="">
				<input type="hidden" name="googleplus_user_id" id="googleplus-user_id" class="comment-meta-googleplus" value="">
				<input type="hidden" name="googleplus_access_token" id="googleplus-access_token" class="comment-meta-googleplus" value="">
						<p class="comment-form-posting-as pa-googleplus">
			<strong></strong>
			You are commenting using your Google account.			<span class="comment-form-log-out">
				(&nbsp;<a href="javascript:HighlanderComments.doExternalLogout( &#39;googleplus&#39; );">Log&nbsp;Out</a>&nbsp;/&nbsp;
				<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)
			</span>
			<span class="pa-icon"><svg xmlns="http://www.w3.org/2000/svg" role="presentation" x="0px" y="0px" viewBox="0 0 60 60"><path fill="#519bf7" d="M56.3,30c0,-1.6 -0.2,-3.4 -0.6,-5h-3.1H42.2H30v10.6h14.8C44,39.3 42,42 39.1,43.9l8.8,6.8C53,46 56.3,39 56.3,30z"></path><path fill="#3db366" d="M30,57.5c6.7,0 13.1,-2.4 17.9,-6.8l-8.8,-6.8c-2.5,1.6 -5.6,2.4 -9.1,2.4c-7.2,0 -13.3,-4.7 -15.4,-11.2l-9.3,7.1C9.8,51.3 19.1,57.5 30,57.5z"></path><path fill="#fdc600" d="M5.3,42.2l9.3,-7.1c-0.5,-1.6 -0.8,-3.3 -0.8,-5.1s0.3,-3.5 0.8,-5.1l-9.3,-7.1C3.5,21.5 2.5,25.6 2.5,30S3.5,38.5 5.3,42.2z"></path><path fill="#f15b44" d="M40.1,17.4l8,-8C43.3,5.1 37,2.5 30,2.5C19.1,2.5 9.8,8.7 5.3,17.8l9.3,7.1c2.1,-6.5 8.2,-11.1 15.4,-11.1C33.9,13.7 37.4,15.1 40.1,17.4z"></path></svg></span>
		</p>
					</div>
	
		</div>
	</div>

	<div id="comment-form-twitter" class="comment-form-service">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
				<img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/ad516503a11cd5ca435acc9bb6523536(1)" alt="Twitter picture" width="25" class="no-grav" originals="25" scale="1.5">
			</div>

				<div class="comment-form-fields">
				<input type="hidden" name="twitter_avatar" id="twitter-avatar" class="comment-meta-twitter" value="">
				<input type="hidden" name="twitter_user_id" id="twitter-user_id" class="comment-meta-twitter" value="">
				<input type="hidden" name="twitter_access_token" id="twitter-access_token" class="comment-meta-twitter" value="">
						<p class="comment-form-posting-as pa-twitter">
			<strong></strong>
			You are commenting using your Twitter account.			<span class="comment-form-log-out">
				(&nbsp;<a href="javascript:HighlanderComments.doExternalLogout( &#39;twitter&#39; );">Log&nbsp;Out</a>&nbsp;/&nbsp;
				<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)
			</span>
			<span class="pa-icon"><svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24"><rect x="0" fill="none" width="24" height="24"></rect><g><path fill="#1DA1F2" d="M22.23 5.924c-.736.326-1.527.547-2.357.646.847-.508 1.498-1.312 1.804-2.27-.793.47-1.67.812-2.606.996C18.325 4.498 17.258 4 16.078 4c-2.266 0-4.103 1.837-4.103 4.103 0 .322.036.635.106.935-3.41-.17-6.433-1.804-8.457-4.287-.353.607-.556 1.312-.556 2.064 0 1.424.724 2.68 1.825 3.415-.673-.022-1.305-.207-1.86-.514v.052c0 1.988 1.415 3.647 3.293 4.023-.344.095-.707.145-1.08.145-.265 0-.522-.026-.773-.074.522 1.63 2.038 2.817 3.833 2.85-1.404 1.1-3.174 1.757-5.096 1.757-.332 0-.66-.02-.98-.057 1.816 1.164 3.973 1.843 6.29 1.843 7.547 0 11.675-6.252 11.675-11.675 0-.178-.004-.355-.012-.53.802-.578 1.497-1.3 2.047-2.124z"></path></g></svg></span>
		</p>
					</div>
	
		</div>
	</div>

	<div id="comment-form-facebook" class="comment-form-service">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
				<img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/ad516503a11cd5ca435acc9bb6523536(1)" alt="Facebook photo" width="25" class="no-grav" originals="25" scale="1.5">
			</div>

				<div class="comment-form-fields">
				<input type="hidden" name="fb_avatar" id="facebook-avatar" class="comment-meta-facebook" value="">
				<input type="hidden" name="fb_user_id" id="facebook-user_id" class="comment-meta-facebook" value="">
				<input type="hidden" name="fb_access_token" id="facebook-access_token" class="comment-meta-facebook" value="">
						<p class="comment-form-posting-as pa-facebook">
			<strong></strong>
			You are commenting using your Facebook account.			<span class="comment-form-log-out">
				(&nbsp;<a href="javascript:HighlanderComments.doExternalLogout( &#39;facebook&#39; );">Log&nbsp;Out</a>&nbsp;/&nbsp;
				<a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)
			</span>
			<span class="pa-icon"><svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24"><rect x="0" fill="none" width="24" height="24"></rect><g><path fill="#3B5998" d="M20.007 3H3.993C3.445 3 3 3.445 3 3.993v16.013c0 .55.445.994.993.994h8.62v-6.97H10.27V11.31h2.346V9.31c0-2.325 1.42-3.59 3.494-3.59.993 0 1.847.073 2.096.106v2.43h-1.438c-1.128 0-1.346.537-1.346 1.324v1.734h2.69l-.35 2.717h-2.34V21h4.587c.548 0 .993-.445.993-.993V3.993c0-.548-.445-.993-.993-.993z"></path></g></svg></span>
		</p>
					</div>
	
		</div>
	</div>


	<div id="comment-form-load-service" class="comment-form-service">
		<div class="comment-form-posting-as-cancel"><a href="javascript:HighlanderComments.cancelExternalWindow();">Cancel</a></div>
		<p>Connecting to %s</p>
	</div>

</div>

<script type="text/javascript">
var highlander_expando_javascript = function(){
	var input = document.createElement( 'input' ),
	    comment = jQuery( '#comment' );

	if ( 'placeholder' in input ) {
		comment.attr( 'placeholder', jQuery( '.comment-textarea label' ).remove().text() );
	}

	// Expando Mode: start small, then auto-resize on first click + text length
	jQuery( '#comment-form-identity' ).hide();
	jQuery( '#comment-form-subscribe' ).hide();
	jQuery( '#commentform .form-submit' ).hide();

	comment.css( { 'height':'10px' } ).one( 'focus', function() {
		var timer = setInterval( HighlanderComments.resizeCallback, 10 )
		jQuery( this ).animate( { 'height': HighlanderComments.initialHeight } ).delay( 100 ).queue( function(n) { clearInterval( timer ); HighlanderComments.resizeCallback(); n(); } );
		jQuery( '#comment-form-identity' ).slideDown();
		jQuery( '#comment-form-subscribe' ).slideDown();
		jQuery( '#commentform .form-submit' ).slideDown();
	});
}
jQuery(document).ready( highlander_expando_javascript );
</script>

<div id="comment-form-subscribe" style="display: none;">
	<p class="comment-subscription-form"><input type="checkbox" name="subscribe" id="subscribe" value="subscribe" style="width: auto;"> <label class="subscribe-label" id="subscribe-label" for="subscribe" style="display: inline;">Notify me of new comments via email.</label></p><p class="post-subscription-form"><input type="checkbox" name="subscribe_blog" id="subscribe_blog" value="subscribe" style="width: auto;"> <label class="subscribe-label" id="subscribe-blog-label" for="subscribe_blog" style="display: inline;">Notify me of new posts via email.</label></p></div>




<p class="form-submit" style="display: none;"><input name="submit" type="submit" id="comment-submit" class="submit" value="Post Comment"> <input type="hidden" name="comment_post_ID" value="8329" id="comment_post_ID">
<input type="hidden" name="comment_parent" id="comment_parent" value="0">
</p><p style="display: none;"><input type="hidden" id="akismet_comment_nonce" name="akismet_comment_nonce" value="631bd30d50"></p>
<input type="hidden" name="genseq" value="1572929742">
<p style="display: none;"></p><input type="hidden" id="ak_js" name="ak_js" value="1572929745251"></form>	</div><!-- #respond -->
	<div style="clear: both"></div>
</div><!-- #comments .comments-area -->

			
			</div><!-- #content .site-content -->
		</div><!-- #primary .content-area -->

<script type="text/javascript">
								var _gaq = _gaq || [];
								_gaq.push(['_setAccount', 'UA-21256318-4']);
_gaq.push(['_trackPageview']);

								(function() {
									var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
									ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
									var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
								})();
							</script>

		</div><!-- #main .site-main -->

		
		<div id="secondary" class="widget-area" role="complementary">
						<aside id="search-3" class="widget widget_search">	<form method="get" id="searchform" action="https://jeremykun.com/" role="search">
		<label for="s" class="assistive-text">Search</label>
		<input type="text" class="field" name="s" value="" id="s" placeholder="Search …">
		<input type="submit" class="submit" name="submit" id="searchsubmit" value="Search">
	</form>
</aside><aside id="media_image-15" class="widget widget_media_image"><style>.widget.widget_media_image { overflow: hidden; }.widget.widget_media_image img { height: auto; max-width: 100%; }</style><div style="width: 936px" class="wp-caption alignnone"><a href="http://pimbook.org/"><img width="926" height="474" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/screen-shot-2018-12-01-at-8-47-20-am.png" class="image wp-image-82462  attachment-926x474 size-926x474" alt="A Programmer&#39;s Introduction to Mathematics" style="max-width: 100%; height: auto;" srcset="https://jeremykun.files.wordpress.com/2018/12/screen-shot-2018-12-01-at-8-47-20-am.png 926w, https://jeremykun.files.wordpress.com/2018/12/screen-shot-2018-12-01-at-8-47-20-am.png?w=150 150w, https://jeremykun.files.wordpress.com/2018/12/screen-shot-2018-12-01-at-8-47-20-am.png?w=300 300w, https://jeremykun.files.wordpress.com/2018/12/screen-shot-2018-12-01-at-8-47-20-am.png?w=768 768w" sizes="(max-width: 926px) 100vw, 926px" data-attachment-id="82462" data-permalink="https://jeremykun.com/screen-shot-2018-12-01-at-8-47-20-am/" data-orig-file="https://jeremykun.files.wordpress.com/2018/12/screen-shot-2018-12-01-at-8-47-20-am.png" data-orig-size="926,474" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2018-12-01 at 8.47.20 AM" data-image-description="" data-medium-file="https://jeremykun.files.wordpress.com/2018/12/screen-shot-2018-12-01-at-8-47-20-am.png?w=300" data-large-file="https://jeremykun.files.wordpress.com/2018/12/screen-shot-2018-12-01-at-8-47-20-am.png?w=926"></a><p class="wp-caption-text">Buy my book, which teaches programmers how to engage with mathematics. Every chapter includes an application, from cryptography to economics, physics, neural networks, and more!</p></div></aside><aside id="media_image-9" class="widget widget_media_image"><style>.widget.widget_media_image { overflow: hidden; }.widget.widget_media_image img { height: auto; max-width: 100%; }</style><a href="https://github.com/j2kun/"><img width="180" height="180" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/github-icon.png" class="image wp-image-5618 alignnone attachment-180x180 size-180x180" alt="Github repository" style="max-width: 100%; height: auto;" srcset="https://jeremykun.files.wordpress.com/2015/02/github-icon.png?w=180 180w, https://jeremykun.files.wordpress.com/2015/02/github-icon.png?w=150 150w, https://jeremykun.files.wordpress.com/2015/02/github-icon.png 244w" sizes="(max-width: 180px) 100vw, 180px" data-attachment-id="5618" data-permalink="https://jeremykun.com/github-icon/" data-orig-file="https://jeremykun.files.wordpress.com/2015/02/github-icon.png" data-orig-size="244,244" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="github-icon" data-image-description="" data-medium-file="https://jeremykun.files.wordpress.com/2015/02/github-icon.png?w=244" data-large-file="https://jeremykun.files.wordpress.com/2015/02/github-icon.png?w=244"></a></aside><aside id="media_image-8" class="widget widget_media_image"><style>.widget.widget_media_image { overflow: hidden; }.widget.widget_media_image img { height: auto; max-width: 100%; }</style><a href="https://medium.com/@jeremyjkun"><img width="180" height="180" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/medium-icon1.png" class="image wp-image-5617  attachment-180x180 size-180x180" alt="Medium @jeremyjkun" style="max-width: 100%; height: auto;" srcset="https://jeremykun.files.wordpress.com/2015/02/medium-icon1.png?w=180 180w, https://jeremykun.files.wordpress.com/2015/02/medium-icon1.png?w=150 150w, https://jeremykun.files.wordpress.com/2015/02/medium-icon1.png 244w" sizes="(max-width: 180px) 100vw, 180px" data-attachment-id="5617" data-permalink="https://jeremykun.com/medium-icon-2/" data-orig-file="https://jeremykun.files.wordpress.com/2015/02/medium-icon1.png" data-orig-size="244,244" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="medium-icon" data-image-description="" data-medium-file="https://jeremykun.files.wordpress.com/2015/02/medium-icon1.png?w=244" data-large-file="https://jeremykun.files.wordpress.com/2015/02/medium-icon1.png?w=244"></a></aside><aside id="media_image-6" class="widget widget_media_image"><style>.widget.widget_media_image { overflow: hidden; }.widget.widget_media_image img { height: auto; max-width: 100%; }</style><a href="https://twitter.com/MathProgramming"><img width="180" height="180" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/twitter1-e1500589540515.png" class="image wp-image-3436 alignnone attachment-180x180 size-180x180" alt="" style="max-width: 100%; height: auto;" srcset="https://jeremykun.files.wordpress.com/2013/05/twitter1-e1500589540515.png?w=180 180w, https://jeremykun.files.wordpress.com/2013/05/twitter1-e1500589540515.png?w=150 150w, https://jeremykun.files.wordpress.com/2013/05/twitter1-e1500589540515.png 200w" sizes="(max-width: 180px) 100vw, 180px" data-attachment-id="3436" data-permalink="https://jeremykun.com/twitter-2/" data-orig-file="https://jeremykun.files.wordpress.com/2013/05/twitter1-e1500589540515.png" data-orig-size="200,200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="twitter" data-image-description="" data-medium-file="https://jeremykun.files.wordpress.com/2013/05/twitter1-e1500589540515.png?w=200" data-large-file="https://jeremykun.files.wordpress.com/2013/05/twitter1-e1500589540515.png?w=200"></a></aside><aside id="rss_links-2" class="widget widget_rss_links"><h1 class="widget-title">RSS</h1><ul><li><a href="https://jeremykun.com/feed/" title="Subscribe to Posts">RSS - Posts</a></li></ul>
</aside>		</div><!-- #secondary .widget-area -->

		<footer id="colophon" class="site-footer" role="contentinfo">
			<div class="site-info">
								<a></a>
				
							</div><!-- .site-info -->
		</footer><!-- #colophon .site-footer -->
	</div><!-- #page .hfeed .site -->
</div><!-- #wrapper -->
<!--  -->
<script src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/gprofiles.js.下载"></script>
<script>
var WPGroHo = {"my_hash":""};
</script>
<script type="text/javascript" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/wpgroho.js.下载"></script>

	<script>
		//initialize and attach hovercards to all gravatars
		jQuery( document ).ready( function( $ ) {

			if (typeof Gravatar === "undefined"){
				return;
			}

			if ( typeof Gravatar.init !== "function" ) {
				return;
			}			

			Gravatar.profile_cb = function( hash, id ) {
				WPGroHo.syncProfileData( hash, id );
			};
			Gravatar.my_hash = WPGroHo.my_hash;
			Gravatar.init( 'body', '#wp-admin-bar-my-account' );
		});
	</script>

		<div style="display:none">
	<div class="grofile-hash-map-899b321d1e724bf1e214fc96e596771c">
	</div>
	<div class="grofile-hash-map-709674d8a8b5c54d4b785d40a71be503">
	</div>
	<div class="grofile-hash-map-589f2a3d31656708eb697e68826c8553">
	</div>
	<div class="grofile-hash-map-74fb05adf8ebc3e0a8af02762f1bd0b0">
	</div>
	<div class="grofile-hash-map-34147608ed4560acae55f4858aeb0ab7">
	</div>
	<div class="grofile-hash-map-a7e744113723dd9b1d6d4e5294358bad">
	</div>
	<div class="grofile-hash-map-5bc5aaf4d3a7d64f5121b605f046d930">
	</div>
	<div class="grofile-hash-map-90b179348780a6e7fe8e502968dc534a">
	</div>
	<div class="grofile-hash-map-acaa01eedaf2f4341cedb808705bc910">
	</div>
	<div class="grofile-hash-map-32f8f96ce5e384abf5dda6dcd60d089a">
	</div>
	<div class="grofile-hash-map-0f7dcfffea377349e74559a09945c013">
	</div>
	<div class="grofile-hash-map-f1f1ba12bbcb225b4d7af4e791e0b7d1">
	</div>
	<div class="grofile-hash-map-42aace5028b0b87571be854212620104">
	</div>
	<div class="grofile-hash-map-8b27349917970925b591f026bf23d3bb">
	</div>
	<div class="grofile-hash-map-f7db3ed455bbf1d29857645c686efa92">
	</div>
	</div>
<script>
var HighlanderComments = {"loggingInText":"Logging In\u2026","submittingText":"Posting Comment\u2026","postCommentText":"Post Comment","connectingToText":"Connecting to %s","commentingAsText":"%1$s: You are commenting using your %2$s account.","logoutText":"Log Out","loginText":"Log In","connectURL":"https:\/\/jeremykun.wordpress.com\/public.api\/connect\/?action=request&domain=jeremykun.com","logoutURL":"https:\/\/jeremykun.wordpress.com\/wp-login.php?action=logout&_wpnonce=49a53ba7f5","homeURL":"https:\/\/jeremykun.com\/","postID":"8329","gravDefault":"identicon","enterACommentError":"Please enter a comment","enterEmailError":"Please enter your email address here","invalidEmailError":"Invalid email address","enterAuthorError":"Please enter your name here","gravatarFromEmail":"This picture will show whenever you leave a comment. Click to customize it.","logInToExternalAccount":"Log in to use details from one of these accounts.","change":"Change","changeAccount":"Change Account","comment_registration":"0","userIsLoggedIn":"","isJetpack":"","text_direction":"ltr"};
</script>
<script type="text/javascript" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/saved_resource(7)"></script>

	<div id="carousel-reblog-box">
		<form action="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#" name="carousel-reblog">
			<textarea id="carousel-reblog-content" name="carousel-reblog-content" placeholder="Add your thoughts here... (optional)"></textarea>
			<label for="carousel-reblog-to-blog-id" id="carousel-reblog-lblogid">Post to</label>
			<select name="carousel-reblog-to-blog-id" id="carousel-reblog-to-blog-id">
						</select>

			<div class="submit">
				<span class="canceltext"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#" class="cancel">Cancel</a></span>
				<input type="submit" name="carousel-reblog-submit" class="button" id="carousel-reblog-submit" value="Reblog Post">
				<input type="hidden" id="carousel-reblog-blog-id" value="23934684">
				<input type="hidden" id="carousel-reblog-blog-url" value="https://jeremykun.com">
				<input type="hidden" id="carousel-reblog-blog-title" value="Math ∩ Programming">
				<input type="hidden" id="carousel-reblog-post-url" value="">
				<input type="hidden" id="carousel-reblog-post-title" value="">
			</div>

			<input type="hidden" id="_wpnonce" name="_wpnonce" value="5ddf78add7"><input type="hidden" name="_wp_http_referer" value="/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/">		</form>

		<div class="arrow"></div>
	</div>

	<script type="text/javascript">
		window.WPCOM_sharing_counts = {"https:\/\/jeremykun.com\/2016\/05\/16\/singular-value-decomposition-part-2-theorem-proof-algorithm\/":8329};
	</script>
					
		<script type="text/javascript" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/saved_resource(8)"></script>
<script type="text/javascript">
	(function(){
		var corecss = document.createElement('link');
		var themecss = document.createElement('link');
		var corecssurl = "https://s1.wp.com/wp-content/plugins/syntaxhighlighter/syntaxhighlighter3/styles/shCore.css?ver=3.0.9b";
		if ( corecss.setAttribute ) {
				corecss.setAttribute( "rel", "stylesheet" );
				corecss.setAttribute( "type", "text/css" );
				corecss.setAttribute( "href", corecssurl );
		} else {
				corecss.rel = "stylesheet";
				corecss.href = corecssurl;
		}
		document.head.appendChild( corecss );
		var themecssurl = "https://s2.wp.com/wp-content/plugins/syntaxhighlighter/syntaxhighlighter3/styles/shThemeDefault.css?m=1363304414h&amp;ver=3.0.9b";
		if ( themecss.setAttribute ) {
				themecss.setAttribute( "rel", "stylesheet" );
				themecss.setAttribute( "type", "text/css" );
				themecss.setAttribute( "href", themecssurl );
		} else {
				themecss.rel = "stylesheet";
				themecss.href = themecssurl;
		}
		document.head.appendChild( themecss );
	})();
	SyntaxHighlighter.config.strings.expandSource = '+ expand source';
	SyntaxHighlighter.config.strings.help = '?';
	SyntaxHighlighter.config.strings.alert = 'SyntaxHighlighter\n\n';
	SyntaxHighlighter.config.strings.noBrush = 'Can\'t find brush for: ';
	SyntaxHighlighter.config.strings.brushNotHtmlScript = 'Brush wasn\'t configured for html-script option: ';
	SyntaxHighlighter.defaults['pad-line-numbers'] = false;
	SyntaxHighlighter.defaults['toolbar'] = false;
	SyntaxHighlighter.all();

	// Infinite scroll support
	if ( typeof( jQuery ) !== 'undefined' ) {
		jQuery( function( $ ) {
			$( document.body ).on( 'post-load', function() {
				SyntaxHighlighter.highlight();
			} );
		} );
	}
</script>
<link rel="stylesheet" id="all-css-0-3" href="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/jetpack-carousel.css" type="text/css" media="all">
<script>
var comment_like_text = {"loading":"Loading..."};
</script>
<script>
var actionbardata = {"siteID":"23934684","siteName":"Math \u2229 Programming","siteURL":"https:\/\/jeremykun.com","icon":"<img alt='' src='https:\/\/secure.gravatar.com\/blavatar\/ffc08531463d8605aef9e0b51a9ac71f?s=50&d=https%3A%2F%2Fs2.wp.com%2Fi%2Flogo%2Fwpcom-gray-white.png' class='avatar avatar-50' height='50' width='50' \/>","canManageOptions":"","canCustomizeSite":"","isFollowing":"","themeSlug":"pub\/confit","signupURL":"https:\/\/wordpress.com\/start\/","loginURL":"https:\/\/wordpress.com\/log-in?redirect_to=https%3A%2F%2Fjeremykun.com%2F2016%2F05%2F16%2Fsingular-value-decomposition-part-2-theorem-proof-algorithm%2F&signup_flow=account&domain=jeremykun.com","themeURL":"https:\/\/wordpress.com\/theme\/confit\/","xhrURL":"https:\/\/jeremykun.com\/wp-admin\/admin-ajax.php","nonce":"b9e1c8964c","isSingular":"1","isFolded":"","isLoggedIn":"","isMobile":"","subscribeNonce":"<input type=\"hidden\" id=\"_wpnonce\" name=\"_wpnonce\" value=\"8a5d6c09dc\" \/>","referer":"https:\/\/jeremykun.com\/2016\/05\/16\/singular-value-decomposition-part-2-theorem-proof-algorithm\/","canFollow":"1","feedID":"6655781","statusMessage":"","customizeLink":"https:\/\/jeremykun.wordpress.com\/wp-admin\/customize.php?url=https%3A%2F%2Fjeremykun.wordpress.com%2F2016%2F05%2F16%2Fsingular-value-decomposition-part-2-theorem-proof-algorithm%2F","postID":"8329","shortlink":"https:\/\/wp.me\/p1Cqvi-2al","canEditPost":"","editLink":"https:\/\/wordpress.com\/post\/jeremykun.com\/8329","statsLink":"https:\/\/wordpress.com\/stats\/post\/8329\/jeremykun.com","i18n":{"view":"View site","follow":"Follow","following":"Following","edit":"Edit","login":"Log in","signup":"Sign up","customize":"Customize","report":"Report this content","themeInfo":"Get theme: Confit","shortlink":"Copy shortlink","copied":"Copied","followedText":"New posts from this site will now appear in your <a href=\"https:\/\/wordpress.com\/\">Reader<\/a>","foldBar":"Collapse this bar","unfoldBar":"Expand this bar","editSubs":"Manage subscriptions","viewReader":"View site in Reader","viewReadPost":"View post in Reader","subscribe":"Sign me up","enterEmail":"Enter your email address","followers":"Join 19,665 other followers","alreadyUser":"Already have a WordPress.com account? <a href=\"https:\/\/wordpress.com\/log-in?redirect_to=https%3A%2F%2Fjeremykun.com%2F2016%2F05%2F16%2Fsingular-value-decomposition-part-2-theorem-proof-algorithm%2F&signup_flow=account&domain=jeremykun.com\">Log in now.<\/a>","stats":"Stats"}};
</script>
<script>
var jetpackCarouselStrings = {"widths":[370,700,1000,1200,1400,2000],"is_logged_in":"","lang":"en","ajaxurl":"https:\/\/jeremykun.com\/wp-admin\/admin-ajax.php","nonce":"302421024d","display_exif":"1","display_geo":"1","single_image_gallery":"1","single_image_gallery_media_file":"","background_color":"black","comment":"Comment","post_comment":"Post Comment","write_comment":"Write a Comment...","loading_comments":"Loading Comments...","download_original":"View full size <span class=\"photo-size\">{0}<span class=\"photo-size-times\">\u00d7<\/span>{1}<\/span>","no_comment_text":"Please be sure to submit some text with your comment.","no_comment_email":"Please provide an email address to comment.","no_comment_author":"Please provide your name to comment.","comment_post_error":"Sorry, but there was an error posting your comment. Please try again later.","comment_approved":"Your comment was approved.","comment_unapproved":"Your comment is in moderation.","camera":"Camera","aperture":"Aperture","shutter_speed":"Shutter Speed","focal_length":"Focal Length","copyright":"Copyright","comment_registration":"0","require_name_email":"1","login_url":"https:\/\/jeremykun.wordpress.com\/wp-login.php?redirect_to=https%3A%2F%2Fjeremykun.com%2F2016%2F05%2F16%2Fsingular-value-decomposition-part-2-theorem-proof-algorithm%2F","blog_id":"23934684","meta_data":["camera","aperture","shutter_speed","focal_length","copyright"],"local_comments_commenting_as":"<fieldset><label for=\"email\">Email (Required)<\/label> <input type=\"text\" name=\"email\" class=\"jp-carousel-comment-form-field jp-carousel-comment-form-text-field\" id=\"jp-carousel-comment-form-email-field\" \/><\/fieldset><fieldset><label for=\"author\">Name (Required)<\/label> <input type=\"text\" name=\"author\" class=\"jp-carousel-comment-form-field jp-carousel-comment-form-text-field\" id=\"jp-carousel-comment-form-author-field\" \/><\/fieldset><fieldset><label for=\"url\">Website<\/label> <input type=\"text\" name=\"url\" class=\"jp-carousel-comment-form-field jp-carousel-comment-form-text-field\" id=\"jp-carousel-comment-form-url-field\" \/><\/fieldset>","reblog":"Reblog","reblogged":"Reblogged","reblog_add_thoughts":"Add your thoughts here... (optional)","reblogging":"Reblogging...","post_reblog":"Post Reblog","stats_query_args":"blog=23934684&v=wpcom&tz=-8&user_id=0&subd=jeremykun","is_public":"1","reblog_enabled":""};
</script>
<script>
var sharing_js_options = {"lang":"en","counts":"1","is_stats_active":"1"};
</script>
<script type="text/javascript" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/saved_resource(9)"></script><div id="actionbar" class="actnbr-pub-confit actnbr-has-follow actnbr-hidden"><ul><li class="actnbr-btn actnbr-hidden"> 			    	<a class="actnbr-action actnbr-actn-follow" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/"><svg class="gridicon gridicon__follow" height="24px" width="24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><g><path d="M23 16v2h-3v3h-2v-3h-3v-2h3v-3h2v3h3zM20 2v9h-4v3h-3v4H4c-1.1 0-2-.9-2-2V2h18zM8 13v-1H4v1h4zm3-3H4v1h7v-1zm0-2H4v1h7V8zm7-4H4v2h14V4z"></path></g></svg><span>Follow</span></a> 			    	<div class="actnbr-popover tip tip-top-left actnbr-notice"> 			    		<div class="tip-arrow"></div> 			    		<div class="tip-inner actnbr-follow-bubble"></div> 			    	</div> 			    </li><li class="actnbr-ellipsis actnbr-hidden"> 			  <svg class="gridicon gridicon__ellipsis" height="24" width="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><g><circle cx="5" cy="12" r="2"></circle><circle cx="19" cy="12" r="2"></circle><circle cx="12" cy="12" r="2"></circle></g></svg> 			  <div class="actnbr-popover tip tip-top-left actnbr-more"> 			  	<div class="tip-arrow"></div> 			  	<div class="tip-inner"> 				  <ul> 				    <li class="actnbr-sitename actnbr-hidden"><a href="https://jeremykun.com/"><img alt="" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/ffc08531463d8605aef9e0b51a9ac71f.png" class="avatar avatar-50" height="50" width="50" originals="50" scale="1.5"> Math ∩ Programming</a></li> 				   	<li class="actnbr-folded-customize actnbr-hidden"><a href="https://jeremykun.wordpress.com/wp-admin/customize.php?url=https%3A%2F%2Fjeremykun.wordpress.com%2F2016%2F05%2F16%2Fsingular-value-decomposition-part-2-theorem-proof-algorithm%2F"><svg class="gridicon gridicon__customize" height="20px" width="20px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><g><path d="M2 6c0-1.505.78-3.08 2-4 0 .845.69 2 2 2 1.657 0 3 1.343 3 3 0 .386-.08.752-.212 1.09.74.594 1.476 1.19 2.19 1.81L8.9 11.98c-.62-.716-1.214-1.454-1.807-2.192C6.753 9.92 6.387 10 6 10c-2.21 0-4-1.79-4-4zm12.152 6.848l1.34-1.34c.607.304 1.283.492 2.008.492 2.485 0 4.5-2.015 4.5-4.5 0-.725-.188-1.4-.493-2.007L18 9l-2-2 3.507-3.507C18.9 3.188 18.225 3 17.5 3 15.015 3 13 5.015 13 7.5c0 .725.188 1.4.493 2.007L3 20l2 2 6.848-6.848c1.885 1.928 3.874 3.753 5.977 5.45l1.425 1.148 1.5-1.5-1.15-1.425c-1.695-2.103-3.52-4.092-5.448-5.977z" data-reactid=".2.1.1:0.1b.0"></path></g></svg><span>Customize<span></span></span></a></li> 				    <li class="actnbr-folded-follow actnbr-hidden"><a class="actnbr-action actnbr-actn-follow" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/"><svg class="gridicon gridicon__follow" height="24px" width="24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><g><path d="M23 16v2h-3v3h-2v-3h-3v-2h3v-3h2v3h3zM20 2v9h-4v3h-3v4H4c-1.1 0-2-.9-2-2V2h18zM8 13v-1H4v1h4zm3-3H4v1h7v-1zm0-2H4v1h7V8zm7-4H4v2h14V4z"></path></g></svg><span>Follow</span></a></li> 					<li class="actnbr-signup actnbr-hidden"><a href="https://wordpress.com/start/">Sign up</a></li> 				    <li class="actnbr-login actnbr-hidden"><a href="https://wordpress.com/log-in?redirect_to=https%3A%2F%2Fjeremykun.com%2F2016%2F05%2F16%2Fsingular-value-decomposition-part-2-theorem-proof-algorithm%2F&amp;signup_flow=account&amp;domain=jeremykun.com">Log in</a></li> 				     				    <li class="actnbr-shortlink actnbr-hidden"><a href="https://wp.me/p1Cqvi-2al">Copy shortlink</a></li> 				    <li class="flb-report actnbr-hidden"><a href="http://en.wordpress.com/abuse/">Report this content</a></li> 				     				     				    <li class="actnbr-subs actnbr-hidden"><a href="https://subscribe.wordpress.com/">Manage subscriptions</a></li> 				    <li class="actnbr-fold actnbr-hidden"><a href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/">Collapse this bar</a></li> 			      </ul> 			    </div> 		      </div> 		    </li> 	      </ul></div>
<script type="text/javascript">
var windowOpen;
			jQuery( document.body ).on( 'click', 'a.share-facebook', function() {
				// If there's another sharing window open, close it.
				if ( 'undefined' !== typeof windowOpen ) {
					windowOpen.close();
				}
				windowOpen = window.open( jQuery( this ).attr( 'href' ), 'wpcomfacebook', 'menubar=1,resizable=1,width=600,height=400' );
				return false;
			});
var windowOpen;
			jQuery( document.body ).on( 'click', 'a.share-twitter', function() {
				// If there's another sharing window open, close it.
				if ( 'undefined' !== typeof windowOpen ) {
					windowOpen.close();
				}
				windowOpen = window.open( jQuery( this ).attr( 'href' ), 'wpcomtwitter', 'menubar=1,resizable=1,width=600,height=350' );
				return false;
			});
var windowOpen;
			jQuery( document.body ).on( 'click', 'a.share-linkedin', function() {
				// If there's another sharing window open, close it.
				if ( 'undefined' !== typeof windowOpen ) {
					windowOpen.close();
				}
				windowOpen = window.open( jQuery( this ).attr( 'href' ), 'wpcomlinkedin', 'menubar=1,resizable=1,width=580,height=450' );
				return false;
			});
var windowOpen;
			jQuery( document.body ).on( 'click', 'a.share-tumblr', function() {
				// If there's another sharing window open, close it.
				if ( 'undefined' !== typeof windowOpen ) {
					windowOpen.close();
				}
				windowOpen = window.open( jQuery( this ).attr( 'href' ), 'wpcomtumblr', 'menubar=1,resizable=1,width=450,height=450' );
				return false;
			});
</script>
<script type="text/javascript">
// <![CDATA[
(function() {
try{
  if ( window.external &&'msIsSiteMode' in window.external) {
    if (window.external.msIsSiteMode()) {
      var jl = document.createElement('script');
      jl.type='text/javascript';
      jl.async=true;
      jl.src='/wp-content/plugins/ie-sitemode/custom-jumplist.php';
      var s = document.getElementsByTagName('script')[0];
      s.parentNode.insertBefore(jl, s);
    }
  }
}catch(e){}
})();
// ]]>
</script>		<iframe src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/master.html" scrolling="no" id="likes-master" name="likes-master" style="display:none;"></iframe>
		<div id="likes-other-gravatars"><div class="likes-text"><span>%d</span> bloggers like this:</div><ul class="wpl-avatars sd-like-gravatars"></ul></div>
<script src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/w.js.下载" type="text/javascript" async="" defer=""></script>
<script type="text/javascript">
_tkq = window._tkq || [];
_stq = window._stq || [];
_tkq.push(['storeContext', {'blog_id':'23934684','blog_tz':'-8','user_lang':'en','blog_lang':'en','user_id':'0'}]);
_stq.push(['view', {'blog':'23934684','v':'wpcom','tz':'-8','user_id':'0','post':'8329','subd':'jeremykun'}]);
_stq.push(['extra', {'crypt':'UE40eW5QN0p8M2Y/RE1TaVhzUzFMbjdWNHpwZGhTayxPSUFCMGNrd29+Smw0TDhnZmRTK0hlRi9QSGh6bi9GXVhBJWIlZlR5U1JMLU8/MkNtblkvY1d6eVJXLU13dlVUTUYlVD09YS1fM2lfKy1xRUs/UDdyRGtEZEloJm9nNjNyMUJ0ek81NzZbWi8rcldWbHU2ZmJ8OFh8OC1Nbl84cGc3NnVYQX53UGpGeTdbS1JHSXFLT3BoPTddd2xjcVU0SCZfcy82MFk/QzMuQWNhVHNjcVJrT1Y/SkFxMURCRk89U19YV0MtSERzbFRPK2ZSZEh0TTBLLVtBVnE5Qi9GVzJOWEd5Tzl0c1t6azNaTURpbSxbeDEsSkRRfm1tQ112ZywsVWY0c0NZbHZ8TnB8SEd5U3o2dS9hbk12SVpnNw=='}]);
_stq.push([ 'clickTrackerInit', '23934684', '8329' ]);
	</script>
<noscript><img src="https://pixel.wp.com/b.gif?v=noscript" style="height:0px;width:0px;overflow:hidden" alt="" /></noscript>
<script>
if ( 'object' === typeof wpcom_mobile_user_agent_info ) {

	wpcom_mobile_user_agent_info.init();
	var mobileStatsQueryString = "";
	
	if( false !== wpcom_mobile_user_agent_info.matchedPlatformName )
		mobileStatsQueryString += "&x_" + 'mobile_platforms' + '=' + wpcom_mobile_user_agent_info.matchedPlatformName;
	
	if( false !== wpcom_mobile_user_agent_info.matchedUserAgentName )
		mobileStatsQueryString += "&x_" + 'mobile_devices' + '=' + wpcom_mobile_user_agent_info.matchedUserAgentName;
	
	if( wpcom_mobile_user_agent_info.isIPad() )
		mobileStatsQueryString += "&x_" + 'ipad_views' + '=' + 'views';

	if( "" != mobileStatsQueryString ) {
		new Image().src = document.location.protocol + '//pixel.wp.com/g.gif?v=wpcom-no-pv' + mobileStatsQueryString + '&baba=' + Math.random();
	}
	
}
</script>


<!--
	generated in 0.225 seconds
	222565 bytes batcached for 300 seconds
-->
<div class="comment-likes-overlay" style="display: none;"></div><div id="sharing_email" style="display: none;">
		<form action="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/" method="post">
			<label for="target_email">Send to Email Address</label>
			<input type="email" name="target_email" id="target_email" value="">

			
				<label for="source_name">Your Name</label>
				<input type="text" name="source_name" id="source_name" value="">

				<label for="source_email">Your Email Address</label>
				<input type="email" name="source_email" id="source_email" value="">

						<input type="text" id="jetpack-source_f_name" name="source_f_name" class="input" value="" size="25" autocomplete="off" title="This field is for validation and should not be changed">
			
			<div class="g-recaptcha" data-sitekey="6LcmyE0UAAAAALID28yVNg7pFCodGaArJzHitez_" data-theme="light" data-type="image" data-tabindex="0"></div>
			<script type="text/javascript" src="https://www.google.com/recaptcha/api.js?hl=en" async=""></script>
			
			<img style="float: right; display: none" class="loading" src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/loading.gif" alt="loading" width="16" height="16" scale="0">
			<input type="submit" value="Send Email" class="sharing_send">
			<a rel="nofollow" href="https://jeremykun.com/2016/05/16/singular-value-decomposition-part-2-theorem-proof-algorithm/#cancel" class="sharing_cancel" role="button">Cancel</a>

			<div class="errors errors-1" style="display: none;">
				Post was not sent - check your email addresses!			</div>

			<div class="errors errors-2" style="display: none;">
				Email check failed, please try again			</div>

			<div class="errors errors-3" style="display: none;">
				Sorry, your blog cannot share posts by email.			</div>
		</form>
	</div><img src="./Singular Value Decomposition Part 2_ Theorem, Proof, Algorithm – Math ∩ Programming_files/g.gif" alt=":)" id="wpstats" scale="0"></body></html>