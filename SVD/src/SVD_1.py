# -*- coding: utf-8 -*-
# @Time    : 2019/11/4 19:45
# @Author  : Weiyang
# @File    : SVD_1.py

#=======================================================================================================================
# 奇异值分解(singular value decomposition,SVD)：一种矩阵因子分解法，用于矩阵数据压缩，即用因子分解式的方式近似地表示原始矩阵，
# 这种近似是在平方损失(弗罗贝尼乌斯范数)意义下的最优近似。

# 概念：
# 任意一个m×n 非零矩阵，都可以表示为三个矩阵的乘积：
#                               A_m*n = U_m*m ∑_m*n (V_n*n)^T
# U是m阶正交矩阵，∑ 是由 降序排列的 非负的 对角线元素 组成的m×n矩形对角矩阵，V是 n阶正交矩阵
# 对角线元素为奇异值，U 的列向量称为左奇异向量，V 的列向量称为右奇异向量
# 称为该矩阵的奇异值分解。

# 奇异值分解不要求矩阵A是方阵。

# 正交矩阵的性质：
# 1. Q*Q^T = E
# 2. Q^T = Q^(-1) ，转置矩阵 = 逆矩阵
# 3. 行向量两两正交，列向量两两正交
# 4. 列向量组是R^n 的标准正交基
# 5. 假设alpha_i ,alpha_j 是列向量，则有 i = j 时，(alpha_i)^T * alpha_j = 1 ,i ≠ j 时，(alpha_i)^T * alpha_j = 0

# 特征向量
# 1. 矩阵的特征值是唯一确定的，但特征向量不唯一
# 2. 一个特征向量的任何非零倍数也是特征向量，同一特征值的不同特征向量的线性组合也是特征向量

# 矩阵的奇异值分解一定存在，但不唯一。矩阵的奇异值分解中，奇异值是唯一的，但U和V不是唯一的，因为特征向量不唯一
# 求V和∑
# A^T*A的特征向量单位化后构成正交矩阵V的列，A^T*A的特征值的平方根为∑的奇异值，对奇异值由大到小排列作为∑的对角线元素；
# 求U
# 1. 求正奇异值对应的左奇异向量，即 u_j = 1/sigma_j * Av_j ,   v_j是V的列向量 ，构成U1 = [u1,..,u_r] r为原矩阵的秩或正奇异值的个数
# 2. 再求扩充的A^T的标准正交基，构成正交矩阵U的列，即求A^T的零空间的一组标准正交基{u_r+1,..,u_m}，构成U2 = [u_r+1,..,u_m]
# 3. U = [U1,U2]

# 奇异值分解分为：
# 1. 完全奇异值分解：A_m*n = U_m*m ∑_m*n (V_n*n)^T ，即保留所有的奇异值，所有的左奇异向量 和 所有的右奇异向量，奇异向量是列向量
# 2. 紧奇异值分解：A_m*n = U_m*r ∑_r*r (V_n*r)^T，r 为原始矩阵A的秩，矩阵U_m*r 是由完全奇异值分解中的U_m*m的前r列组成，
#                 矩阵V_n*r是由完全奇异值分解中的V_n*n的前r列组成，对角阵∑_r*r 是由完全奇异值分解中的∑_m*n的前r个对角线元素
#                 组成；
#                 紧奇异值分解是与原始矩阵等秩的奇异值分解，对应着无损压缩
# 3. 截断奇异值分解：A_m*n = U_m*k ∑_k*k (V_n*k)^T，k 对应着前K个最大的奇异值，其中 k < r(原始矩阵A的秩)，
#                   矩阵U_m*k 是由完全奇异值分解中的U_m*m的前k列组成，矩阵V_n*k是由完全奇异值分解中的V_n*n的前k列组成，
#                   对角阵∑_k*k 是由完全奇异值分解中的∑_m*n的前k个对角线元素组成；
#                   我们通常指的奇异值分解便是截断奇异值分解，对应着有损压缩

# SVD的用途：
# 在实际用途中，常常需要对矩阵的数据进行压缩，将其近似表示，奇异值分解提供了一种方法。奇异值分解是在平方损失(弗罗贝尼乌斯范数)
# 意义下对矩阵的最优近似。紧奇异值分解对应着无损压缩，截断奇异值分解对应着有损压缩。

# 奇异值分解的几何解释
# 1. 几何上，矩阵描述的是一种线性变换，比如 m*n的矩阵表示从n维空间R^n到m维空间R^m的一个线性变换：
#                                    T : x -> Ax
#    x ∈ R^n , Ax ∈ R^m , x 和 Ax 分别是各自空间的向量
# 2. 奇异值分解从线性变换的角度理解，可分解为三个变换：
#    1. 一个坐标系的旋转或反射变换
#    2. 一个坐标轴的缩放变换
#    3. 另一个坐标系的选择或反射变换
# 3. 奇异值分解保证2中的变换一定存在，这便是奇异值分解的几何解释。
# 4. 对矩阵A进行奇异值分解，得到 A_m*n = U_m*m ∑_m*n (V_n*n)^T ，V和U都是正交矩阵，所以V的列向量v1,v2,...,v_n构成R^n空间的
#    一组标准正交基，表示R^n中的正交坐标系的旋转或反射变换；U的列向量u1,u2,...,u_m构成R^m空间的一组标准正交基，表示R^m中的
#    正交坐标系的旋转或反射变换；∑的对角元素σ_1,σ_2,...,σ_n 是一组非负实数，表示R^n中的原始正交坐标系坐标轴的
#    σ_1,σ_2,...,σ_n倍的缩放变换。
# 5. 任意一个向量 x∈R^n，经过基于A=U∑V^T 的线性变换，等价于 经过坐标系的旋转或反射变换V^T，坐标轴的缩放变换∑，以及坐标系的
#    旋转或反射变换U，得到向量 Ax ∈R^m ，注意 线性变换T : x -> Ax = U∑V^T x ，因此从右向左一层一层变换。
# 6. 矩阵的奇异值分解也可以看作是将其对应的线性变换分解为旋转变换、缩放变换及旋转变换的组合。

# 性质
# 1. 设矩阵A的奇异值分解为A=U∑V^T，则以下关系成立：
#    A^T * A = (U∑V^T)^T * (U∑V^T) = V * ∑^T * U^T *  U * ∑ * V^T =  V * ∑^T * ∑ * V^T = V(∑^T * ∑)V^T
#    A * A^T = (U∑V^T) * (U∑V^T)^T = (U∑V^T) * V * ∑^T * U^T = U * ∑ * ∑^T * U^T = U(∑ * ∑^T)U^T
#    A^T * A 和 A * A^T 都是方阵，由上式可知，这两个矩阵的特征分解存在，且可以由矩阵A的奇异值分解的矩阵表示。
#    V的列向量是A^T * A的特征向量，U的列向量是A * A^T的特征向量，∑的奇异值是A^T * A 和 A * A^T 的平方根
#    注意，不可以同时根据A^T * A和A * A^T来求V和U，因为此时U和V并不对应

# 奇异值分解的计算步骤
# 1. 首先求A^T * A的特征值和特征向量：
#    设W = A^T * A,求解特征方程 (W - λI)x = 0,得到特征值λ，并将特征值由大到小排列，
#    将特征值带入方程Av = λv 求得对应的特征向量
# 2. 求n阶正交矩阵V
#    将特征向量单位化，得到单位特征向量v1,v2,...,vn，构成正交矩阵V=[v1,v2,...,vn]，注意这里v1是第一列，其它类似
# 3. 求m*n的对角矩阵∑
#    计算A的奇异值，σ_i = sqrt(λ_i) ,λ_i是1中的特征值
#    构造m*n矩形对角矩阵∑，主对角线元素是奇异值，其余元素是零，∑ = diag(σ_1,σ_2,...,σ_n)
# 4. 求m阶正交矩阵U
#    对A的前r个奇异值，令
#                      u_j = 1/σ_j * A * v_j , j = 1,2,...,r
#    得到
#                      U1 = [u1,...,u_r]
#    求A^T的零空间的一组标准正交基{u_r+1,u_r+2,...,u_m}，可令A^Tx = 0 求得，这个是多解
#                      U2 = [u_r+1,u_r+2,...,u_m] 注意这里v_r+1是第一列，其它类似
#    则 U = [U1,U2]
#=======================================================================================================================

import numpy as np

def SVD(matrix,rank=2):
    '''
    matrix: np.array 待分解的矩阵
    matrix.shape = (m,n)
    rank = rank(A) <= min(m,n)表示 紧奇异值分解
    0 < rank < rank(A) 表示 截断奇异值分解

    如果给出的rank大于等于矩阵的秩，则返回紧奇异值分解；如果给出的rank小于矩阵的秩，则返回截断奇异值分解

    缺陷：无法求解完全奇异值分解，因为暂时无法解决Ax=b，其中A不是方阵，的求解问题
    '''
    if type(rank) != int: return None
    matrix = np.array(matrix,dtype=float) # 转为浮点数，避免计算误差
    m,n = matrix.shape
    # 求 A^T * A 的特征值和特征向量
    feature_value,feature_vector = np.linalg.eigh(matrix.T.dot(matrix)) # 特征值是按照升序排列的
    # 将特征值和其对应的特征向量，按照特征值的大小降序排列
    feature_value,feature_vector = feature_value[::-1],feature_vector[::-1]

    # 求n阶正交矩阵V: 将特征向量单位化，得到单位特征向量v1,v2,...,vn，构成正交矩阵V=[v1,v2,...,vn] 注意这里v1是第一列，其它类似
    feature_vector = [ vec/np.sqrt(np.sum([value*value for value in vec],dtype=float)) for vec in feature_vector]
    V = np.array(feature_vector).T  # 上面是按行排列的，需要转置一下

    # 求m*n的对角阵∑
    # 求奇异值，包含正奇异值和0奇异值
    singular_value = [np.sqrt(value) for value in feature_value]
    # 对角阵∑
    sigma = np.diag(singular_value)
    # 获取原始矩阵的秩
    matrix_rank = np.linalg.matrix_rank(matrix)
    print('原始矩阵的秩为：',matrix_rank)

    # 求m阶正交矩阵U
    # 对全部正奇异值，计算 u_j = 1/singular_value * A * v_j ，v_j是A^T * A单位化的特征向量
    U1 = [ 1/value * matrix.dot(vector) for value,vector in zip(singular_value,feature_vector) if value > 0]
    U = np.array(U1).T # 上面是按行排列的，需转置一下

    if rank >= matrix_rank:
        # 返回紧奇异值分解
        return U[:,:matrix_rank],sigma[:matrix_rank,:matrix_rank],V[:,:matrix_rank]
    else:
        # 返回截断的奇异值分解
        return U[:,:rank],sigma[:rank,:rank],V[:,:rank]

if __name__ == '__main__':
    matrix = np.array([
        [2, 5, 3],
        [1, 2, 1],
        [4, 1, 1],
        [3, 5, 2],
        [5, 3, 1],
        [4, 5, 5],
        [2, 4, 2],
        [2, 2, 5],
    ], dtype='float64')

    U,sigma,V = SVD(matrix,rank=3)
    print("奇异值分解的三个矩阵为：")
    print("U矩阵是：")
    print(U)
    print()
    print("sigma对角矩阵是：")
    print(sigma)
    print()
    print("V矩阵是：")
    print(V)
    print()
    print("用分解后的三个矩阵 重构原矩阵的结果为：")
    print(U.dot(sigma.dot(V.T)))
    print()
    print("原始矩阵为：")
    print(matrix)